
 <!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
  
    <title>机器学习实战 — 支持向量机 | Zane Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Jinping Luo">
    
    <meta name="description" content="1. 要解决的问题与「机器学习实战 — 决策树」的问题一样
2. 前情回顾在上一次中，随机森林的效果最好，最终效果如下：
3. 特征工程特征工程与第二次作业一样，但增加了最后一步「特征归一化」，步骤概述如下：

特征选取
删除无用特征
空值处理
处理重要特征
特征标签化
特征归一化

3.1 特征归">
    
    
    <meta name="description" content="1. 要解决的问题与「机器学习实战 — 决策树」的问题一样 2. 前情回顾在上一次中，随机森林的效果最好，最终效果如下： 3. 特征工程特征工程与第二次作业一样，但增加了最后一步「特征归一化」，步骤概述如下：  特征选取 删除无用特征 空值处理 处理重要特征 特征标签化 特征归一化  3.1 特征归一化使用 StandardScaler 和 MinMaxScaler 的差别不大，最终使用的是 St">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习实战 — 支持向量机">
<meta property="og:url" content="http://luojinping.com/2019/03/04/机器学习实战-—-支持向量机/index.html">
<meta property="og:site_name" content="Zane Blog">
<meta property="og:description" content="1. 要解决的问题与「机器学习实战 — 决策树」的问题一样 2. 前情回顾在上一次中，随机森林的效果最好，最终效果如下： 3. 特征工程特征工程与第二次作业一样，但增加了最后一步「特征归一化」，步骤概述如下：  特征选取 删除无用特征 空值处理 处理重要特征 特征标签化 特征归一化  3.1 特征归一化使用 StandardScaler 和 MinMaxScaler 的差别不大，最终使用的是 St">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://luojinping.com/img/RF_finally_auc.jpg">
<meta property="og:image" content="http://luojinping.com/img/features_normalization_gradient_descent.jpg">
<meta property="og:image" content="http://luojinping.com/img/features_normalization_analysis.jpg">
<meta property="og:image" content="http://luojinping.com/img/SVM_GridSearch_result.jpg">
<meta property="og:image" content="http://luojinping.com/img/SVM_normal_model_auc.jpg">
<meta property="og:image" content="http://luojinping.com/img/SVM_model_compare.jpg">
<meta property="og:updated_time" content="2019-08-18T08:52:45.002Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习实战 — 支持向量机">
<meta name="twitter:description" content="1. 要解决的问题与「机器学习实战 — 决策树」的问题一样 2. 前情回顾在上一次中，随机森林的效果最好，最终效果如下： 3. 特征工程特征工程与第二次作业一样，但增加了最后一步「特征归一化」，步骤概述如下：  特征选取 删除无用特征 空值处理 处理重要特征 特征标签化 特征归一化  3.1 特征归一化使用 StandardScaler 和 MinMaxScaler 的差别不大，最终使用的是 St">
<meta name="twitter:image" content="http://luojinping.com/img/RF_finally_auc.jpg">

    
    <link rel="alternative" href="/atom.xml" title="Zane Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?a2d87d3add52ff134d9fac6cc16e4800";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

</head>
</html>
  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Zane Blog" title="Zane Blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Zane Blog">Zane Blog</a></h1>
				<h2 class="blog-motto">业精于勤荒于嬉，形成思毁于随</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:luojinping.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/03/04/机器学习实战-—-支持向量机/" title="机器学习实战 — 支持向量机" itemprop="url">机器学习实战 — 支持向量机</a>
  </h1>
  <p class="article-author">By
       
		<a href="http://luojinping.com/about" title="Jinping Luo" target="_blank" itemprop="author">Jinping Luo</a>
		
  <p class="article-time">
    <time datetime="2019-03-04T15:23:56.000Z" itemprop="datePublished"> Published Mar 4 2019</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-要解决的问题"><span class="toc-number">1.</span> <span class="toc-text">1. 要解决的问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-前情回顾"><span class="toc-number">2.</span> <span class="toc-text">2. 前情回顾</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-特征工程"><span class="toc-number">3.</span> <span class="toc-text">3. 特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-特征归一化"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 特征归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-最终数据集"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 最终数据集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-SVM"><span class="toc-number">4.</span> <span class="toc-text">4. SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-核函数介绍"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 核函数介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-SVM-RBF-参数搜索"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 SVM RBF 参数搜索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-常用核函数"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 常用核函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-自定义核函数"><span class="toc-number">4.4.</span> <span class="toc-text">4.4 自定义核函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-总结"><span class="toc-number">5.</span> <span class="toc-text">5. 总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-SVM-准确率的思考"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 SVM 准确率的思考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-提升-SVM-训练速度的心得"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 提升 SVM 训练速度的心得</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考文档"><span class="toc-number">6.</span> <span class="toc-text">参考文档</span></a></li></ol>
		
		</div>
		
		<h1 id="1-要解决的问题"><a href="#1-要解决的问题" class="headerlink" title="1. 要解决的问题"></a>1. 要解决的问题</h1><p>与「机器学习实战 — 决策树」的问题一样</p>
<h1 id="2-前情回顾"><a href="#2-前情回顾" class="headerlink" title="2. 前情回顾"></a>2. 前情回顾</h1><p>在上一次中，随机森林的效果最好，最终效果如下：<br><img src="/img/RF_finally_auc.jpg" alt="RF_finally_auc.jpg"></p>
<h1 id="3-特征工程"><a href="#3-特征工程" class="headerlink" title="3. 特征工程"></a>3. 特征工程</h1><p>特征工程与第二次作业一样，但增加了最后一步「特征归一化」，步骤概述如下：</p>
<ol>
<li>特征选取</li>
<li>删除无用特征</li>
<li>空值处理</li>
<li>处理重要特征</li>
<li>特征标签化</li>
<li><strong>特征归一化</strong></li>
</ol>
<h2 id="3-1-特征归一化"><a href="#3-1-特征归一化" class="headerlink" title="3.1 特征归一化"></a>3.1 特征归一化</h2><p>使用 StandardScaler 和 MinMaxScaler 的差别不大，最终使用的是 StandardScaler。因为特征基本上都是符合正态分布的，而且 StandardScaler 对数据变动时引入新的极值点更友好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 z-score 标准化特征</span></span><br><span class="line">ss = preprocessing.StandardScaler()</span><br><span class="line">X = ss.fit_transform(X)</span><br></pre></td></tr></table></figure>

<p>特征归一化的好处有以下两点：</p>
<ol>
<li>模型训练速度更快<br>能够使参数优化时能以较快的速度收敛。<br>归一化前后的 SVM(linear 核) 的耗时对比，数据集 (2783, 54)，即 2783 条数据，54 个特征。归一化前后的耗时分别为：1083s，0.44s，可见归一化对计算速度的提升非常大。</li>
<li>模型的准确率提升<br>将特征缩放到同一尺度的量级，能够使搜索的跳跃更加平滑，避免反复震荡的情况，提高准确率。可以参考下图形象化的解释：<br><img src="/img/features_normalization_gradient_descent.jpg" alt="features_normalization_gradient_descent.jpg"></li>
</ol>
<p>对于不同数量的训练集，训练 SVM，LR，DT，RF 四个模型。随着数据集的数量增加，特征归一化后的模型，其准确率提升如下图所示：<br><img src="/img/features_normalization_analysis.jpg" alt="features_normalization_analysis.jpg"></p>
<p>通过这个图，也会发现特征归一化也不是能够提升所有模型的准确率，对于 DT 和 RF 就没有效果，这是因为决策树的分支只是计算信息熵，而不考虑整体特征的分布情况。</p>
<h2 id="3-2-最终数据集"><a href="#3-2-最终数据集" class="headerlink" title="3.2 最终数据集"></a>3.2 最终数据集</h2><p>经过一系列处理后可用的数据集有 30w，但由于 SVM 运行地太慢了，从中选取 2w 数据来作为本次作业的数据集。</p>
<h1 id="4-SVM"><a href="#4-SVM" class="headerlink" title="4. SVM"></a>4. SVM</h1><h2 id="4-1-核函数介绍"><a href="#4-1-核函数介绍" class="headerlink" title="4.1 核函数介绍"></a>4.1 核函数介绍</h2><p>常见的核函数有：</p>
<ol>
<li>linear：主要用于线性可分的情形。参数少，速度快，对于一般数据，分类效果已经很理想了。</li>
<li>rbf：将样本映射到更高维的空间，目前应用最广的一个，对大小样本都有比较好的性能，而且参数较少。linear 是 rbf 的一个特例。</li>
<li>poly：多项式核函数，将低维的输入空间映射到高纬的特征空间，参数多，当多项式的阶数比较高时，计算复杂度会非常大。</li>
<li>sigmod：支持向量机实现的就是一种多层神经网络。</li>
</ol>
<p>Andrew Ng 的建议：</p>
<ol>
<li>如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM</li>
<li>如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel</li>
<li>如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况</li>
</ol>
<p>本次作业的数据集特征少，数据大。结合上述建议，再加上取了少部分(1k~5k)的数据进行了初步对比，决定重点调优 rbf 的参数。</p>
<h2 id="4-2-SVM-RBF-参数搜索"><a href="#4-2-SVM-RBF-参数搜索" class="headerlink" title="4.2 SVM RBF 参数搜索"></a>4.2 SVM RBF 参数搜索</h2><p>训练集数据量： 2w。搜索最优参数，用时 12.3 小时，将 搜索过程的数据记录 绘制成下图所示，纵轴代表搜索得分，横轴代表 {C, gamma} 两个参数的取值。</p>
<p><img src="/img/SVM_GridSearch_result.jpg" alt="SVM_GridSearch_result.jpg"></p>
<p>C = 10, gamma = 0.1 时的效果最好。如上图中红圈所示，对于 C = 0.1, 100, 1000 时，都是gamma = 0.1 这个位置时效果最好。</p>
<h2 id="4-3-常用核函数"><a href="#4-3-常用核函数" class="headerlink" title="4.3 常用核函数"></a>4.3 常用核函数</h2><p>在本次作业的数据集中，linear 核函数的运算速度相当慢，所以对于常用核函数，仅对比了 rbf，poly 和 sigmoid 三个核函数。针对 2w 条数据，运行结果如下：</p>
<p><img src="/img/SVM_normal_model_auc.jpg" alt="SVM_normal_model_auc.jpg"></p>
<p>其中，rbf 效果最好，AUC 有 0.82，但相比起之前 AUC 0.9 的 RF 来还是不理想。</p>
<h2 id="4-4-自定义核函数"><a href="#4-4-自定义核函数" class="headerlink" title="4.4 自定义核函数"></a>4.4 自定义核函数</h2><p>由于常用核函数的效果不够理想，所以尝试使用自定义的核函数，参考前人总结出的各种核函数，放入模型中进行尝试。核函数的公式见原代码，任取两个核函数的说明如下：</p>
<p><strong>Rational quadratic kernel</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Rational quadratic kernel, </span></span><br><span class="line"><span class="string">    K(x, y) = 1 - ||x-y||^2/(||x-y||^2+c)</span></span><br><span class="line"><span class="string">where:</span></span><br><span class="line"><span class="string">    c &gt; 0</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rational_quadratic</span><span class="params">(data_1, data_2)</span>:</span></span><br><span class="line">    _c = <span class="number">1</span></span><br><span class="line">    dists_sq = euclidean_dist_matrix(data_1, data_2)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> - (dists_sq / (dists_sq + _c))</span><br></pre></td></tr></table></figure>

<p><strong>Inverse multiquadratic kernel</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Inverse multiquadratic kernel, </span></span><br><span class="line"><span class="string">    K(x, y) = 1 / sqrt(||x-y||^2 + c^2)</span></span><br><span class="line"><span class="string">where:</span></span><br><span class="line"><span class="string">    c &gt; 0</span></span><br><span class="line"><span class="string">as defined in:</span></span><br><span class="line"><span class="string">"Interpolation of scattered data: Distance matrices and conditionally positive definite functions"</span></span><br><span class="line"><span class="string">Charles Micchelli</span></span><br><span class="line"><span class="string">Constructive Approximation</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inverse_multiquadratic</span><span class="params">(data_1, data_2)</span>:</span></span><br><span class="line">    _c = <span class="number">1</span> ** <span class="number">2</span></span><br><span class="line">    dists_sq = euclidean_dist_matrix(data_1, data_2)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / np.sqrt(dists_sq + _c)</span><br></pre></td></tr></table></figure>

<p>仍然是对于这 2w 条数据，将所有核函数放入 SVM 中训练，最终每个核函数的准确率和耗时对比表格如下：</p>
<p><img src="/img/SVM_model_compare.jpg" alt="SVM_model_compare.jpg"></p>
<p>可以发现 rbf, inverse_multiquadratic 和 cauchy 这三个核函数的效果较好，其中 rbf 训练速度最快，inverse_multiquadratic 准确率最高。</p>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><h2 id="5-1-SVM-准确率的思考"><a href="#5-1-SVM-准确率的思考" class="headerlink" title="5.1 SVM 准确率的思考"></a>5.1 SVM 准确率的思考</h2><p>最终，使用 inverse_multiquadratic 核函数可以将 SVM 模型的 AUC Score 最高调至 0.822，相比于第二次作业中 Random Forest 模型的 AUC Score 结果 0.902 还有差距。可能是由于核函数选取的仍然不够合适，在映射后的空间中数据不是那么线性可分，降低了模型的泛化能力，导致准确率不如 RF。而对于核函数的选取，需要更多地理解特征，并列举出所有可能的核函数，再进行对比选择，在选取核函数这一点上，没有很好的捷径可走。</p>
<h2 id="5-2-提升-SVM-训练速度的心得"><a href="#5-2-提升-SVM-训练速度的心得" class="headerlink" title="5.2 提升 SVM 训练速度的心得"></a>5.2 提升 SVM 训练速度的心得</h2><ol>
<li>特征标签化和归一化</li>
<li>SVC 的 cache_size 设置到 7000 (M) </li>
<li>核函数是 SVM 的关键，先用少部分数据来选核函数，再用全量数据训练</li>
<li>SVM 的 C 参数不要设置的太大</li>
</ol>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://scikit-learn.org/stable/modules/svm.html" target="_blank" rel="noopener">1.4. Support Vector Machines — scikit-learn 0.20.1 documentation</a><br><a href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py" target="_blank" rel="noopener">RBF SVM parameters — scikit-learn 0.20.1 documentation</a><br><a href="https://www.jianshu.com/p/95e5faa3f709" target="_blank" rel="noopener">逻辑斯蒂回归VS决策树VS随机森林 - 简书</a><br><a href="https://www.csie.ntu.edu.tw/~r95162/guide.pdf" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~r95162/guide.pdf</a><br><a href="https://github.com/gmum/pykernels" target="_blank" rel="noopener">https://github.com/gmum/pykernels</a></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Machine-Learning/">Machine Learning</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://luojinping.com/2019/03/04/机器学习实战-—-支持向量机/" data-title="机器学习实战 — 支持向量机 | Zane Blog" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/2019/03/04/机器学习实战-—-决策树/"  title="机器学习实战 — 决策树">
 <strong>下一篇：</strong><br/> 
 <span>机器学习实战 — 决策树
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-要解决的问题"><span class="toc-number">1.</span> <span class="toc-text">1. 要解决的问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-前情回顾"><span class="toc-number">2.</span> <span class="toc-text">2. 前情回顾</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-特征工程"><span class="toc-number">3.</span> <span class="toc-text">3. 特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-特征归一化"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 特征归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-最终数据集"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 最终数据集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-SVM"><span class="toc-number">4.</span> <span class="toc-text">4. SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-核函数介绍"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 核函数介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-SVM-RBF-参数搜索"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 SVM RBF 参数搜索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-常用核函数"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 常用核函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-自定义核函数"><span class="toc-number">4.4.</span> <span class="toc-text">4.4 自定义核函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-总结"><span class="toc-number">5.</span> <span class="toc-text">5. 总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-SVM-准确率的思考"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 SVM 准确率的思考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-提升-SVM-训练速度的心得"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 提升 SVM 训练速度的心得</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考文档"><span class="toc-number">6.</span> <span class="toc-text">参考文档</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/Java/" title="Java">Java<sup>15</sup></a></li>
		
			<li><a href="/tags/Machine-Learning/" title="Machine Learning">Machine Learning<sup>11</sup></a></li>
		
			<li><a href="/tags/Algorithm/" title="Algorithm">Algorithm<sup>10</sup></a></li>
		
			<li><a href="/tags/Data/" title="Data">Data<sup>5</sup></a></li>
		
			<li><a href="/tags/Distributed-System/" title="Distributed System">Distributed System<sup>3</sup></a></li>
		
			<li><a href="/tags/Tools/" title="Tools">Tools<sup>3</sup></a></li>
		
			<li><a href="/tags/Math/" title="Math">Math<sup>3</sup></a></li>
		
			<li><a href="/tags/Introspect/" title="Introspect">Introspect<sup>2</sup></a></li>
		
			<li><a href="/tags/Mix/" title="Mix">Mix<sup>1</sup></a></li>
		
			<li><a href="/tags/Spring/" title="Spring">Spring<sup>1</sup></a></li>
		
			<li><a href="/tags/Hexo/" title="Hexo">Hexo<sup>1</sup></a></li>
		
			<li><a href="/tags/Network/" title="Network">Network<sup>1</sup></a></li>
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m ljp215 Page in Google. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://zespia.tw/hexo/" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Pacman">Jacman</a> © 2019 
		
		<a href="http://luojinping.com/about" target="_blank" title="Jinping Luo">Jinping Luo</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#nothing"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>




<script type="text/javascript">

var disqus_shortname = 'zane215';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F' type='text/javascript'%3E%3C/script%3E"));
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<!-- MathJax End -->

  </body>
</html>
