<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习实战 — 支持向量机]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E2%80%94-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[要解决的问题与「机器学习实战 — 决策树」的问题一样 前情回顾在上一次中，随机森林的效果最好，最终效果如下： 特征工程特征工程与第二次作业一样，但增加了最后一步「特征归一化」，步骤概述如下： 特征选取 删除无用特征 空值处理 处理重要特征 特征标签化 特征归一化 特征归一化使用 StandardScaler 和 MinMaxScaler 的差别不大，最终使用的是 StandardScaler。因为特征基本上都是符合正态分布的，而且 StandardScaler 对数据变动时引入新的极值点更友好。 123# 使用 z-score 标准化特征ss = preprocessing.StandardScaler()X = ss.fit_transform(X) 特征归一化的好处有以下两点： 模型训练速度更快能够使参数优化时能以较快的速度收敛。归一化前后的 SVM(linear 核) 的耗时对比，数据集 (2783, 54)，即 2783 条数据，54 个特征。归一化前后的耗时分别为：1083s，0.44s，可见归一化对计算速度的提升非常大。 模型的准确率提升将特征缩放到同一尺度的量级，能够使搜索的跳跃更加平滑，避免反复震荡的情况，提高准确率。可以参考下图形象化的解释： 对于不同数量的训练集，训练 SVM，LR，DT，RF 四个模型。随着数据集的数量增加，特征归一化后的模型，其准确率提升如下图所示： 通过这个图，也会发现特征归一化也不是能够提升所有模型的准确率，对于 DT 和 RF 就没有效果，这是因为决策树的分支只是计算信息熵，而不考虑整体特征的分布情况。 最终数据集经过一系列处理后可用的数据集有 30w，但由于 SVM 运行地太慢了，从中选取 2w 数据来作为本次作业的数据集。 SVM核函数介绍常见的核函数有： linear：主要用于线性可分的情形。参数少，速度快，对于一般数据，分类效果已经很理想了。 rbf：将样本映射到更高维的空间，目前应用最广的一个，对大小样本都有比较好的性能，而且参数较少。linear 是 rbf 的一个特例。 poly：多项式核函数，将低维的输入空间映射到高纬的特征空间，参数多，当多项式的阶数比较高时，计算复杂度会非常大。 sigmod：支持向量机实现的就是一种多层神经网络。 Andrew Ng 的建议： 如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM 如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel 如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况 本次作业的数据集特征少，数据大。结合上述建议，再加上取了少部分(1k~5k)的数据进行了初步对比，决定重点调优 rbf 的参数。 SVM RBF 参数搜索训练集数据量： 2w。搜索最优参数，用时 12.3 小时，将 搜索过程的数据记录 绘制成下图所示，纵轴代表搜索得分，横轴代表 {C, gamma} 两个参数的取值。 C = 10, gamma = 0.1 时的效果最好。如上图中红圈所示，对于 C = 0.1, 100, 1000 时，都是gamma = 0.1 这个位置时效果最好。 常用核函数在本次作业的数据集中，linear 核函数的运算速度相当慢，所以对于常用核函数，仅对比了 rbf，poly 和 sigmoid 三个核函数。针对 2w 条数据，运行结果如下： 其中，rbf 效果最好，AUC 有 0.82，但相比起之前 AUC 0.9 的 RF 来还是不理想。 自定义核函数由于常用核函数的效果不够理想，所以尝试使用自定义的核函数，参考前人总结出的各种核函数，放入模型中进行尝试。核函数的公式见原代码，任取两个核函数的说明如下： Rational quadratic kernel12345678910"""Rational quadratic kernel, K(x, y) = 1 - ||x-y||^2/(||x-y||^2+c)where: c &gt; 0"""def rational_quadratic(data_1, data_2): _c = 1 dists_sq = euclidean_dist_matrix(data_1, data_2) return 1. - (dists_sq / (dists_sq + _c)) Inverse multiquadratic kernel1234567891011121314"""Inverse multiquadratic kernel, K(x, y) = 1 / sqrt(||x-y||^2 + c^2)where: c &gt; 0as defined in:"Interpolation of scattered data: Distance matrices and conditionally positive definite functions"Charles MicchelliConstructive Approximation"""def inverse_multiquadratic(data_1, data_2): _c = 1 ** 2 dists_sq = euclidean_dist_matrix(data_1, data_2) return 1. / np.sqrt(dists_sq + _c) 仍然是对于这 2w 条数据，将所有核函数放入 SVM 中训练，最终每个核函数的准确率和耗时对比表格如下： 可以发现 rbf, inverse_multiquadratic 和 cauchy 这三个核函数的效果较好，其中 rbf 训练速度最快，inverse_multiquadratic 准确率最高。 总结SVM 准确率的思考最终，使用 inverse_multiquadratic 核函数可以将 SVM 模型的 AUC Score 最高调至 0.822，相比于第二次作业中 Random Forest 模型的 AUC Score 结果 0.902 还有差距。可能是由于核函数选取的仍然不够合适，在映射后的空间中数据不是那么线性可分，降低了模型的泛化能力，导致准确率不如 RF。而对于核函数的选取，需要更多地理解特征，并列举出所有可能的核函数，再进行对比选择，在选取核函数这一点上，没有很好的捷径可走。 提升 SVM 训练速度的心得 特征标签化和归一化 SVC 的 cache_size 设置到 7000 (M) 核函数是 SVM 的关键，先用少部分数据来选核函数，再用全量数据训练 SVM 的 C 参数不要设置的太大 参考文档1.4. Support Vector Machines — scikit-learn 0.20.1 documentationRBF SVM parameters — scikit-learn 0.20.1 documentation逻辑斯蒂回归VS决策树VS随机森林 - 简书https://www.csie.ntu.edu.tw/~r95162/guide.pdfhttps://github.com/gmum/pykernels]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习实战 — 决策树]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E2%80%94-%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"><![CDATA[要解决的问题一句话概述：预测进入 App 首页的用户是否会点击「XLJH推荐模块」，该模块是 App 的一个功能，用户点击按钮则会进入一个XLJH的页面。 目前每天进入 App 首页的用户中，有 2.1234% 的用户会点击「XLJH推荐模块」，转化率非常低，而首页每日的曝光量是最大的，所以优化这个模块的转化率就变得尤为重要，也是本次作业要解决的问题。 整体思路获取某一段时间的相关埋点事件、用户业务数据、用户画像等数据，将数据合并、清洗、整理为可用的数据集，然后跑决策树，随机森林和 Adaboost 三个模型。要获取的数据是： 用户被展示到该模块的埋点事件 用户点击该模块的埋点事件 用户使用过 XLJH 的统计数据 用户画像 用户的业务画像 特征选取特征举例特征的总数非常多，总共有 280 个，抽取一些特征描述如下： 年龄 性别 身高 体重 业务特征 1 业务特征 2 业务特征 3 … … 业务特征 n-1 业务特征 n 进入首页时距离上一次使用模块的时间 设备机型 获取数据通过在 hive 里跑 sql(具体的 sql 语句略) 获取到的数据量为：54w。（单位为数据行数，下同） 特征工程删除无用特征 无用特征的删除：例如 userId 等。这些特征明显与结果无关。 删除由预测结果导致的特征：例如使用过该模块的时间。这些特征是在预测值为 True 时才会有值，而且这特征的赋值在要预测的事件发生之后。 特征的空值处理 删除特征为空的数据，例如年龄，性别等必须会有的特征。 int 类型的特征将空值填充为 0，例如某业务的 累计分钟数，某实体数量，粉丝数量，过去7天的XX业务使用统计等 string 类型的特征将空值填充为 0，例如 citycode，tags 等。 处理重要特征跑完 Random Forest 模型，可以输出 Feature importances 列表， Top 10 的图略。 其中需要特别处理的特征是 c.bmi 和 c.age。分析数据后发现年龄为空值的情况非常少，所以把 c.age 为空的数据删掉。c.bmi 需要用户填入身高和体重，这部分数据缺失一些，所以填为 c.bmi 这一列的平均值，数据集中的 dataset[c.bmi].mean = 23.3174390247965，符合常识。 特征标签化数据标准化的处理方式如下： 123from sklearn import preprocessingle = preprocessing.LabelEncoder()dataset = dataset.apply(le.fit_transform) 可用数据量按如上方式处理完后，最终可用的数据量为：30w 模型调优Decision Tree 调优树的深度调优使用的特征数量为 275 个，使用的训练集数量为 54801。 不同树深度对应的模型评估如下： 可以发现树的深度越高，召回率越高，准确率却越低。总体评价是树的深度为 5 最好。 其他参数调优max_features=’sqrt’ 加了这个反而变差了很多。min_samples_split=5, min_samples_leaf=5，加了这个反而变差了一些。 DT 输出深度为 5 的 DT 截取部分放大后的图如下： Random Forest 调优n_estimators：100, 300, 500 都试过，差别不大。弱学习器的最大迭代次数太小会不准确，太大模型训练地就很慢。oob_score: True，即采用袋外样本来评估模型的好坏，提高模型拟合后的泛化能力。基本上，RF 不怎么需要调参。 比较有价值的是能产生特征的重要性，Top 30 Feature importances 的图片略。Feature importances Top 10 的可视化略。 使用 GridSearchCV 搜索最优参数，参数搜索结果如下： 但是使用参数后，RF 的 AUC 降到了 0.82，应该是 max_features 和 min_samples_leaf 这两个参数调的不对。 Adaboost 调优AdaBoostClassifier 的 base_estimator 选择已经之前训练好的 DT，效果更好，如下： 1234adb_clf = AdaBoostClassifier(n_estimators=100, random_state=100, learning_rate=0.02).fit(X_train, y_train)AUC Score (Train): 0.629162adb_clf_2 = AdaBoostClassifier(clf, n_estimators=100, random_state=100, learning_rate=0.02).fit(X_train, y_train)AUC Score (Train): 0.659129 learning_rate 设置为 0.02 能兼顾速度和效果。 踩过的坑信息熵基尼指数和信息熵的几乎无差别，不怎么影响结果。 PCA 降维PCA 降维，使用 mle 和 5 个特征，都不好使，准确度反而更低，AUC 得分降至 0.51。 用了未来特征决策树 AUC: 0.52 -&gt; 0.77随机森林 AUC: 0.82-&gt;0.93 随机森林的模型评价如下： 会发现准确度太高了，仔细分析后，发现用了一个「创建体测时间」的特征，而这个特征是在用户点击了 「智能计划推荐模块」后会更新值的，所以相当于用了事件发生后的特征来预测事件发生的概率，这样肯定会导致模型的准确率很高。后来去掉了这个特征。 模型对比数据集：30w，其中正样本的比例为 22%。 对比发现，DT 和 Adaboost 的效果都不好，AUC Score 都在 0.65 左右。RF 的效果最好，AUC Score 能到 0.90。可能是因为数据集符合 low bias, high variance 的规律，所以 RF 要比 Adaboost 好。 RF 的准确率和召回率都还不错，感觉可以后续上线用于 App 首页了。 总结整个过程可以抽象为：获取数据 -&gt; 调整模型参数 -&gt; 引入更多特征 -&gt; 调整模型参数 -&gt; PCA -&gt; 减少特征 -&gt; 处理重要特征 -&gt; gridSearchCV -&gt; 调整模型参数 一些总结： 特征工程很重要，特征处理好后 AUC 有明显的提升 调参也有用，但相比起来，好的特征更有用 基尼系数和熵的区别不大 树的层数越多，准确率越低，召回越高 AdaBoostClassifier base_estimators 用训练好的决策树来做，效果更好 gridSearchCV 搜索最有用的参数太慢了，而且最终效果还不好 小心引入未来特征！ 参考文档决策树分类器在Scikit-learn的使用小结 - qq_29003925的博客 - CSDN博客sklearn中的回归决策树 - FontTian的专栏 - CSDN博客1.10. 决策树 — scikit-learn 0.19.0 中文文档 - ApacheCNpandas的汇总和计算描述统计 - 修炼之路 - CSDN博客数据分析-pandas数据处理清洗常用总结 - 简书https://www.zhihu.com/question/29316149/answer/252391239集成学习概述（Bagging，RF，GBDT，Adaboost） - U R MINE - CSDN博客数据预处理与特征选择 - Joe的博客 - CSDN博客谈谈评价指标中的宏平均和微平均 - robert_ai - 博客园https://blog.csdn.net/sinat_26917383/article/details/75199996DecisionTreeClassifier和DecisionTreeClassifier 重要参数调参注意点 - akon_wang_hkbu的博客 - CSDN博客机器学习-分类器-Adaboost原理 - 宋兴柱 - 博客园]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习实战 — 朴素贝叶斯]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E2%80%94-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[作业根据给定的 20-News Group 数据集，设计Naïve Bayes 算法进行文本分类的研究。讨论和使用不同的预处理方法，并讨论各种预处理对于算法性能的影响。 步骤 加载数据集 提取 TF-IDF 特征 生成文档的 TF-IDF 矩阵 训练多项式朴素贝叶斯模型 评价模型 实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192from sklearn.datasets import fetch_20newsgroupsfrom pprint import pprintfrom sklearn.feature_extraction.text import TfidfVectorizer# sklearn twenty_newsgroups document# http://sklearn.apachecn.org/cn/0.19.0/datasets/twenty_newsgroups.htmlfetch_20newsgroups(data_home='/Users/ljp/Codes/ivy_plan/naive_bayes/20_newsgroups', # 文件下载的路径 subset='train', # 加载那一部分数据集 train/test categories=None, # 选取哪一类数据集[类别列表]，默认20类 shuffle=True, # 将数据集随机排序 random_state=42, # 随机数生成器 remove=(), # ('headers','footers','quotes') 去除部分文本 download_if_missing=True # 如果没有下载过，重新下载 )# 加载数据集newsgroups_train = fetch_20newsgroups(subset='train')# Bunch# load_*和 fetch_* 函数返回的数据类型是 datasets.base.Bunch，本质上是一个 dict，它的键值对可用通过对象的属性方式访问。# 主要包含以下属性：# data：特征数据数组，type 是 list，是 n_samples * n_features 的二维 numpy.ndarray 数组# filenames：文件数组，是文件路径，是 n_samples 的一维 numpy.ndarray 数组# target：标签数组，是类别的整数索引，是 n_samples 的一维 numpy.ndarray 数组，与 filenames 一一对应# DESCR：数据描述# feature_names：特征名# target_names：标签名# print(type(newsgroups_train)) # &lt;class 'sklearn.utils.Bunch'&gt;# print(list(newsgroups_train)) # ['data', 'filenames', 'target_names', 'target', 'DESCR', 'description']# 提取tfidf特征vectorizer = TfidfVectorizer() # vectorizer type is &lt;class 'sklearn.feature_extraction.text.TfidfVectorizer'&gt;# vectors type is &lt;class 'scipy.sparse.csr.csr_matrix'&gt;# 数据格式为：(文档序号, 单词序号), tf-idf值# 文档序号是该文档在 newsgroups_train.filenames 里的索引(位置)# 单词序号是该单词在所有单词所构成的一维向量(也称为词袋，Bag of words)里的索引(位置)# 例如：# (0, 11071) 0.02879840104494835# (0, 19516) 0.15199951710440102# (0, 24556) 0.36446543134314724vectors = vectorizer.fit_transform(newsgroups_train.data)# MultinomialNB实现文本分类from sklearn.naive_bayes import MultinomialNBfrom sklearn.metrics import accuracy_score,f1_score# 训练clf=MultinomialNB(alpha=0.1)clf.fit(vectors,newsgroups_train.target)# 加载测试集newsgroups_test=fetch_20newsgroups(subset='test')# 提取测试集tfidf特征vectors_test=vectorizer.transform(newsgroups_test.data)# 模型评价from sklearn.metrics import classification_reportpred=clf.predict(vectors_test)print('accuracy_score: ' + str(accuracy_score(newsgroups_test.target,pred)))print("classification report on test set for classifier:")print(clf)X_test = vectorizer.transform((d for d in newsgroups_test.data))pred = clf.predict(X_test)y_test = newsgroups_test.targetprint(classification_report(y_test, pred, target_names=newsgroups_test.target_names))## 生成混淆矩阵，观察每种类别被错误分类的情况from sklearn.metrics import confusion_matrixcm = confusion_matrix(y_test, pred)print("confusion matrix:")print(cm)# Show confusion matriximport matplotlib.pyplot as pltplt.figure(figsize=(8, 8), dpi=144)plt.title('Confusion matrix of the classifier')ax = plt.gca()ax.spines['right'].set_color('none')ax.spines['top'].set_color('none')ax.spines['bottom'].set_color('none')ax.spines['left'].set_color('none')ax.xaxis.set_ticks_position('none')ax.yaxis.set_ticks_position('none')ax.set_xticklabels([])ax.set_yticklabels([])plt.matshow(cm, fignum=1, cmap='gray')plt.colorbar()plt.show() 输出如下： 参考文档5.6.2. 20个新闻组文本数据集 — scikit-learn 0.19.0 中文文档 - ApacheCN利用朴素贝叶斯算法进行文档分类 - 简书https://www.cs.waikato.ac.nz/ml/publications/2004/kibriya_et_al_cr.pdf]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性回归正则化]]></title>
    <url>%2F2018%2F11%2F11%2F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%AD%A3%E5%88%99%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言线性回归出的模型如果出现过拟合怎么办？ 脏数据太多，需要清洗数据 增加训练数据的数量和多样性 特征数量过多，使用正则化减少特征数量 向量的范数向量的范数是一种用来刻画向量大小的一种度量。实数的绝对值，复数的模，三维空间向量的长度，都是抽象范数概念的原型。上述三个对象统一记为 x ，衡量它们大小的量记为 ||x|| （我们用单竖线表示绝对值，双竖线表示范数），显然它们满足以下三条性质： L0范数：向量中非零元素的个数。L1范数：向量中各个元素绝对值之和，又叫“稀疏规则算子”（Lasso regularization）L2范数：向量中各个元素平方和再开方p-范数：$||\textbf{x}||_p = (\sum_{i=1}^N|x_i|^p)^{\frac{1}{p}}$，即向量元素绝对值的p次方和的1/p次幂。 下图展示了 p 取不同值时 unit ball 的形状： 正则化在统计学的缩减中，引入了惩罚项，减少了不重要的参数，同时还可采用正则化（regularization）减少不重要的参数。既然是减少特征，那么最容易想到的就是使用 L0 范数，求回归函数中的参数向量 w 的非零元素的个数。如果约束 $‖w‖_0≤k$，就是约束非零元素个数不大于 k。不过很明显，L0 范数是不连续的且非凸的，如果在线性回归中加上 L0 范数的约束，就变成了一个组合优化问题：挑出 $≤k$ 个系数然后做回归，找到目标函数的最小值对应的系数组合，这是一个 NP 问题。 有趣的是，L1 范数也可以达到稀疏的效果，是 L0 范数的最优凸近似。我们把引入 L1 范数的线性回归叫做 Lasso 回归。 Lasso 回归Lasso 算法（英语：least absolute shrinkage and selection operator，又译最小绝对值收敛和选择算子、套索算法）是一种同时进行特征选择和正则化（数学）的回归分析方法，旨在增强统计模型的预测准确性和可解释性，最初由斯坦福大学统计学教授 Robert Tibshirani 于 1996 年基于 Leo Breiman 的非负参数推断(Nonnegative Garrote, NNG)提出。 优化目标：min $ 1/N\ast\sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} }$ Lasso 回归：min $1/N\ast\sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + \lambda||\omega||_{1}$ Ridge 回归岭回归是加了二阶正则项的最小二乘，主要适用于过拟合严重或各变量之间存在多重共线性的时候，岭回归是有 bias 的，这里的 bias 是为了让 variance 更小。 Ridge 回归：min $1/N\ast\sum_{i = 1}^{N}{(y_{i} -\omega^{T} x_{i})^{2} } + \lambda ||\omega||_{2}^{2} $ 岭回归最先是用来处理特征数多与样本数的情况，现在也用于在估计中加入偏差，从而得到更好的估计。这里引入λ限制了所有w的和，通过引入该惩罚项，能够减少不重要的参数，这个技术在统计学上也叫做缩减。缩减方法可以去掉不重要的参数，因此能更好的理解数据。选取不同的λ进行测试，最后得到一个使得误差最小λ。 缩减方法可以去掉不重要的参数，因此能更好地理解数据。此外，与简单的线性回归相比，缩减法能取得更好的预测效果。 比较两者Lasso 回归与 Ridge 回归有共同点，也有区别。 共同点都能解决两个问题： 线性回归出现的过拟合现象 使用 Normal equation 求解时，解决 $(X^TX)$ 不可逆的问题。 区别岭回归加入的正则项是 L2 范数，其结果可以将偏回归系数往 0 的方向进行压缩，但不会把偏回归系数压缩为 0，即岭回归不会剔除变量。Lasso 回归同样也可以将偏回归系数往 0 方向压缩，但是能够将某些变量的偏回归系数压缩为 0，因此可以起到变量筛选的作用。 红色的椭圆和蓝色的区域的切点就是目标函数的最优解，我们可以看到，如果是圆，则很容易切到圆周的任意一点，但是很难切到坐标轴上，因此没有稀疏；但是如果是菱形或者多边形，则很容易切到坐标轴上，因此很容易产生稀疏的结果。这也说明了为什么 L1 范式会是稀疏的。 ReferenceLasso算法 - 维基百科，自由的百科全书机器学习方法：回归（二）：稀疏与正则约束ridge regression，Lasso]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 7 SVM]]></title>
    <url>%2F2018%2F04%2F14%2FStanford-Machine-Learning-7-SVM%2F</url>
    <content type="text"><![CDATA[SVM 定义支持向量机，因其英文名为 support vector machine，故一般简称 SVM，通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。 函数间隔和几何间隔上图中哪个分类器最好呢？ 符号定义为了方便介绍 SVM，重新定义以下符号。 在logstic回归中我们用0,1代表两个类, 现在我们改用-1,+1, 即 y∈{-1，-1} 在logistic回归中, 我们的 g 是sigmoid函数, 现在改为:g(z)=1, z&gt;=0g(z)=-1, z&lt;0 在logistic回归中, 我们的假设函数为 $h_θ(x)$, 现在改为, h_\theta(x)$h_{x,b}(x)=g(w^{T}x+b)$, 其中w相当于$[θ_1,θ_2,θ_3,…θ_n]^T$, b 相当于 $θ_0$，即截距。 h_{x,b} x=a+b函数间隔(functional margin)对于一个训练样本 $(x^{(i)}, y^{(i)})$，我们定义它到超平面 (w,b) 的函数间隔为: \widehat\gamma=y^{(i)}(w^{T}x^{(i)}+b)我们希望函数间隔越大越好, 即:if $y^{(i)}=1$, want $(w^{T}x^{(i)}+b) \gg 0 $ (&gt;&gt;代表远大于)if $y^{(i)}=-1$, want $(w^{T}x^{(i)}+b) \ll 0$ 函数间隔越大，代表我们对于分类的结果非常确定。 但这里有一个漏洞，即可以在不改变这个超平面的情况下可以让函数间隔任意大，只要我们成比增加 w,b 就可以达到这个目的了。例如，我们将 w 变为 2w， b 变为 2b，那么我们的函数间隔将会是原来的两倍。 所以对于整个训练集, 函数间隔定义为： \widehat\gamma=min{\widehat\gamma^{(i)}}几何间隔(geometric margin)定义对于一个训练样本 $A(x^{(i)}, y^{(i)})$，它到超平面 $w^{T}x^{(i)}+b$ 的几何距离为 $\gamma^{(i)}$。设 B 为 A 在超平面上的投影，易得超平面的法向量为 $\frac{w}{||w||}$，则有 $A=B+\gamma^{(i)}\frac{w}{||w||}$，即 $B = A - \gamma^{(i)}\frac{w}{||w||}$。又因为 B 在超平面上，所以有$w^{T}(x^{(i)} - \gamma^{(i)}\frac{w}{||w||})+b=0$故几何距离为: \gamma^{(i)}=(\frac{w}{||w||})^{T}x^{(i)} + \frac{b}{||w||}定义其几何间隔： \gamma^{(i)}=y^{(i)}[(\frac{w}{||w||})^{T}x^{(i)} + \frac{b}{||w||}]所以对于整个训练集, 几何间隔定义为： \gamma=min{\gamma^{(i)}}可以发现，当 $||w||=1$时，$\widehat\gamma^{(i)}=\gamma^{(i)}$ 最优间隔分类器几何间隔就是在求 $\frac{\widehat\gamma}{||w||}$ 的最小值，可以发现函数间隔 $\widehat\gamma$ 可放大缩小，且其对结果不产生影响，所以不妨设令${\widehat\gamma}=1$。现在，目标函数转为了： max \frac{1}{||w||}, s.t., y^{(i)}(w^{T}x^{(i)}+b)\ge1, i=1,2,3...,n等价于 min{\frac12{||w||^2}}, s.t., y^{(i)}(w^{T}x^{(i)}+b)\ge1, i=1,2,3...,n利用拉格朗日乘子法可得： L(w,b,\alpha)=\frac12{||w||^2}-\sum_{i=1}^{n}\alpha_i[y^{(i)}(w^{T}x^{(i)}+b)-1]令 \theta(w)=\displaystyle\max_{\alpha_i\ge0}L(w, b, \alpha)则目标函数变成了： \displaystyle\min_{w,b}\theta(w)=\displaystyle\min_{w,b}\max_{\alpha_i\ge0}L(w, b, \alpha)=p^\*求解目标函数使用对偶问题求解SVM 中用到了高维映射，将线性不可分的问题映射为线性可分，且映射函数的具体形式无法提前确定，而往往使用核函数映射后，维度 w 会提升很多，甚至至无穷维。在原问题下，求解算法的复杂度与样本维度（w 的维度）相关；在对偶问题下，求解算法的复杂度与样本数量（等于拉格朗日算子 a 的数量）相关。 因此，如果是做线性分类，且样本维度低于样本数量的话，可以在原问题下求解。例如 Liblinear 的线性 SVM 默认做法就是这样的；但如果是做非线性分类，那就会涉及到升维（比如使用高斯核做核函数，其实是将样本升到无穷维），升维后的样本维度往往会远大于样本数量，此时显然在对偶问题下求解会更好。 直接求解原问题有多难？ TBD 使用对偶问题的解法对于不等书约束条件的最优化问题，使用拉格朗日对偶问题来求解。具体介绍见之前的 blog: 拉格朗日乘子法 用 $p^*$ 表示这个问题的最优值，这个问题和我们最初的问题是等价的。不过，把最小和最大的位置交换一下： \displaystyle\max_{\alpha_i\ge0}\min_{w,b}L(w, b, \alpha)=d^*交换以后的问题不再等价于原问题，新问题的最优值用 $d^$ 来表示。并且，有 $d^$ ≤ $p^*$。 第二个问题的最优值 $d^$ 提供了一个第一个问题的最优值 $p^$ 的一个下界。经过论证，原始问题满足强对偶所需要的条件，故这两者相等，所以可以通过求解第二个问题来间接地求解第一个问题。 优化公式要让 L 关于 w 和 b 最小化，分别对 w，b 求偏导数，即令$\frac{∂L}{∂w}$ 和 $\frac{∂L}{∂b}$ 等于零，有： \frac{∂L}{∂w}=w-\sum_{i=1}^{n}\alpha_iy^{(i)}x^{(i)}=0\frac{∂L}{∂b}=\sum_{i=1}^{n}\alpha_iy^{(i)}=0将上式代入： L(w,b,\alpha)=\frac12{||w||^2}-\sum_{i=1}^{n}\alpha_i[y^{(i)}(w^{T}x^{(i)}+b)-1]推导过程如下： 这样求出 $\alpha$ 后即可得到 w 和 b。 现在我们的优化问题变成了如上的形式。对于这个问题，我们有更高效的优化算法，即序列最小优化（SMO）算法。我们通过这个优化算法能得到α，再根据α，我们就可以求解出w和b，进而求得我们最初的目的：找到超平面，即”决策平面”。 SMO 算法https://zhuanlan.zhihu.com/p/29212107https://cloud.tencent.com/developer/article/1076970 核函数如果数据集就是线性不可分的应该怎么处理呢？处理方法是将数据集映射到更高维的空间，变成线性可分的。如下图所示： 一般使用高斯核，但这样会导致映射后的维度非常巨大，也就是 w 的维度很大，这也是为什么要转化为对偶问题来求解的原因，对偶问题的时间复杂度只和数据集的数量有关，与维度无关。 总结 SVMSVM 是神经网络出现之前最好的分类算法。求解 SVM 的过程也就是找到区分正负数据的最优超平面，所以引入了几何间隔的概念。而求解最大的几何间隔的问题即是在不等式约束条件下求解最优解的问题。这就引入了拉格朗日对偶问题，接着针对对偶问题求解，引入快速学习算法 SMO，最终找到超平面。对于原始数据线性不可分的情况，引入核函数映射到高维计算，这其中 SVM 求解过程的时间复杂度与维度无关。 附一个很精髓的 SVM十问十答。 SVM 优缺点优点： 可用于线性/非线性分类 可以解决高维问题，即大型特征空间; 泛化错误率低 结果容易解释 可以避免神经网络结构选择和局部极小点问题 SVM 尽量保持与样本间距离的性质导致它抗攻击的能力更强 缺点： 对参数调节和和函数的选择敏感，原始分类器不加修改仅适用于处理二分类问题 在大规模训练样本下，效率不高 对非线性问题有时很难找到一个合适的核函数 解决多分类问题存在困难 附录点到平面的距离 $d$ 维空间中的超平面由下面的方程确定: $w^Tx+b=0$，其中，$w$ 与 $x$ 都是 $d$ 维列向量， $x=(x_1,x_2,…,x_d)^T$ 为平面上的点， $w=(w_1,w_2,…,w_d)^T$为平面的法向量。$b$ 是一个实数， 代表平面与原点之间的距离。 Reference http://blog.csdn.net/v_july_v/article/details/7624837http://guoze.me/2014/11/26/svm-knowledge/https://pdfs.semanticscholar.org/59ee/e096b49d66f39891eb88a6c84cc89acba12d.pdfhttp://luojinping.com/2018/03/04/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拉格朗日乘子法]]></title>
    <url>%2F2018%2F03%2F04%2F%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%2F</url>
    <content type="text"><![CDATA[拉格朗日乘子法定义在数学中的最优化问题中，拉格朗日乘数法（以数学家约瑟夫·拉格朗日命名）是一种寻找多元函数在其变量受到一个或多个条件的约束时的极值的方法。这种方法可以将一个有n个变量与k个约束条件的最优化问题转换为一个解有n + k个变量的方程组的解的问题。这种方法中引入了一个或一组新的未知数，即拉格朗日乘数，又称拉格朗日乘子，或拉氏乘子，它们是在转换后的方程，即约束方程中作为梯度（gradient）的线性组合中各个向量的系数。 比如，要求 $f(x,y) 在 g(x,y)=c$ 时的最大值时，我们可以引入新变量拉格朗日乘数 $L(x,y,λ)=f(x,y) + λ(g(x,y)-c)$，更一般地，对含n个变量和k个约束的情况，有： L(x_1,x_2, ..., x_n, λ_1,λ_2,...,λ_n)=f(x_1,x_2, ..., x_n) - \sum_{i=1}^{k}λ_ig_i(x_1,x_2, ..., x_n)拉格朗日乘数法所得的极点会包含原问题的所有极值点，但并不保证每个极值点都是原问题的极值点。拉格朗日乘数法的正确性的证明牵涉到偏微分，全微分或链法。 用处现要解决以下问题，在满足 g(x,y)=c 这个等式的前提下，求 f(x,y) 函数的最小值（最大值道理相同）。这样的问题我们在高中的时候就遇到过了，只不过高中时遇到的限制条件 g(x,y)=c 都比较简单，一般而言都可以将 y 用 x 的式子表示出来，然后用变量替换的方法代回 f(x,y) 求解。但是，如果 g(x,y) 的形式过于复杂，或者变量太多时，这种方法就失效了。而拉格朗日乘子法就是解决这类问题的通用策略。 等式约束条件的优化问题解法设 $f(x,y)=x^2+y^2$, 约束条件为： $g(x,y)=xy−1=0$。将三维的 $ f(x,y)$ 图像投影到二维平面上，为下图中红色曲线，也称为 $f(x,y)$ 的等高线。g(x,y) 为图中蓝色曲线。 沿着蓝线往内部的圆走，经过橙色点，此时不是最优解，当走到黑色点时，找到了最优解。此时可认为找到了在蓝线这个限制条件下 $f(x,y )$ 的最低点。 拉格朗日观察到，黑点位置，蓝线与圆是相切的，而橙点位置显然不满足这个性质。且拉格朗日还指出黑点位置蓝线与圆一定是相切的，这正是拉格朗日乘子法的核心。 在最低点，蓝线的切线方向都指向橙线的等高线方向。换句话说，在切点的位置沿蓝线移动很小的一步，都相当于在橙线的等高线上移动，这个时候，可以认为函数值已经趋于稳定了。所以，我们认为这个点的值“可能”是最低（高）的。相切，意味着在切点的位置，等高线和蓝色曲线的等高线方向是平行的，考虑到梯度与等高线垂直，我们可以用两条曲线的梯度平行来求出切点位置（最低点）。 所以有：∇f=λ∇g，其中 λ 表示一个标量，因为我们虽然能保证两个梯度平行，但不能保证它们的长度一样（或者方向相同）。在高维函数中，∇f 表示的是函数在各个自变量方向的偏导。对于上面的例子，我们可以求出函数 f 和 g 的偏导，再根据方程组(1)：$\frac{∂f}{∂x}=λ\frac{∂g}{∂x}$$\frac{∂f}{∂y}=λ\frac{∂g}{∂y}$$g(x,y)=0$ 求解时，使用一个统一的拉格朗日函数：$L(x,y,λ)=f(x,y)+λg(x,y)$，令这个函数偏导为 0，可以得到方程组(2)：$\frac{∂L}{∂x}=\frac{∂f}{∂x}−λ\frac{∂g}{∂x}=0$$\frac{∂L}{∂y}=\frac{∂f}{∂y}−λ\frac{∂g}{∂y}=0$$\frac{∂L}{∂λ}=g(x,y)=0$ 可以发现方程组(2)与方程组(1)一样，联立以上三式即可求出 x, y, λ 的值。 如果是多个约束条件，则拉格朗日函数为：$L(x_1,…,x_n,λ_1,…,λ_k)=f(x1,…,xn)−\sum_{j=1}^{k}λ_jg_j(x_1,…,x_n)$ 进一步理解二维情况下的另一个图示，便于理解两个曲线的梯度变化情况： 根据拉格朗日乘子法的定义，这是一种寻找极值的策略，换句话说，该方法并不能保证找到的一定是最低点或者最高点。事实上，它只是一种寻找极值点的过程，而且，拉格朗日乘子法找到的切点可能不只一个（也就是上面的方程组可能找到多个解），例如下图： 所以联立方程组得到的解为所有极值点，是最优解的必要条件，具体是否为极值点需根据问题本身的具体情况检验. 这个方程组称为等式约束的极值必要条件。如果是凸函数，可以保证最优解是存在的。 已经解决的在等式约束条件下的求函数极值的问题，那不等式约束条件下，应该如何解决呢？ 凸优化在开始不等式约束条件下求解函数极值之前，先了解凸优化和对偶问题。 凸优化的意义 其应用非常广泛，机器学习中很多优化问题都要通过凸优化来求解； 在非凸优化中，凸优化同样起到重要的作用，很多非凸优化问题，可以转化为凸优化问题来解决； 如上引用所述，凸优化问题可以看作是具有成熟求解方法的问题，而其他优化问题则未必。 而在最优化中，凸优化是最为常见而又最为重要的，因为凸优化有一个良好的性质：局部最优是全局最优，这个性质使得我们不需要去证明解是否会收敛到全局最优，或者如何避免局部最优。因此凸优化有广泛应用，在优化问题不是凸的时候，往往也会尝试将其变为凸问题便于求解。 相关定义凸集：定义目标函数和约束函数的定义域。凸函数：定义优化相关函数的凸性限制。凸优化：中心内容的标准描述。凸优化问题求解：核心内容。相关算法，梯度下降法、牛顿法、内点法等。 对偶问题对偶问题是优化问题中非常重要的方法，将一般优化问题转化为凸优化问题，是求解非凸优化问题的有效方法。 对于一般的优化问题，不管其是不是凸的，其对偶问题一定是凸优化问题。 不等式约束条件的优化问题广义拉格朗日函数有不等式约束条件的最优化问题描述如下:$min.:f(x)$$s.t.:$ $g_i(x) ≤ 0, i=1,2,…,p,$ $h_j(x) = 0, j=1,2,…,q,$ $x∈Ω⊂Rn$其中. $f(x)$为目标函数, $g_i(x)≤0,i=1,2,…,p$ 为不等式约束条件, $h_j(x)=0,k=1,2,…,q$为等式约束条件。 引入广义拉格朗日函数： L(x,λ,μ)=f(x)+\sum_{i=1}^{p}μ_ig_i(x)+\sum_{j=1}^{q}λ_jh_j(x)其中，$μ_i\ge0$。 定义原始问题最优解现在，如果把 $L(x,λ,μ)$ 看作是关于 $λ,μ$ 的函数，经过优化(不管用什么方法)，就是确定的值使得 $L(x,λ,μ)$ 取得最大值(此过程中把 $x$ 看做常量)，确定了 $λ,μ$ 的值，就可以得到 $L(x,λ,μ)$ 的最大值，因为 $λ,μ$ 已经确定，显然 $L(x,λ,μ)$ 的最大值就是只和 $x$ 有关的函数，定义这个函数为： \theta_p(x)={max}_{λ,μ:μ_i\ge0}L(x,λ,μ)=L(x,λ,μ)那么定义 $\theta_p(x)$ 的意义在哪里呢？在于其值就是 f(x)，也就是说 $\theta_p(x)=f(x)$。下面证明这个等式。 如果 $x$ 违反了约束条件，即 $g_i(x) &gt; 0$ 或者 $h_j(x) \neq 0$，则容易存在 $μ_i -&gt; +∞$，也容易存在 $λ_j$ 使得 $λ_jh_j(x) -&gt; +∞$，这样显然 $\theta_p(x)$ 是没有最大值的。 如果 $x$ 满足了约束条件，则 $\theta_p(x)={max}_{λ,μ:μ_i\ge0}L(x,λ,μ)={max}_{λ,μ:μ_i\ge0}f(x)=f(x)$，因为 ${max}_{λ,μ:μ_i\ge0}f(x)$ 与 $λ,μ$ 没有关系，所以其等于 $f(x)$。 所以当 $x$ 满足约束条件时，$min_x\theta_p(x)=min_xf(x)$，我们定义 $p^*=min_x\theta_p(x)$ 代表原始问题的最优解。 定义对偶问题定义关于 $λ,μ$ 的函数： \theta_D(λ,μ)={min}_xL(x,λ,μ)其中 ${min}_xL(x,λ,μ)$ 是关于 $x$ 的函数的最小化，确定 $x$ 以后，最小值就只与 $λ,μ$ 有关，所以是一个关于 $λ,μ$ 的函数。 考虑极大化 $\theta_D(λ,μ)$ 即 {max}_{λ,μ:μ_i\ge0}\theta_D(λ,μ)={max}_{λ,μ:μ_i\ge0}{min}_xL(x,λ,μ)，与原始问题最优解的定义很相似，形式上是对称的。定义对偶问题的最优解 $d^*={max}_{λ,μ:μ_i\ge0}\theta_D(λ,μ)$ 对偶问题与原始问题的关系很显然有 $d^ \le p^$，当两个问题的最优解相等时，即 $x^, λ^, μ^$ $d^ = p^*$，称原问题和对偶问题是强对偶的，否则是弱对偶的。 所以为了通过求对偶问题来求原问题，我们希望他们是强对偶的。 当满足以下条件时他们是强对偶的： 原始问题是凸优化问题的时候 原始问题满足 Slater 条件（这一条还可以换成其他条件） 最优解满足 KKT 条件 Slater 条件 若原始问题为凸优化问题，且存在严格满足约束条件的点 x，这里的“严格”是指 $g_i(x)≤0$ 中的“≤”严格取到“&lt;”，即存在 x 满足 $g_i(x)&lt;0 ,i=1,2,…,n$，则存在 $x^∗,α^∗,β^∗$ 使得 $x^∗$ 是原始问题的解， $α^∗,β^∗$ 是对偶问题的解，且满足：$p^∗=d^∗=L(x^∗,α^∗,β^∗)$ 也就是说如果原始问题是凸优化问题并且满足 Slater 条件的话，那么强对偶性成立。需要注意的是，这里只是指出了强对偶成立的一种情况，并不是唯一的情况。例如，对于某些非凸优化的问题，强对偶也成立。SVM 中的原始问题 是一个凸优化问题（二次规划也属于凸优化问题），Slater 条件在 SVM 中指的是存在一个超平面可将数据分隔开，即数据是线性可分的。当数据不可分时，强对偶是不成立的，这个时候寻找分隔平面这个问题本身也就是没有意义了，所以对于不可分的情况预先加个 kernel 就可以了。 KKT条件KKT 条件(Karush-Kuhn-Tucker Conditions)，是指在满足一些有规则的条件下, 一个非线性规划(Nonlinear Programming)问题能有最优化解法的一个必要和充分条件，这是一个广义化拉格朗日乘数的成果。 可以发现最优解要么在 $g_i(x) = 0$ 上，要么在 $g_i(x) &lt; 0$ 范围内，如下图： 定义不等式约束下的拉格朗日函数L： L(x,λ,μ)=f(x)+\sum_{i=1}^{p}μ_ig_i(x)+\sum_{j=1}^{q}λ_jh_j(x)所谓 KKT 最优化条件，就是指上式的最优解$x^*$必须满足下面的条件: 约束条件满足 $g_i(x^)≤0,i=1,2,…,p$, 以及 $h_j(x^)=0,j=1,2,…,q$ $∇f(x^)+\sum_{i=1}^{p}μ_i∇g_i(x^)+\sum_{j=1}^{q}λ_j∇h_j(x^*)=0$, 其中$∇$为梯度算子，也就是 L(x,u,λ) 对 x 求导为 0 $λ_j≠0$ 且不等式约束条件满足 $μ_i≥0$, $μ_ig_i(x^*)=0,i=1,2,…,p$，因为 $g(x)&lt;=0$，如果要满足这个等式，必须 $μ_i=0$ 或者 $g(x)=0$ 第三个式子非常有趣，因为g(x)&lt;=0，如果要满足这个等式，必须$μ_i=0$或者g(x)=0，这是 SVM 的很多重要性质的来源，如支持向量的概念。 KKT条件的推导 总结关于不等式约束条件的优化问题，原问题分两种情况： 原问题是一个凸优化问题，则可以直接应用 KKT 条件来求解 原问题不是一个凸优化问题，则通过对偶问题转化为凸优化问题，在满足强对偶的条件下应用 KKT 条件求解 Reference http://jermmy.xyz/2017/07/27/2017-7-27-understand-lagrange-multiplier/https://www.zhihu.com/question/38586401/answer/134473412https://zhuanlan.zhihu.com/p/27731819http://blog.csdn.net/Mr_KkTian/article/details/53750424http://www.cnblogs.com/mo-wang/p/4775548.htmlhttp://www.hanlongfei.com/convex/2015/11/05/duality/https://www.cnblogs.com/90zeng/p/Lagrange_duality.htmlhttp://bioinfo.ict.ac.cn/~dbu/AlgorithmCourses/Lectures/KKT-examples.pdf]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[导数与微分]]></title>
    <url>%2F2018%2F03%2F04%2F%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86%2F</url>
    <content type="text"><![CDATA[连续设 $y=f(x)$ 在 $x_0$ 有定义，若$\displaystyle\lim_{x\to x_0}{f(x)}=f(x_0)$则函数 $f(x)$ 在点 $x_0$ 处连续。 另外一种定义：在点 $x_0$ 附近，如果自变量的该变量是无穷小时，对应的因变量的该变量也是无穷小，则这个函数在点 $x_0$ 处连续。 通俗地说，所谓“连续”，就是不间断。放到函数上，就是没有“断点”（但是可以有“拐点”）。 二元函数的连续性定义与一元函数类似。 导数定义导数（Derivative）是微积分学中重要的基础概念。一个函数在某一点的导数描述了这个函数在这一点附近的变化率。导数的本质是通过极限的概念对函数进行局部的线性逼近。 导数的几何定义是：曲线上的纵坐标对点的横坐标的导数是曲线在该点的切线的斜率。 导数的物理意义之一是：位移s对时间t的导数是瞬时速度，即 $v=\frac{ds}{dt}$ 可导函数可导定义：（1）设 f(x)在 $x_0$ 及其附近有定义,则当 $\displaystyle\lim_{\Delta{x}\to0}{\frac{f(x_0+\Delta{x})-f(x_0)}{a}}$ 存在, 则称 f(x) 在 $x_0$ 处可导。（2）若对于区间 (a,b) 上任意一点 (x，f(x)) 均可导，则称 f(x) 在 (a，b) 上可导。 左导数：$\displaystyle\lim_{\Delta{x}\to0^-}{\frac{f(x_0+\Delta{x})-f(x_0)}{a}}$右导数：$\displaystyle\lim_{\Delta{x}\to0^+}{\frac{f(x_0+\Delta{x})-f(x_0)}{a}}$ 连续函数可导条件：函数在该点的左右偏导数都存在且相等。即就是一个函数在某一点求极限，如果极限存在，则为可导，若所得导数等于函数在该点的函数值，则函数为连续可导函数，否则为不连续可导函数。 微分在数学中，微分是对函数的局部变化率的一种线性描述。微分可以近似地描述当函数自变量的取值作足够小的改变时，函数的值是怎样改变的。 定义若 y=f(x) 在处可导，则函数的增量，$\Delta{y}=f(x+\Delta{x})-f(x)=f’(x)\Delta{x}+\alpha(\Delta{x})\Delta{x}$其中 $\alpha(\Delta{x})$ 是$\Delta{x}(\Delta{x} \to 0)$ 的高阶无穷小。称 $f’(x)\Delta{x}$ 为 $f(x)$ 在 $x$ 处的微分。而 $f’(x)$ 是 $f(x)$ 在 $x$ 处的导数。 可微设函数$y= f(x)$，若自变量在点x的改变量Δx与函数相应的改变量Δy有关系$Δy=AΔx+ο(Δx)$其中A与Δx无关，则称函数f(x)在点x可微，并称AΔx为函数f(x)在点x的微分，记作dy，即$dy=AΔx$当$x=x_0$时，则记作$dy∣x=x_0$. 可微条件：必要条件：若函数在某点可微，则该函数在该点对x和y的偏导数必存在。充分条件：若函数对x和y的偏导数在这点的某一邻域内都存在，且均在这点连续，则该函数在这点可微。 连续但不可微的例子：魏尔斯特拉斯函数连续，但在任一点都不可微 连续，可导，可微的关系 一元函数：可导必然连续，连续推不出可导，可导与可微等价。 多元函数：可偏导与连续之间没有联系，也就是说可偏导推不出连续，连续推不出可偏导。 多元函数中可微必可偏导，可微必连续，可偏导推不出可微，但若一阶偏导具有连续性则可推出可微。 全微分对于多元函数，如果两个自变量都变化的话，这时候函数的微分就称为全微分。如果函数z=f(x,y)在(x,y)处的全增量$\Delta z=f(x+\Delta x,y+\Delta y)-f(x,y)$可以写成$\Delta z=A\Delta x+B\Delta y+o(\rho)$，取其线性主部，称为二元函数的全微分 $\Delta z=A\Delta x+B\Delta y$ 可以证明全微分又可写成$dz=f_x dx+f_ydy =\frac{\partial z}{\partial x}dx+\frac{\partial z}{\partial y}dy$ 上式又称为全微分的叠加原理。可以这么理解：全增量包含两个部分，$\Delta x$引起的函数值增量和$\Delta y$引起的函数值增量。 一句话感性说全微分其实就在表达曲面在某一点处的切平面。 梯度梯度的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）。 例如：在一元函数 f(x) 中，梯度只能沿 x 轴正方向或负方向，而在二元函数 f(x,y) 中，梯度则是一个二维向量 (∂f/∂x,∂f/∂y)。 梯度一个重要的性质：梯度跟函数等高线是垂直的。证明：假设 Δx，Δy 是两个极小的变化量，根据全微分的知识，可以得到：f(x+Δx,y+Δy)≈f(x,y)+∂f∂xΔx+∂f∂yΔy如果 (Δx,Δy) 是在等高线方向的增量，那么 f(x+Δx,y+Δy)≈f(x,y)，这意味着 ∂f∂xΔx+∂f∂yΔy=0，换句话说，向量 ∇f 和向量 (Δx,Δy) 的内积为 0。所以，梯度和函数的等高线是垂直的。 Referencehttp://jermmy.xyz/2017/07/27/2017-7-27-understand-lagrange-multiplier/]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[概率论知识]]></title>
    <url>%2F2018%2F02%2F25%2F%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[概率论在机器学习中扮演着一个核心角色，因为机器学习算法的设计通常依赖于对数据的概率假设。 随机变量在概率论中扮演着一个重要角色。最重要的一个事实是，随机变量并不是变量，它们实际上是将（样本空间中的）结果映射到真值的函数。我们通常用一个大写字母来表示随机变量。 条件分布条件分布为概率论中用于探讨不确定性的关键工具之一。它明确了在另一随机变量已知的情况下（或者更通俗来说，当已知某事件为真时）的某一随机变量的分布。 正式地，给定$Y=b$时，$X=a$的条件概率定义为： P(X=a|Y=b)= \frac{P(X=a,Y=b)}{P(Y=b)}其中，$P(Y=b)&gt;0$ 独立性在概率论中，独立性是指随机变量的分布不因知道其它随机变量的值而改变。在机器学习中，我们通常都会对数据做这样的假设。例如，我们会假设训练样本是从某一底层空间独立提取；并且假设样例i的标签独立于样例j(i≠j)的特性。从数学角度来说，随机变量X独立于Y，当： P(X)=P(X|Y) 注意，上式没有标明X,Y的取值，也就是说该公式对任意X,Y可能的取值均成立。）利用等式(2)，很容易可以证明如果X对Y独立，那么Y也独立于X。当X和Y相互独立时，记为X⊥Y。对于随机变量X和Y的独立性，有一个等价的数学公式：P(X,Y)=P(X)P(Y) 我们有时也会讨论条件独立，就是当我们当我们知道一个随机变量（或者更一般地，一组随机变量）的值时，那么其它随机变量之间相互独立。正式地，我们说“给定Z，X和Y条件独立”，如果：P(X|Z)=P(X|Y,Z) 或者等价的：P(X,Y|Z)=P(X|Z)P(Y|Z) 链式法则我们现在给出两个与联合分布和条件分布相关的，基础但是重要的可操作定理。第一个叫做链式法则，它可以看做等式(2)对于多变量的一般形式。定理1（链式法则）： P(X1,X2,…,Xn)=P(X1)P(X2|X1)…P(Xn|X1,X2,…,Xn−1)…………(3) 链式法则通常用于计算多个随机变量的联合概率，特别是在变量之间相互为（条件）独立时会非常有用。注意，在使用链式法则时，我们可以选择展开随机变量的顺序；选择正确的顺序通常可以让概率的计算变得更加简单。第二个要介绍的是贝叶斯定理。利用贝叶斯定理，我们可以通过条件概率P(Y|X)计算出P(X|Y)，从某种意义上说，就是“交换”条件。它也可以通过等式(2)推导出。 条件概率条件概率如果 A，B 是条件组 S 下的随机事件，事件 A 发生的概率随事件 B 是否发生而变化，同样，事件 B 发生的概率也随事件 A 是否发生而变化。事件 A 在另外一个事件 B 已经发生条件下的发生概率称为条件概率，表示为P(A|B)，读作「在 B 条件下 A 的概率」。当 P(B) &gt; 0 时，有： P(A|B)= \frac{P(AB)}{P(B)}P.S. 如果 A，B 是独立事件，则 A 发生的概率与 B 无关，那么 $P(A|B) = P(A)$，并且 $P(AB)=P(A)P(B)$。 联合概率联合概率表示两个事件共同发生的概率。A 与 B 的联合概率表示为$P(A\cap B)$ 或者 ${\displaystyle P(A,B)}$ 或者 $P(A,B)$。 边缘概率边缘概率是某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中不需要的那些事件合并成其事件的全概率而消失（对离散随机变量用求和得全概率，对连续随机变量用积分得全概率）。这称为边缘化（marginalization）。A的边缘概率表示为$P(A)$，B的边缘概率表示为$P(B)$。 全概率公式 贝叶斯定理P(X|Y)=\frac{P(Y|X)P(X)}{P(Y)}https://zh.wikipedia.org/wiki/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87http://blog.csdn.net/u012566895/article/details/51220127http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 6 生成学习算法]]></title>
    <url>%2F2018%2F02%2F25%2FStanford-Machine-Learning-6-%E7%94%9F%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[生成学习算法介绍有监督机器学习可以分为判别学习算法(generative learning algorithm)和生成学习算法(discriminative learning algorithm)。 判别学习算法常见的有：逻辑回顾，支持向量机等。 生成学习算法常见的有：混合高斯模型、朴素贝叶斯法和隐形马尔科夫模型等。 判别学习算法是直接学习 p(y|x) 或者是从输入直接映射到输出的算法。 生成学习算法是计算变量x在变量y上的条件分布p(x|y)和变量y的分布p(y) ，然后使用贝叶斯公式: $p(y|x)=\frac{p(x,y)}{p(x)}=\frac{p(y)*p(x|y)}{p(x)}$ 计算出p(y|x)。 针对课程中提到的两种生成学习算法中，高斯判别分析(Gaussian Discriminant Analysis)和朴素贝叶斯(Navie Bayes)分别解决了两种场景下的问题。GDA 是针对的是特征向量 X 为连续值时的问题，而 Navie Bayes 则针对的是特征向量为离散值时的问题。 高斯判别分析多维正态分布(The multivariate normal distribution)假设随机变量 $X$ 满足 $n$ 维的多项正态分布，参数为均值向量 $μ ∈ R^{n} $，协方差矩阵$Σ ∈ R^{n×n}$，记为 $N(μ,Σ)$ 其概率密度表示为： p(x;μ,Σ)=\frac{1}{(2π)^{\frac{n}2}(detΣ)^{\frac12}}exp(−\frac12(x−μ)^TΣ^{−1}(x−μ))$detΣ$ 表示矩阵 $Σ$ 的行列式(determinant)。均值向量: $μ$协方差矩阵: $Σ=E[(X−E[X])(X−E[X])T]=E[(x−μ)(x−μ)T]$ 高斯判别分析GDA 模型针对的是输入特征为连续值时的分类问题，这个模型的基本假设是目标值 y 服从伯努利分布(0-1分布)，条件概率 P(x|y) 服从多元正态分布((multivariate normal distribution))，即:$y∼Bernoulli(\phi)$$P(x|y=0)∼N(μ_0,\Sigma)$$P(x|y=1)∼N(μ_1,\Sigma)$ 它们的概率密度为： p(y)=\phi^y(1−\phi)^{1−y}p(x|y=0)=\frac1{(2π)^{n/2}|\Sigma|^{1/2}}exp(−\frac12(x−μ_0)^T\Sigma^{−1}(x−μ_0))p(x|y=1)=\frac1{(2π)^{n/2}|\Sigma|^{1/2}}exp(−\frac12(x−μ_1)^T\Sigma^{−1}(x−μ_1))我们模型的参数包括，$\phi,\Sigma,μ_0,μ_1$ 注意到，我们使用了两种不同的均值向量$μ_0$和$μ_1$，但是使用了同一种协方差矩阵 $\Sigma$, 则我们的极大似然函数的对数如下所示： L(\phi,μ_0,μ_1,\Sigma)=log\Pi_{i=1}^mp(x^{(i)},y^{(i)};\phi,μ_0,μ_1,\Sigma)=log\Pi_{i=1}^mp(x^{(i)}|y^{(i)};\phi,μ_0,μ_1,\Sigma)p(y^{(i)};\phi)对极大似然函数对数最大化，我们就得到了GDA模型各参数的极大虽然估计(略)。 GDA 与 LR前面我们提到： {argmax}_yp(y|x)={argmax}_y\frac{p(x|y)p(y)}{p(x)}={argmax}_yp(x|y)p(y)我们有： p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1)+p(x|y=0)p(y=0)}上式实际上可以表示成logistic函数的形式： p(y=1|x;ϕ,μ0,μ1,Σ)=\frac1{1+exp(−θ^TX)}其中，θ是参数ϕ,μ0,μ1,Σθ是参数ϕ,μ0,μ1,Σ某种形式的函数。GDA的后验分布可以表示logistic函数的形式。 下图为用 GDA 对两类样本分别拟合高斯概率密度函数p(x|y=0)和p(x|y=1)，得到两个钟形曲线。沿x轴遍历样本，在x轴上方画出相应的p(y=1|x)。如选x轴靠左的点，那么它属于1的概率几乎为0，p(y=1|x)=0，两条钟形曲线交点处，属于0或1的概率相同，p(y=1|x)=0.5，x轴靠右的点，输出1的概率几乎为1，p(y=1|x)=1。最终发现，得到的曲线和sigmoid函数曲线很相似。 实际上，可以证明，不仅仅当先验概率分布服从多变量正态分布时可以推导出逻辑回归的模型，当先验分布属于指数分布簇中的任何一个分布，如泊松分布时，都可以推导出逻辑回归模型。而反之不成立，逻辑回归的先验概率分布不一定必须得是指数分布簇中的成员。基于这些原因，在实践中使用逻辑回归比使用GDA更普遍。 生成学习算法比判决学习算法需要更少的数据。如GDA的假设较强，所以用较少的数据能拟合出不错的模型。而逻辑回归的假设较弱，对模型的假设更为健壮，拟合数据需要更多的样本。 朴素贝叶斯考虑自变量比较多的情况，比如垃圾邮件的识别需要检测成百上千甚至上万的字符是否出现，如有免费、购买等类似的词出现的邮件很大可能是垃圾邮件。这种情况下若有k个自变量，考虑各变量之间的交互作用就需要计算$2^k$次，为了简化计算量对模型作一个更强的假设：给定因变量 y 的值，各自变量之间相互独立. 所以有 p(x_1,...,x_n|y)=p(x_1|y)p(x_2|y,x_1)p(x_3|y,x_1,x_2)...p(x_n|y,x_1,x_2,...,x_{n-1})=p(x_1|y)p(x_2|y)p(x_3|y)…p(x_n|y)=\Pi_{i=1}^np(x_i|y)第一个等式是根据通常的概率论得到的，第二个等式是根据贝叶斯假设得到的。虽然贝叶斯假设是个很强的假设，但是实践证明在许多问题上都表现得很好。 参数的极大似然估计及p(y|x)的推导过程略。 拉普拉斯平滑拉普拉斯平滑(Laplace Smoothing)又称为加1平滑。平滑方法的存在是为了解决零概率问题。 所谓的零概率问题，就是在计算新实例的概率时，如果某个分量在训练集中从没出现过，会导致整个实例的概率计算结果为０，针对文本分类问题就是当一个词语在训练集中没有出现过，那么该词语的概率为０，使用连乘计算文本出现的概率时，整个文本出现的概率也为０，这显然不合理，因为不能因为一个事件没有观测到就判断该事件的概率为０. Referencehttp://xtf615.com/2017/03/25/%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95/http://blog.csdn.net/v1_vivian/article/details/52190572http://www.cnblogs.com/mikewolf2002/p/7763475.html]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-Binary-Tree-Maximum-Path-Sum]]></title>
    <url>%2F2018%2F01%2F31%2FLeetCode-Binary-Tree-Maximum-Path-Sum%2F</url>
    <content type="text"><![CDATA[Problem DescriptionGiven a binary tree, find the maximum path sum. For this problem, a path is defined as any sequence of nodes from some starting node to any node in the tree along the parent-child connections. The path must contain at least one node and does not need to go through the root. For example:Given the below binary tree,123 1 / \2 3 Return 6. problem link: https://leetcode.com/problems/binary-tree-maximum-path-sum/description/ Solution1234567891011121314151617public class Solution &#123; int maxValue; public int maxPathSum(TreeNode root) &#123; maxValue = Integer.MIN_VALUE; maxPathDown(root); return maxValue; &#125; private int maxPathDown(TreeNode node) &#123; if (node == null) return 0; int left = Math.max(0, maxPathDown(node.left)); int right = Math.max(0, maxPathDown(node.right)); maxValue = Math.max(maxValue, left + right + node.val); return Math.max(left, right) + node.val; &#125;&#125; 解题思路每一个结点可以选和不选，处理方法就是：int left = Math.max(0, maxPathDown(node.left));，其中的 Math.max(0, x)，当取值为 0 时就是不取这个结点。 全局变量 maxValue 就覆盖了子树中的 ^ 这种类型，例如子树如下： 123 x a yb c 则 b-&gt;a-&gt;c 这种路径的最大值被 maxValue 保存了。而 b-&gt;a-&gt;x-&gt;y 这种经过根节点的路径被 Math.max(left, right) + node.val; 覆盖了。]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode-Trapping-Rain-Water]]></title>
    <url>%2F2018%2F01%2F31%2FLeetCode-Trapping-Rain-Water%2F</url>
    <content type="text"><![CDATA[Problem DescriptionGiven n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining. For example,Given [0,1,0,2,1,0,1,3,2,1,2,1], return 6. problem link: https://leetcode.com/problems/trapping-rain-water Solution12345678910111213141516171819202122public class TrappingRainWater_42 &#123; public int trap(int[] height) &#123; int a = 0; int b = height.length - 1; int max = 0; int leftMax = 0; int rightMax = 0; while (a &lt;= b) &#123; leftMax = Math.max(leftMax, height[a]); rightMax = Math.max(rightMax, height[b]); if (leftMax &lt; rightMax) &#123; // leftMax is smaller than rightMax, so the (leftMax-A[a]) water can be stored max += (leftMax - height[a]); a++; &#125; else &#123; max += (rightMax - height[b]); b--; &#125; &#125; return max; &#125;&#125; 算法解释对任意位置 i，在 i 上的积水，由左右两边最高的 bar 决定。]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka Consumer 的实现]]></title>
    <url>%2F2017%2F11%2F12%2FKafka-Consumer-%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[_说明: kafka 版本号为 0.11.0_ Consumer 拉取消息的实现在 Kafka Consumer 正常消费时，观察其调用堆栈。 1234567891011"pool-16-thread-7" #154 prio=5 os_prio=0 tid=0x00007ff581c8c000 nid=0x326d runnable [0x00007ff5468e7000] java.lang.Thread.State: RUNNABLE ... at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:433) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:232) - locked &lt;0x00000000c2e04f90&gt; (a org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:208) at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1096) at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1043) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:571) ... 对应的代码实现是 org.apache.kafka.clients.consumer.KafkaConsumer#poll，如下：123456789101112131415161718192021222324252627@Override public ConsumerRecords&lt;K, V&gt; poll(long timeout) &#123; ... try &#123; ... // poll for new data until the timeout expires long start = time.milliseconds(); long remaining = timeout; do &#123; Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollOnce(remaining); if (fetcher.sendFetches() &gt; 0 || client.hasPendingRequests()) client.pollNoWakeup(); if (this.interceptors == null) return new ConsumerRecords&lt;&gt;(records); else return this.interceptors.onConsume(new ConsumerRecords&lt;&gt;(records)); long elapsed = time.milliseconds() - start; remaining = timeout - elapsed; &#125; while (remaining &gt; 0); return ConsumerRecords.empty(); &#125; finally &#123; release(); &#125; &#125; 其中 org.apache.kafka.clients.consumer.KafkaConsumer#pollOnce的实现如下：12345678910111213141516private Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(long timeout) &#123; ... // ConsumerCoordinator coordinator; coordinator.poll(time.milliseconds(), timeout); ... // if data is available already, return it immediately Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords(); if (!records.isEmpty()) return records; // send any new fetches (won't resend pending fetches) fetcher.sendFetches(); ... return fetcher.fetchedRecords(); &#125; 所以可以看到 consumer 每次 poll 时是先从 fetcher 中 fetchedRecords 的，如果拿不到结果，就新发起一个 sendFetches 请求。 Consumer 拉取消息的数量在 org.apache.kafka.clients.consumer.internals.Fetcher#fetchedRecords 可以看到 maxPollRecords(max.poll.records 配置) 变量限制了每次 poll 的消息条数，不管 consumer 对应多少个 partition，从所有 partition 拉取到的消息条数总和不会超过 maxPollRecords。 在 org.apache.kafka.clients.consumer.internals.Fetcher#sendFetches 可以看到 fetchSize(max.partition.fetch.bytes 配置) 用于每次创建 FetchRequest 时的 org.apache.kafka.common.requests.FetchRequest.PartitionData 的参数设置。fetchSize限制了 consumer 每次从每个 partition 拉取的数据量。不过，还是看代码中的 ConsumerConfig#MAX_PARTITION_FETCH_BYTES_DOC 说明吧： The maximum amount of data per-partition the server will return. Records are fetched in batches by the consumer. If the first record batch in the first non-empty partition of the fetch is larger than this limit, the batch will still be returned to ensure that the consumer can make progress. The maximum record batch size accepted by the broker is defined via message.max.bytes (broker config) or max.message.bytes (topic config). See “ + FETCH_MAX_BYTES_CONFIG + “ for limiting the consumer request size. poll 和 fetch 的关系在满足max.partition.fetch.bytes限制的情况下，假如fetch到了100个record，放到本地缓存后，由于max.poll.records限制每次只能poll出15个record。那么KafkaConsumer就需要执行7次才能将这一次通过网络发起的fetch请求所fetch到的这100个record消费完毕。其中前6次是每次pool中15个record，最后一次是poll出10个record。 Consumer 的心跳机制在 org.apache.kafka.clients.consumer.internals.AbstractCoordinat 中启动 HeartbeatThread 线程来定时发送心跳和检查 consumer 的状态。每个 Consumer 都有一个 ConsumerCoordinator(继承 AbstractCoordinator)，每个 ConsumerCoordinator 都启动一个 HeartbeatThread 线程来维护心跳，心跳信息存放在 org.apache.kafka.clients.consumer.internals.Heartbeat。 实现如下：1234567891011121314151617181920212223242526272829303132@Overridepublic void run() &#123; try &#123; log.debug("Heartbeat thread for group &#123;&#125; started", groupId); while (true) &#123; synchronized (AbstractCoordinator.this) &#123; ... client.pollNoWakeup(); long now = time.milliseconds(); if (coordinatorUnknown()) &#123; ... &#125; else if (heartbeat.sessionTimeoutExpired(now)) &#123; // the session timeout has expired without seeing a successful heartbeat, so we should // probably make sure the coordinator is still healthy. coordinatorDead(); &#125; else if (heartbeat.pollTimeoutExpired(now)) &#123; // the poll timeout has expired, which means that the foreground thread has stalled // in between calls to poll(), so we explicitly leave the group. maybeLeaveGroup(); &#125; else if (!heartbeat.shouldHeartbeat(now)) &#123; // poll again after waiting for the retry backoff in case the heartbeat failed or the // coordinator disconnected AbstractCoordinator.this.wait(retryBackoffMs); &#125; else &#123; heartbeat.sentHeartbeat(now); ... &#125; &#125; // end synchronized &#125; // end while &#125; //end try &#125; // end run 其中最重要的两个 timeout 函数：1234567public boolean sessionTimeoutExpired(long now) &#123; return now - Math.max(lastSessionReset, lastHeartbeatReceive) &gt; sessionTimeout;&#125;public boolean pollTimeoutExpired(long now) &#123; return now - lastPoll &gt; maxPollInterval;&#125; sessionTimeout如果是 sessionTimeout 则 Mark the current coordinator as dead，此时 会将 consumer 踢掉，重新分配 partition 和 consumer 的对应关系。 在 Kafka Server 端，Consumer 的 Group 定义了五个状态：： pollTimeout如果是 pollTimeout 则 Reset the generation and memberId because we have fallen out of the group，此时 consumer 会退出 group，当再次 poll 时又会 rejoin group 触发 rebalance group。 Rebalance Generation表示 rebalance 之后的一届成员，主要是用于保护 consumer group，隔离无效 offset 提交。每次 group 进行 rebalance 之后，generation 号都会加 1，表示 group 进入到了一个新的版本，下图所示为 consumer 2 退出后 consumer 4 加入时 Rebalance Generation 的过程： partition 的数量设置 一个 partition 只能被 Consumer Group 中的一个 consumer 消费，因此，为了提高并发量，可以提高 partition 的数量，但是这会造成 replica 副本拷贝的网络请求增加，故障恢复时的耗时增加。因为 kafka 使用 batch pull 的方式，所以单个线程的消费速率还是有保障的。并且 partition 数量过多，zk 维护 ISR 列表负载较重。 partiton 数量最好是 consumer 数目的整数倍，比如取 24， consumer 数目的设置就会灵活很多。 consumer 消费消息时不时严格有序的。当从多个 partition 读数据时，kafka 只保证在一个 partition 上数据是有序的，多个 partition 的消息消费很可能就不是严格有序的了。 参数设置heartbeat.interval.ms心跳间隔。心跳是在 consumer 与 coordinator 之间进行的。心跳是确定 consumer 存活，加入或者退出 group 的有效手段。这个值必须设置的小于 session.timeout.ms，因为：当 consumer 由于某种原因不能发 heartbeat 到 coordinator 时，并且时间超过 session.timeout.ms 时，就会认为该 consumer 已退出，它所订阅的 partition 会分配到同一 group 内的其它的 consumer 上。 参数值默认值：3000 (3s)，通常设置的值要低于session.timeout.ms的1/3。 session.timeout.msconsumer session 过期时间。如果超时时间范围内，没有收到消费者的心跳，broker 会把这个消费者置为失效，并触发消费者负载均衡。因为只有在调用 poll 方法时才会发送心跳，更大的 session 超时时间允许消费者在 poll 循环周期内处理消息内容，尽管这会有花费更长时间检测失效的代价。如果想控制消费者处理消息的时间， 参数值默认值：10000 (10s)，这个值必须设置在 broker configuration 中的 group.min.session.timeout.ms 与 group.max.session.timeout.ms 之间。 max.poll.interval.msThis config sets the maximum delay between client calls to poll(). When the timeout expires, the consumer will stop sending heartbeats and send an explicit LeaveGroup request. As soon as the consumer resumes processing with another call to poll(), the consumer will rejoin the group. By increasing the interval between expected polls, you can give the consumer more time to handle a batch of records returned frompoll(long). The drawback is that increasing this value may delay a group rebalance since the consumer will only join the rebalance inside the call to poll. You can use this setting to bound the time to finish a rebalance, but you risk slower progress if the consumer cannot actually call poll often enough. 参数设置大一点可以增加两次 poll 之间处理消息的时间。当 consumer 一切正常(也就是保持着 heartbeat )，且参数的值小于消息处理的时长，会导致 consumer leave group 然后又 rejoin group，触发无谓的 group balance，出现 consumer livelock 现象。 但如果设置的太大，会延迟 group rebalance，因为消费者只会在调用 poll 时加入rebalance。 max.poll.recordsUse this setting to limit the total records returned from a single call to poll. This can make it easier to predict the maximum that must be handled within each poll interval. By tuning this value, you may be able to reduce the poll interval, which will reduce the impact of group rebalancing. 0.11.0 Kafka 的默认配置是 max.poll.interval.ms=5min max.poll.records=500 即平均 600ms 要处理完一条消息，如果消息的消费时间高于 600ms，则一定要调整 max.poll.records 或 max.poll.interval.ms。 Kafka Javadoc - Detecting Consumer FailuresAfter subscribing to a set of topics, the consumer will automatically join the group when poll(long) is invoked. The poll API is designed to ensure consumer liveness. As long as you continue to call poll, the consumer will stay in the group and continue to receive messages from the partitions it was assigned. Underneath the covers, the consumer sends periodic heartbeats to the server. If the consumer crashes or is unable to send heartbeats for a duration of session.timeout.ms, then the consumer will be considered dead and its partitions will be reassigned.It is also possible that the consumer could encounter a “livelock” situation where it is continuing to send heartbeats, but no progress is being made. To prevent the consumer from holding onto its partitions indefinitely in this case, we provide a liveness detection mechanism using the max.poll.interval.ms setting. Basically if you don’t call poll at least as frequently as the configured max interval, then the client will proactively leave the group so that another consumer can take over its partitions. When this happens, you may see an offset commit failure (as indicated by a CommitFailedException thrown from a call to commitSync()). This is a safety mechanism which guarantees that only active members of the group are able to commit offsets. So to stay in the group, you must continue to call poll. ReferenceKafka消费组(consumer group)kafka.apache.org javadocCoordinator实现原理kafka paramskafka源码分析之kafka的consumer的负载均衡管理Group Management ProtocolKafka 之 Group 状态变化分析及 Rebalance 过程KIP-62: Allow consumer to send heartbeats from a background threadKafka: The Definitive Guide Chapter 4 - Kafka Consumers]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 Kafka Consumer 卡顿的问题]]></title>
    <url>%2F2017%2F11%2F12%2F%E8%A7%A3%E5%86%B3-Kafka-Consumer-%E5%8D%A1%E9%A1%BF%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[运行环境说明_kafka 版本号为 0.11.0_ Kafka Consumer 的参数配置如下： 12345678910111213141516private Map&lt;String, Object&gt; getDefaultConsumerConfigs() &#123; Map&lt;String, Object&gt; propsMap = new HashMap&lt;&gt;(); // 手动设置自动提交为false,交由 spring-kafka 启动的invoker执行提交 propsMap.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); propsMap.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "30000"); propsMap.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, "10000"); propsMap.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); propsMap.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); // 从partition中获取消息最大大小 propsMap.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, "102400"); return propsMap; &#125; Consumer 卡顿现象Consumer 卡顿时的日志每次卡顿不消费时都出现以下日志：123456789101112131415161718192017/11/09 19:35:29:DEBUG pool-16-thread-10 org.apache.kafka.clients.consumer.internals.Fetcher - Fetch READ_UNCOMMITTED at offset 11429299 for partition my_topic-27 returned fetch data (error=NONE, highWaterMark=11429299, lastStableOffset = -1, logStartOffset = 10299493, abortedTransactions = null, recordsSizeInBytes=0) 2017/11/09 19:35:29:DEBUG pool-16-thread-10 org.apache.kafka.clients.consumer.internals.Fetcher - Added READ_UNCOMMITTED fetch request for partition my_topic-27 at offset 11429299 to node p-kafka-host-03.ali.keep:9092 (id: 6 rack: null) 2017/11/09 19:35:29:DEBUG pool-16-thread-10 org.apache.kafka.clients.consumer.internals.Fetcher - Sending READ_UNCOMMITTED fetch for partitions [my_topic-27] to broker p-kafka-host-03.ali.keep:9092 (id: 6 rack: null) 2017/11/09 19:35:29:DEBUG kafka-coordinator-heartbeat-thread | myConsumerGroup org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending Heartbeat request for group myConsumerGroup to coordinator p-kafka-host-02:9092 (id: 2147483642 rack: null)2017/11/09 19:35:29:DEBUG pool-16-thread-13 org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Attempt to heartbeat failed for group myConsumerGroup since it is rebalancing.2017/11/09 19:35:29:INFO pool-16-thread-13 org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [my_topic-18] for group myConsumerGroup2017/11/09 19:35:29:INFO pool-16-thread-13 org.springframework.kafka.listener.ConcurrentMessageListenerContainer - partitions revoked: [my_topic-18]2017/11/09 19:35:29:INFO pool-16-thread-13 org.springframework.kafka.listener.ConcurrentMessageListenerContainer - partitions revoked: [my_topic-18]2017/11/09 19:35:29:DEBUG pool-16-thread-4 org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Attempt to heartbeat failed for group myConsumerGroup since it is rebalancing.2017/11/09 19:35:29:INFO pool-16-thread-4 org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [my_topic-21] for group myConsumerGroup2017/11/09 19:35:29:INFO pool-16-thread-4 org.springframework.kafka.listener.ConcurrentMessageListenerContainer - partitions revoked: [my_topic-21]2017/11/09 19:35:29:INFO pool-16-thread-4 org.springframework.kafka.listener.ConcurrentMessageListenerContainer - partitions revoked: [my_topic-21]...2017/11/09 19:35:29:DEBUG pool-16-thread-4 org.apache.kafka.clients.consumer.internals.Fetcher - Fetch READ_UNCOMMITTED at offset 11426689 for partition my_topic-21 returned fetch data (error=NONE, highWaterMark=11426689, lastStableOffset = -1, logStartOffset = 10552294, abortedTransactions = null, recordsSizeInBytes=0) 2017/11/09 19:35:29:DEBUG pool-16-thread-13 org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Group myConsumerGroup committed offset 11429849 for partition my_topic-18 2017/11/09 19:35:29:INFO pool-16-thread-13 org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group myConsumerGroup 2017/11/09 19:35:29:DEBUG pool-16-thread-13 org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Sending JoinGroup ((type: JoinGroupRequest, groupId=myConsumerGroup, sessionTimeout=30000, rebalanceTimeout=300000, memberId=p-my-consumer-host-03-12-97c12fb0-9bb7-4762-8478-538f06be9e90, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@54371fac)) to coordinator p-kafka-02.ali.keep:9092 (id: 2147483642 rack: null) 其中最重要的部分是： 2017/11/09 19:35:29:DEBUG pool-16-thread-13 org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Attempt to heartbeat failed for group myConsumerGroup since it is rebalancing.2017/11/09 19:35:29:INFO pool-16-thread-13 org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [my_topic-18] for group myConsumerGroup2017/11/09 19:35:29:INFO pool-16-thread-13 org.springframework.kafka.listener.ConcurrentMessageListenerContainer - partitions revoked: [my_topic-18]…2017/11/09 19:35:29:INFO pool-16-thread-13 org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group myConsumerGroup 那为什么每次会这样呢？我们是有单独的线程在发起心跳的！!! Consumer 卡顿时的 jstack观察日志可以发现，卡顿时 ConsumerCoordinator 在不停地 rejoin group，并且做 rebalance，所以需要对比在正常和卡顿这两种情况下 ConsumerCoordinator 的行为。 正常时的 ConsumerCoordinator123cat jstack.normal.log | grep ConsumerCoordinator -B1 | grep -v ConsumerCoordinator | sort | uniq -c32 at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:931)22 at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:950) 卡顿时的 ConsumerCoordinator12345cat jstack.pause.log | grep ConsumerCoordinator -B1 | grep -v ConsumerCoordinator | sort | uniq -c14 at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:316)14 at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:920)8 at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:931)32 at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:950) 根据以上的现场信息，可以发现关键就在 AbstractCoordinator.ensureActiveGroup 这一步，继续观察 jstack.pause.log 中的相关堆栈信息，如下：12345678910111213141516171819202122232425262728"pool-16-thread-14" #167 prio=5 os_prio=0 tid=0x00007f5b19dbf000 nid=0x7ac2 runnable [0x00007f5ae4ccb000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000000c2e816b0&gt; (a sun.nio.ch.Util$2) - locked &lt;0x00000000c2e816a0&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000000c2e742a0&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at org.apache.kafka.common.network.Selector.select(Selector.java:529) at org.apache.kafka.common.network.Selector.poll(Selector.java:321) at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:433) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:232) - locked &lt;0x00000000c2f00da0&gt; (a org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:208) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:168) at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:364) at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:316) at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:297) at org.apache.kafka.clients.consumer.KafkaConsumer.pollOnce(KafkaConsumer.java:1078) at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1043) at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:571) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) 卡顿原因分析卡顿原因：Consumer 在 Region Group根据以上信息，结合 org.apache.kafka.clients.consumer.internals.ConsumerCoordinator 的代码可以发现在ConsumerCoordinator#poll 中判断 needRejoin() 为 true 时会调用 ensureActiveGroup() 函数，如下：1234567891011121314151617public void poll(long now, long remainingMs) &#123; invokeCompletedOffsetCommitCallbacks(); if (subscriptions.partitionsAutoAssigned()) &#123; ... if (needRejoin()) &#123; ... ensureActiveGroup(); ... &#125; &#125; else &#123; ... &#125; &#125; pollHeartbeat(now); maybeAutoCommitOffsetsAsync(now); &#125; Region Group 原因：Consumer Leave Group那么问题就是什么情况下 org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#needRejoin 会返回 true，我们还是看看他的实现：123456789101112131415@Override public boolean needRejoin() &#123; if (!subscriptions.partitionsAutoAssigned()) return false; // we need to rejoin if we performed the assignment and metadata has changed if (assignmentSnapshot != null &amp;&amp; !assignmentSnapshot.equals(metadataSnapshot)) return true; // we need to join if our subscription has changed since the last join if (joinedSubscription != null &amp;&amp; !joinedSubscription.equals(subscriptions.subscription())) return true; return super.needRejoin(); &#125; kafka metadata 什么时候变化？？？？可以看到，不是 metadataSnapshot 有变化，也不是 订阅者 subscriptions 有变化，那就是 super.needRejoin() 返回了 true，问题就转到了 org.apache.kafka.clients.consumer.internals.AbstractCoordinator#needRejoin 这个函数，其实现是：123protected synchronized boolean needRejoin() &#123; return rejoinNeeded;&#125; 从代码上看 rejoinNeeded 的整个变化过程，初始化为 true，在 initiateJoinGroup 成功后，会赋值为 false，在 maybeLeaveGroup 时会赋值为 true，所以怀疑卡顿时是 consumer leave group 了。 Consumer Leave Group 原因：pollTimeoutExpired在 org.apache.kafka.clients.consumer.internals.AbstractCoordinator.HeartbeatThread#run 中调用了 maybeLeaveGroup() 函数，其实现如下：1234567891011121314151617181920212223242526272829303132@Overridepublic void run() &#123; try &#123; log.debug("Heartbeat thread for group &#123;&#125; started", groupId); while (true) &#123; synchronized (AbstractCoordinator.this) &#123; ... client.pollNoWakeup(); long now = time.milliseconds(); if (coordinatorUnknown()) &#123; ... &#125; else if (heartbeat.sessionTimeoutExpired(now)) &#123; // the session timeout has expired without seeing a successful heartbeat, so we should // probably make sure the coordinator is still healthy. coordinatorDead(); &#125; else if (heartbeat.pollTimeoutExpired(now)) &#123; // the poll timeout has expired, which means that the foreground thread has stalled // in between calls to poll(), so we explicitly leave the group. maybeLeaveGroup(); &#125; else if (!heartbeat.shouldHeartbeat(now)) &#123; // poll again after waiting for the retry backoff in case the heartbeat failed or the // coordinator disconnected AbstractCoordinator.this.wait(retryBackoffMs); &#125; else &#123; heartbeat.sentHeartbeat(now); ... &#125; &#125; // end synchronized &#125; // end while &#125; //end try &#125; // end run 其中最重要的两个 timeout 函数：1234567public boolean sessionTimeoutExpired(long now) &#123; return now - Math.max(lastSessionReset, lastHeartbeatReceive) &gt; sessionTimeout;&#125;public boolean pollTimeoutExpired(long now) &#123; return now - lastPoll &gt; maxPollInterval;&#125; 所以是 pollTimeoutExpired 引起了 leave group. 根本原因：pollTimeoutExpiredpollTimeoutExpired 的原因是两次 poll 的时间间隔超过了设置的 maxPollInterval 值。 解决方案调整以下参数 max.poll.records：100 (默认值 500) max.poll.interval.ms：600000 (默认值 300000，也就是5分钟) 后续至此，问题已经解决了，但是有一些疑问。 对于这两个参数值的设定， 是 max.poll.records 越小越好，max.poll.interval.ms 越大越好吗？ 已经设置过的 session.timeout.ms 和 heartbeat.interval.ms难道没用吗？为什么有这么多超时参数的设置啊？ 已经设置过的 max.partition.fetch.bytes 没用吗？为什么还要设置 max.poll.records 啊？ 整体上还需要调哪些参数才可以让 consumer 运行正常，或者是性能达到最大呢？ 在下一篇博客「Kafka Consumer 的实现」中，将会继续分析 Kafka Consumer 的消费过程和参数配置，试图回答以上问题。]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 5 广义线性模型]]></title>
    <url>%2F2017%2F11%2F05%2FStanford-Machine-Learning-5-%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[指数分布族(Exponential Family)指数分布族的定义若一类概率分布可以写成如下形式，那么它就属于指数分布族： P(y;\eta) = b(y)exp(\eta^TT(y)-a(\eta)) $\eta$: 自然参数，通常是一个实数 T(y): 充分统计量，通常，T(y)=y，实际上是一个概率分布的充分统计量（统计学知识） a($\eta$) 被称为 log partition function 对于给定的 a，b，T 三个函数，上式定义了一个以 $\eta$ 为参数的概率分布集合，即改变 $\eta$ 可以得到不同的概率分布，例如高斯分布和伯努利分布。 指数分布族以及它们的特征 正态分布（高斯分布）——总体噪音（由中心极限定理得） 伯努利分布——逻辑回归（对01问题建模） 多项式分布——K种结果的事情进行建模 泊松分布——对计数过程进行建模（一个样本中放射性衰变的数目，网站的访客数目，商店的顾客数目） 伽马分布，指数分布——正数的分布，对间隔进行建模（在公交车站等车的时间） β分布，Dirichlet分布——对小数进行分布，对概率分布进行建模 Wishart分布——协方差的分布 指数分布簇推导高斯分布(Gaussian)和伯努利(Bernoulli)分布都可以推导为指数分布族。 伯努利分布的推导伯努利分布的概率公式为：$P(y=1;\phi)=\phi; P(y=0;\phi)=1-\phi;$ 公式可经如下变换： P(y;\phi)=\phi^y(1-\phi)^y=exp(log(\phi^y(1-\phi)^y))=exp(ylog(\phi)+ (1-y)log(1-\phi))=exp(log(\frac\phi{1-\phi})y + log(1-\phi))对应的指数分布族的参数为：$T(y) = y$$b(y) = 1$$\eta = log(\frac\phi{1-\phi}) =&gt; \phi=\frac1{1+e^{-n}}$$a(\eta) = -log(1-\phi) = log(1+e^n)$ 高斯分布的推导在线性回归中，$\sigma$ 对于模型参数 $\theta$ 的选择没有影响，为了推导方便我们令 $\sigma = 1$。则有： P(y;\mu)=\frac{1}{\sqrt{2\pi}}exp(-\frac12(y-\mu)^2)=\frac{1}{\sqrt{2\pi}}exp(-\frac{1}{2}y^2) * exp({\mu}y-\frac{1}{2}\mu^2)对应的指数分布族的参数为：$T(y) = y$$b(y) = \frac{1}{\sqrt{2\pi}}exp(-\frac12y^2)$$\eta = \mu$$a(\eta) = \frac{ {\mu}^2}2 = \frac{ {\eta}^2}2$ 广义线性模型(Generalized Linear Model)想用 广义线性模型对一般问题进行建模首先需要明确几个 假设： $y | x;θ \sim ExponentialFamily(\eta)$ y的条件概率属于指数分布族; 给定 x 广义线性模型的目标是求解 T(y) | x， 不过由于 很多情况下 T(y) = y 所以我们的目标变成了 y | x , 也即 我们希望拟合函数为 h(x) = E[y|x] (这个条件在线性回归和逻辑回归中都满足， 例如在逻辑回归中 $hθ(x) = p(y = 1|x;\theta) = 0 \cdot p(y = 0|x; \theta) + 1 \cdot p(y = 1|x; \theta) = E[y|x;\theta])$ 自然参数 $\eta$ 与 x 是线性关系：$\eta=\theta^Tx$ ($\eta 为向量时 \eta_{i} = \theta_{i}^Tx$) 有了如上假设，就可以进行建模和求解了。 对于伯努利分布，可以推导出：…这也就是逻辑回归中 sigmod 函数的由来。 多分类算法(Softmax Regression)y有多个可能的分类：{1, 2, …, k} =======具体的公式略======= 最后求借寻找最佳参数时，跟最小二乘和逻辑回归的解法类似，可以用梯度下降法或者牛顿迭代法。 Referecen广义线性模型(Generalized Linear Model)]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 4 逻辑回归]]></title>
    <url>%2F2017%2F11%2F05%2FStanford-Machine-Learning-4-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[逻辑回归对于逻辑回归而言，y 的取值不是 0 就是 1，所以 $h_θ(x)$ 可以写为 h_θ(x) = g(θ^{T}x)=\frac1{1+e^{-θ^{T}x}}其中 g(z)=\frac1{1+e^{-z}}$$； g(z) 被称为 logistic function 或 sigmoid function，其二维坐标下的曲线为: ![sigmoid function](/img/sigmoid_function.png) 我们先取 g(z) 为 sigmoid function，如果有其他使得 y 值从 0 到 1 平滑递增的函数也可以使用。但由于一些列原因(在后续的一般化回归模型 GLM 中会谈到为什么选用这个函数)，g(z) is a fairly natural one. g(z) 的导数我们可以先进行推导: $$g'(z)=\frac{d}{dz}\frac{1}{1+e^{-z}}= \frac{1}{(1+e^{-z})^2}(e^{-z})= \frac{1}{1+e^{-z}}*(1 - \frac{1}{1+e^{-z}})= g(z)(1-g(z))梯度上升法求解逻辑回归对于给定的逻辑回归函数，我们使用最小二乘法来推导出最大似然估计，假设:$P(y=1|x;θ)=h_θ(x)$，代表对于给定的 θ，y 取值为 1 的概率。$P(y=0|x;θ)=1-h_θ(x)$，代表对于给定的 θ，y 取值为 0 的概率。 以上两者可以合并为： P(y|x;θ)=(h_θ(x))^y(1 − h_θ(x))^{(1−y)}假设 m 个训练集是相互独立的，则似然估计为： L(θ)=P(\overrightarrow{y}|X;θ)= \prod^m_{i=1}P(y^i|x^i;θ)= \prod^m_{i=1}{(h_θ(x^{(i)}))^{y^{(i)}}(1 − h_θ(x^{(i)}))^{(1−y^{(i)})}}和之前一样，上式可以简化为： $l(θ) = logL(θ)= \sum_{m}^{i=1}{y^{(i)}}log{h(x^{(i)}) + {(1−y^{(i)})}log(1 − h(x^{(i)}))}$ 那么，如何去最大化似然函数呢，可以应用梯度上升法，因为我们要使 P 的取值足够大，也是就预测准确的概率最够大。 随机梯度上升的公式为： θ:= θ + \alpha\Deltaθl(θ)下面来求$\Deltaθl(θ)$的取值： \frac\partial{\partial\theta_j}l(\theta)= (y\frac1{g(\theta^Tx)} - (1-y)\frac1{1-g(\theta^Tx)})\frac\partial{\partial\theta_j}g(\theta^Tx)= (y\frac1{g(\theta^Tx)} - (1-y)\frac1{1-g(\theta^Tx)}) g(\theta^Tx)(1-g(\theta^Tx))\frac\partial{\partial\theta_j}\theta^Tx= ({y(1-g(\theta^Tx))-(1-y)g(\theta^Tx)})x_j= (y - h_{\theta}(x))x_j附上手写的推导过程： 所以，最终随机梯度上升的公式为： θ_j:=θ_j + \alpha\sum_{i=1}^{m}(y^{(i)} - h_{\theta}(x^{(i))})x_j^{(i)}如何和线性回归的公式放在一起比较， θ_j = θ_j - α \frac1m \* \sum_{i=1}^{m}{(h_θ(x^{(i)}) - y^{(i)})}\*x_j^{(i)}会发现，这两者非常相似，实际上却不然，因为这里的 $(h_θ(x^{(i)})$ 定义的不是线性函数。后续我们谈到 GLM 时会发现这并不是巧合，而是有更深层次的原因。 牛顿迭代法求解逻辑回归牛顿迭代法可以利用到曲线本身的信息，比梯度下降法更容易收敛，即迭代更少次数。 牛顿迭代法简述假设我们要求解方程 f(x)=0 的根，首先随便找一个初始值 x0，如果 x0 不是解，做一个经过 (x0,f(x0)) 这个点的切线，与 x 轴的交点为 x1。同样的道理，如果 x1 不是解，做一个经过 (x1,f(x1)) 这个点的切线，与 x 轴的交点为 x2。 以此类推。以这样的方式得到的 xi 会无限趋近于 f(x)=0 的解。 对于任意一点 $(x_n,y_n)$ 做切线，切线的斜率为 $f’(x_n)$，则有方程： y-f(x_n) = f'(x_n)(x-x_n)迭代过程求解 $f(\theta)$ = 0 时 $\theta$ 的取值。设下一次迭代时 $\theta^{(t+1)}$ 的取值与前一次迭代 $\theta^{(t)}$ 的取值(在 x 轴)距离为 $\Delta$。 则 $\theta^{(t+1)} = \theta^{(t)} - \Delta$，且 $\Delta = \frac{f(\theta^{(t)})}{f’(\theta^{(t)})}$，所以有： \theta^{(t+1)} = \theta^{(t)} - \frac{f(\theta^{(t)})}{f'(\theta^{(t)})}从泰勒展开到牛顿迭代也可以由泰勒展开中推导牛顿迭代的公式。这次为了求解方程 f′=0 的根，把原函数 f(x) 的做泰勒展开，展开到二阶形式： f(x+\Delta x) = f(x)+f'(x)\Delta x+ \frac1{2}f''(x)\Delta x^2当且仅当 $\Delta x$ 逼近 0 时，上式成立，此时忽略 1/2 系数的作用，所以有： f'(x)+ \frac1{2}f''(x)\Delta x = 0故： \Delta x = -\frac{f'(x)}{f''(x)}对函数求极大值的方法&gt; 将原函数y=f(x)，对x求一次导数，得到dy/dx； 令dy/dx = 0，解得一次导函数的零点； 将原函数对x求二次导函数； 将解得的零点坐标的x值代入二次导函数，如果是正值，零点所在位置，就是极小值点，再将该x值代入原函数，得到极小值；如果是值值，零点所在位置，就是极大值点，再将该x值代入原函数，得到极大值；如果是0，零点所在位置，既不是极小值点，也不是极大值点，是拐点。 所以求 $l(\theta)$ 在极大值处 $\theta$ 的取值，则是求 $l’(\theta) = 0$ 时 $\theta$ 的值，应用牛顿迭代法则有： \theta^{(t+1)} = \theta^{(t)} - \frac{l'(\theta^{(t)})}{l''(\theta^{(t)})}多维向量的牛顿迭代对于多维向量 $\overrightarrow{X}$ 求解。 \theta := \theta - H^{-1} \nabla l(\theta)其中$\nabla l(\theta)$ 是对 $l(\theta)$ 求导的值。 H 是一个 n*n 的矩阵，n 是特征数量，元素的计算公式为： H_ij= \frac{\partial^2{l({\theta)}}}{\partial{\theta_i}\partial{\theta_j}}牛顿迭代法的特点是否收敛通常情况下是收敛的，但是需要满足一些条件，对于逻辑回归来讲，是收敛的。 迭代速度每次迭代后，有解数字的误差是成平方倍减小的，是二次收敛函数。 优缺点优点：收敛快缺点：特征多(上千个)时，每次迭代成本大 Referencehttp://blog.csdn.net/baimafujinji/article/details/51179381http://blog.csdn.net/baimafujinji/article/details/51167852如何通过牛顿方法解决Logistic回归问题]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 3 线性回归的概率解释]]></title>
    <url>%2F2017%2F11%2F05%2FStanford-Machine-Learning-3-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%A6%82%E7%8E%87%E8%A7%A3%E9%87%8A%2F</url>
    <content type="text"><![CDATA[欠拟合与过拟合欠拟合：underfitting，与训练数据贴合的不够好，不能准确预测未来目标值。过拟合：overfitting，与训练数据贴合的太好了，预测未来目标值的准确性有较大风险。 线性模型的概率解释思考：我们为什么要用最小二乘的指标作为 cost function？为什么不是绝对值或四次方？ 最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。最小二乘是从函数形式上来看的，极大似然是从概率意义上来看的。事实上，最小二乘可以由高斯噪声假设+极大似然估计推导出来。当然极大似然估计还可以推导出其他的loss function， 比如logistic回归中，loss function是交叉熵。最大似然估计与最小二乘估计的区别 一般的最小二乘法实际上是在假设误差项满足高斯分布且独立同分布的情况下，使似然性最大化。 推导过程回到预测房价的例子，假设最终的预测函数，每一次预测都有误差，用$ε^{(i)}$表示误差，则预测函数可以写为： y^{(i)}=\theta^Tx^{(i)} + ε^{(i)}其中，误差是随机分布的，均值为 0，服从高斯分布 $N(0,σ^2)$。 Andrew Ng 讲到在大多数情况下，线性回归的误差值如果综合来看，就是符合高斯分布的。并且根据中心极限定律，正态分布确实是对误差项分布的合理猜想。 所以 P(y^{(i)}|x^{(i)}; θ) = \frac{1}{\sqrt{2\pi}\sigma}exp(- \frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})$P(y^{(i)}|x^{(i)}; θ)$ 表示：在 θ 为给定的参数的情况下，概率 $y^{(i)}$ 以 $x^{(i)}$ 为随机变量的概率分布，注意 θ 不是随机变量。 由于 ε(i) 是独立的同分布（IID：independentlyidentically distribution），所以以 θ 为变量的似然函数为： L(θ)=L(θ;X,Y)=p(Y|X;θ) = \prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma}exp(- \frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})对 L(θ) 取对数有： l(\theta)=logL(\theta) = log\prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma}exp(- \frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}) = m\sum_{i=1}^{m}log\frac{1}{\sqrt{2\pi}\sigma} - \frac1{2\sigma^2}\sum_{i=1}^{m}(y^{(i)}-\theta^Tx^{(i)})^2最大化 $l(\theta)$ 即是最小化 $\frac1{2\sigma^2}\sum_{i=1}^{m}(y^{(i)}-\theta^Tx^{(i)})^2$，这样就是 cost function. 由于目标变量服从正态分布，但分布的均值和方差都未知，对均值和方差两个参数的合理估计是选取两个参数使得在正态分布的前提下，抽到各样本中的 y 值的概率最大，这就是最大似然估计的思想。 Referencehttp://www.holehouse.org/mlclass/07_Regularization.htmlhttp://rstudio-pubs-static.s3.amazonaws.com/4810_06e3d8fd26ed40eb8c31aff35eae81ae.htmlhttps://rpubs.com/badbye/ml03http://www.qiujiawei.com/linear-algebra-15/最大似然估计]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 2 线性回归进阶]]></title>
    <url>%2F2017%2F11%2F05%2FStanford-Machine-Learning-2-Linear-Regression-with-multiple-features%2F</url>
    <content type="text"><![CDATA[多变量的线性回归n: 特征(features) 数量m: 训练集数量$x^{(i)}$: 表示一条训练数据的向量 i is an index into the training set So x is an n-dimensional feature vector $x^{(3)}$ is, for example, the 3rd training data $x^{(j)}_i$: The value of feature j in the ith training example 例如，当 n=4 时: h_θ(x) = θ_0 + θ_1x_1 + θ_2x_2 + θ_3x_3 + θ_4x_4For convenience of notation, $x_0$ = 1, 所以最后的特征向量的维度是 n+1，从 0 开始，记为”X”，则有： h_θ(x)=θ^TX$θ^T$: [1 * (n+1)] matrix 多变量的梯度下降Cost FunctionJ(θ_0, θ_1, ...,θ_n) = \frac1{2m}\sum_{i=1}^{m}{(h_θ(x^{(i)}) - y^{(i)})^2}Gradient descentRepeat { θ_j = θ_j - α\frac\partial{\partial J(θ_0, θ_1, ...,θ_n)}} every iterator θj = θj - learning rate (α) times the partial derivative of J(θ) with respect to θJ(…) We do this through a simultaneous update of every θj value \frac\partial{\partial J(θ_0, θ_1, ...,θ_n)}= \frac1m * \sum_{i=1}^{m}{(h_θ(x^{(i)}) - y^{(i)})}*x_j^{(i)}Gradient Decent in practiceFeature Scaling假设只有 $x_1$,$x_2$ 两个变量，其中：$x_1\in(0,2000), x_2\in(1,5)$，则最后的 J(θ) 图形是一个椭圆，在椭圆下用梯度下降法会比圆形要耗时更久，So we need to rescale this input so it’s more effective，有很多方式，一种是将各个 feature 除以其本身的最大值，缩小范围至[0,1]，一种是各个 feature 减去 mean 然后除以最大值，缩小范围至[-0.5,0.5] Learning Rate α working correctly: If gradient descent is working then J(θ) should decrease after every iteration convergence: 收敛是指每经过一次迭代，J(θ)的值都变化甚小。 choose α When to use a smaller α If J(θ) is increasing, see below picture If J(θ) looks like a series of waves, decreasing and increasing again But if α is too small then rate is too slow Try a range of α values Plot J(θ) vs number of iterations for each version of alpha Go for roughly threefold increases: 0.001, 0.003, 0.01, 0.03. 0.1, 0.3 Features and polynomial regressionCan create new features如何选择 features 和表达式尤为关键，例如房价与房子的长，房子的宽组成的表达式就会麻烦很多，若将房子的长乘以房子的宽得出面积，则有房价与房子面积的表达式，将会更容易拟合出房价的走势。 Polynomial regression例如房价的走势，如下图，横坐标 x 为房子的面积，纵坐标为房价，使用一元二次的方程，会得出下图的蓝色曲线。容易得到房价今后会有一个下降的过程，可实际上房价是不会随着面积的增大而下降的。所以需要重新选定 Polynomial regression，可以改为使用一元三次的方程或者使用平凡根的方程。 所以选择合适的 Features 和 Polynomial regression 都非常重要。 Normal equation 求解多变量线性回归Normal equation举例说明，假设 J(θ) 是一元二次方程，如：J(θ)=a$θ^2$+bθ+c，则令 \frac{d}{dθ}J(θ)=2aθ+b=0 即可，求出最终的 θ 则得到了线性回归方程，可以预测出今后的 y 值。 更普遍地，当 θ 是一个 n+1 维的向量时，θ $\in$ $R^{n+1}$，则 cost function 如下： J(θ_0, θ_1, ...,θ_n) = \frac1{2m}\sum_{i=1}^{m}{(h_θ(x^{(i)}) - y^{(i)})^2}只需要令： \frac\partial{\partial θ_j}J(θ_0, θ_1, ...,θ_n) = ... = 0 $$，其中 j = 0,1,2,...,n 设 X 代表训练集的 features 的值的矩阵，y 代表训练集的结果的值的矩阵，假设训练集数量为 m, features 个数为 n, 则 X 为 (m\*n) 的矩阵，y 为 (m\*1) 的矩阵，可以推导出求 θ 向量的公式如下： $$θ = (X^TX)^{-1}X^TyGradient descent Vs Normal equationGradient descent Need to chose learning rate Needs many iterations - could make it slower Works well even when n is massive (millions) Better suited to big data What is a big n though: 100 or even a 1000 is still (relativity) small, If n is 10000 then look at using gradient descent 适用于线性回归会逻辑回归 Normal equation No need to chose a learning rate No need to iterate, check for convergence etc. Normal equation needs to compute $(X^TX)^{-1}$ This is the inverse of an n x n matrix With most implementations computing a matrix inverse grows by O(n3), So not great Slow of n is large, Can be much slower 仅适用于线性回归 局部加权线性回归局部加权回归(locally weighted regression)简称 loess，其思想是，针对对某训练数据的每一个点，选取这个点及其临近的一批点做线性回归；同时也需要考虑整个训练数据，考虑的原则是距离该区域越近的点贡献越大，反之则贡献越小，这也正说明局部的思想。其 cost function 为： J(\theta) = \sum_{i=1}^{m} w^{(i)}( y^{(i)}-\theta^Tx^{(i)} )^2其中 w^{(i)} = exp (-\frac{(x^{(i)}-x)^2}{\tau^2})$w^{(i)}$的形式跟正态分布很相似，但二者没有任何关系，仅仅只是便于计算。可以发现，$x^{(j)}$ 离 $x^{(i)}$ 非常近时，${w^{(i)}_j}$ 的值接近于1，此时 j 点的贡献很大，当 $x^{(j)}$ 离 $x^{(i)}$ 非常远时，${w^{(i)}_j}$ 的值接近于 0，此时 j 点的贡献很小。 $\tau^2$ 是波长函数(bandwidth)， 控制权重随距离下降的速度，τ 越小则 x 离 $x^{(i)}$ 越远时 $w^{(i)}$ 的值下降的越快。 所以，如果沿着 x 轴的每个点都进行局部直线拟合，那么你会发现对于这个数据集合来说，局部加权的预测结果，能够最终跟踪这条非线性的曲线。 但局部加权回归也有其缺点： 每次对一个点的预测都需要整个数据集的参与，样本量大且需要多点预测时效率低。提高效率的方法参考 Andrew More’s KD Tree 不可外推，对样本所包含的区域外的点进行预测时效果不好，事实上这也是一般线性回归的弱点 对于线性回归算法，一旦拟合出适合训练数据的参数θ，保存这些参数θ，对于之后的预测，不需要再使用原始训练数据集，所以是参数学习算法。 对于局部加权线性回归算法，每次进行预测都需要全部的训练数据（每次进行的预测得到不同的参数θ），没有固定的参数θ，所以是非参数算法(non-parametric algorithm)。 Reference http://www.holehouse.org/mlclass/04_Linear_Regression_with_multiple_variables.html]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stanford Machine Learning - 1 线性回归入门]]></title>
    <url>%2F2017%2F11%2F05%2FStanford-Machine-Learning-1-Linear%20Regression%20with%20One%20Variable%2F</url>
    <content type="text"><![CDATA[引言本系列的课程来源是 斯坦福大学公开课 CS229: 机器学习课程，也可以看网易公开课的资源，是带字幕的。斯坦福的 CS229 课程相比于 Course 上的 Machine Learning 课程，理论更强，讲解的也更深入，需要有一些的高数基础。两个课程都看了前半部分，更推荐前者，所以相关笔记对应的都是 CS229 课程。 线性回归的定义适用于监督学习，根据已有的数据集合(x, y)，来推断出将来的数据趋势。 单变量线性回归最后的函数应该是 y = ax + b，假设 hypothesis 为： h_{\theta}(x) = \theta_{0} + \theta_{1}则问题转化为求 $\theta_{0}$ 和 $\theta_{1}$ 的值。要求这两个值需要转化上式，并根据已有的数据来求解。下面介绍损失函数，又叫代价函数的概念。 Cost Function针对每一组数据，公式的值是 $h_{\theta}$($x_{i}$), 实际的值是 $y_{i}$，我们要达到的效果则是公式能够尽量表达已有的 m 组数据集合，即 $( h_{\theta}(x^{(i)}) - y_{i})^{2}$ 的值尽量小。所以，对于所有数据集合，需要求使得 \frac1{2m}\sum_{i=1}^{m}{(h_{\theta}(x^{(i)}) - y^{(i)})^2}$$ 最小的 $\theta$ 值。 上式又称为 Cost Function，可以写为： $$ J(\theta_0, \theta_1) = \frac1{2m}\sum_{i=1}^{m}{(h_{\theta}(x^{(i)}) - y^{(i)})^2}我们需要最小化这个 Cost Function。 Cost Function 的作用假设 $\theta_0$ = 0，则有 $\theta_1$ 和 J($\theta_1$) 的关系，且图形如下： 所以当 $\theta_1$ = 1 时， J(\theta_1)= \frac1{2m}\sum_{i=1}^{m}{(\theta_1x^{(i)} - y^{(i)})^2}很容易看出，$J(\theta_1)$ 是关于 $\theta_1$ 的一元二次方程，对于所有的训练数据，每个 $\theta_1$ 的取值都会得到一个 $J(\theta_1)$ 值，而 $J(\theta_1)$ 和 $\theta_1$ 的对应关系根据一元二次方程可知，函数曲线如上图。当 $J(\theta_1)$ 最小时，求得 $\theta_1$ 结果。 当 $\theta_0$ 和 $\theta_1$ 都不为 0 时，J($\theta_0$, $\theta_1$) 的图形如下： 对于两个系数的情况不如一个系数是一个二维坐标系的抛物线那么简单。下面将介绍梯度下降法。 梯度下降法 Start with initial guesses Start at 0,0 (or any other value) Keeping changing $\theta_0$ and $\theta_1$ a little bit to try and reduce J($\theta_0$, $\theta_1$) Each time you change the parameters, you select the gradient which reduces J($\theta_0$, $\theta_1$) the most possible Repeat Do so until you converge to a local minimumHas an interesting property Where you start can determine which minimum you end up Here we can see one initialization point led to one local minimum The other led to a different one 具体的计算过程\theta_j := \theta_j - \alpha \frac\partial{\partial\theta_j}J(\theta_0, \theta_1)(for j = 0 and j = 1) Notation$\alpha$ Is a number called the learning rate Controls how big a step you take If α is big have an aggressive gradient descent If α is small take tiny steps Too small Take baby steps Takes too long Too large Can overshoot the minimum and fail to converge Computer每次都是同时计算 $\theta_0, \theta_1$ 的值，如下： temp0:= \theta_0 - \alpha \frac\partial{\partial\theta_0}J(\theta_0, \theta_1)temp1:= \theta_1 - \alpha \frac\partial{\partial\theta_1}J(\theta_0, \theta_1)\theta_0 := temp0\theta_1 := temp1 利用梯度下降法求解线性回归问题\frac\partial{\partial\theta_j}J(\theta_0, \theta_1)=\frac\partial{\partial\theta_j} * \frac1{2m}\sum_{i=1}^{m}{(h_{\theta}(x^{(i)}) - y^{(i)})^2}=\frac\partial{\partial\theta_j} * \frac1{2m}\sum_{i=1}^{m}{(\theta_0 +\theta_1x^{(i)} - y^{(i)})^2}对于 j = 0 or 1 的情况有：j = 0: \frac\partial{\partial\theta_0}J(\theta_0, \theta_1) = \frac1{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})j = 1: \frac\partial{\partial\theta_1}J(\theta_0, \theta_1) = \frac1{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})*x^{(i)}梯度下降法的证明1、如果优化函数存在解析解。例如我们求最值一般是对优化函数求导，找到导数为0的点。如果代价函数能简单求导，并且求导后为0的式子存在解析解，那么我们就可以直接得到最优的参数。 2、如果式子很难求导，例如函数里面存在隐含的变量或者变量相互间存在耦合，互相依赖的情况。或者求导后式子得不到解释解，或者未知参数的个数大于方程组的个数等。这时候使用迭代算法来一步一步找到最优解。 当目标函数是凸函数时，梯度下降法的解是全局最优解 一般情况下，其解不保证是全局最优解 凸函数凸函数就是一个定义在某个向量空间的凸子集C（区间）上的实值函数 f，而且对于凸子集C中任意两个向量 $x_1$, $x_2$ 有： f(\frac{x_1+x_2}{2}) \le \frac{f(x_1)+f(x_2)}{2}于是容易得出对于任意（0,1)中有理数 p，有： f(px_1+(1-p)x_2) \le pf(x_1)+(1-p)f(x_2)如果 f 连续，那么 p 可以改成任意（0,1）中实数。则 f 称为 I 上的凸函数，当且仅当其上境图（在函数图像上方的点集）为一个凸集。 梯度下降法的使用我们首先在函数上任选一点，计算其损失（即我们上面的L(w)） ，然后按照某一规则寻找更低的一点计算新的损失，只要新损失更小（最小化问题），我们就继续下降，直到达到一个可接受的优化目标。梯度下降方法分为两个部分，第一部分是整体上，我们使用某步长不断下降求损失函数，第二部分是为了防止步长太长导致最后无法收敛，每次当损失上升的时候都调整步长。通常实践中使用时，都是用一些开源算法，很少需要深度改进，比如使用 libsvm 可以直接求解逻辑回归。 Reference http://www.cnblogs.com/yysblog/p/3268508.htmlhttp://52opencourse.com/125/coursera%E5%85%AC%E5%BC%80%E8%AF%BE%E7%AC%94%E8%AE%B0-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%AC%E5%85%AD%E8%AF%BE-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regressionhttp://www.cnblogs.com/chaoren399/p/4851658.html]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jackson反序列化忽略为null的字段]]></title>
    <url>%2F2017%2F08%2F19%2FJackson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%BF%BD%E7%95%A5%E4%B8%BAnull%E7%9A%84%E5%AD%97%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[要解决的问题json 反序列化 bean 时，当某个字段在 json 中为 null 时，使用 bean 中声明的默认值。 Person 类我们改造下：12345public class Person &#123; private String name; // Address is a enum: &#123;CH, US, GZ&#125; private Region region = Region.GZ;&#125; 仍然以 Person 类举例，如果 json 串是：1&#123;"name":"robert", "region":null&#125; 希望反序列化后的 bean 为1Person(name="robert", region=Region.GZ) 解决过程在上一篇文章 lombok 的 AllArgs 导致 Jackson 反序列化丢失字段默认值 中可以看到 json 反序列化为 bean 的过程，一般情况下，是先调用默认构造函数生成 bean，然后根据 json 中出现的字段挨个赋值。所以反序列化生成的 bean 的 region 肯定为 null。 解决方案@JsonInclude(Include.NON_NULL) 可行吗？不可行，这个注解是序列化时忽略 null 值，反序列化时不生效，基本上反序列化时我们不能做什么事情。 JsonCreator 可行吗？在 Region 枚举里写 JsonCreator:12345678910@JsonCreatorpublic static Region getRegion(String value) &#123; for (Region region : Region.values()) &#123; if (region.name().equals(value)) &#123; return region; &#125; &#125; return Region.GZ;&#125; 直接将 {&quot;region&quot;: null} 反序列化为 Region 是可行的，会调用 JsonCreator，但是如果是反序列化 Person 则不会调用到 JsonCreator，为什么呢？ debug 过程：如前文所述，会调用到 com.fasterxml.jackson.databind.deser.BeanDeserializer#deserialize 这个函数中，然后会调用到com.fasterxml.jackson.databind.deser.SettableBeanProperty#deserialize，这个函数的实现是：1234567891011public final Object deserialize(JsonParser p, DeserializationContext ctxt) throws IOException &#123; JsonToken t = p.getCurrentToken(); if (t == JsonToken.VALUE_NULL) &#123; return _valueDeserializer.getNullValue(ctxt); &#125; if (_valueTypeDeserializer != null) &#123; return _valueDeserializer.deserializeWithType(p, ctxt, _valueTypeDeserializer); &#125; return _valueDeserializer.deserialize(p, ctxt);&#125; 所以在这里会把 null 值拦住，直接返回 getNullValue 的结果。 自定义 deserializer实现如下：1234567891011121314151617181920212223public class RegionDeserializer extends JsonDeserializer&lt;Region&gt; &#123; @Override public Region deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException &#123; JsonNode node = jsonParser.getCodec().readTree(jsonParser); Region region = Region.GZ; try &#123; if (StringUtils.isNotEmpty(node.textValue())) &#123; return Region.getRegion(node.textValue()); &#125; &#125; catch (Exception e) &#123; type = Region.GZ; &#125; return region; &#125; @Override public Region getNullValue(DeserializationContext ctxt) &#123; return Region.GZ; &#125;&#125; Person 类改为：1234567public class Person &#123; private String name; // Address is a enum: &#123;CH, US, GZ&#125; @JsonDeserialize(using = RegionDeserializer.class) private Region region = Region.GZ;&#125; 这样，在com.fasterxml.jackson.databind.deser.SettableBeanProperty#deserialize这个方法里，碰到 null 值，就会返回 getNullValue 的结果，即 Region.GZ，如果不是 null 会进入 getRegion 函数处理，也能处理其他情况。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lombok的AllArgsConstructor注解导致Jackson反序列化后丢失字段默认值]]></title>
    <url>%2F2017%2F08%2F19%2Flombok%E7%9A%84AllArgsConstructor%E6%B3%A8%E8%A7%A3%E5%AF%BC%E8%87%B4Jackson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%90%8E%E4%B8%A2%E5%A4%B1%E5%AD%97%E6%AE%B5%E9%BB%98%E8%AE%A4%E5%80%BC%2F</url>
    <content type="text"><![CDATA[要解决的问题希望在反序列化 json 到 bean 时，对于 json 中未出现的字段，在 bean 中赋上默认值。 例如Person 类如下： 12345678@Data@AllArgsConstructor@NoArgsConstructor@JsonIgnoreProperties(ignoreUnknown = true)public class Person &#123; private String name; private String address = "beijing"; // default value if json missing the age field&#125; json:1&#123;&quot;name&quot;:&quot;robert&quot;&#125; 反序列化后的 bean 为1Person(name=&quot;robert&quot;, address=&quot;beijing&quot;) 但实际上，发序列化的结果为1Person(name=&quot;robert&quot;, address=null) 解决过程查看 maven 版本项目中 jackson 的配置如下 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Jackson dependency versions --&gt;&lt;jackson.version&gt;2.6.5&lt;/jackson.version&gt; 配置升到最新后问题仍然存在。 debug json 反序列化过程，找到原因json 反序列化是从1com.fasterxml.jackson.databind.ObjectMapper#_readMapAndClose 这个方法调用开始的，里面的一段代码为： 123456789DeserializationConfig cfg = getDeserializationConfig();DeserializationContext ctxt = createDeserializationContext(jp, cfg);JsonDeserializer&lt;Object&gt; deser = _findRootDeserializer(ctxt, valueType);if (cfg.useRootWrapping()) &#123; result = _unwrapAndDeserialize(jp, ctxt, cfg, valueType, deser);&#125; else &#123; result = deser.deserialize(jp, ctxt);&#125;ctxt.checkUnresolvedObjectId(); 在第 3 行找到的 JsonDeserializer 是 com.fasterxml.jackson.databind.deser.BeanDeserializer从第 7 行代表进入 com.fasterxml.jackson.databind.deser.BeanDeserializer#deserialize(com.fasterxml.jackson.core.JsonParser, com.fasterxml.jackson.databind.DeserializationContext) 函数实现如下：123456789101112131415public Object deserialize(JsonParser p, DeserializationContext ctxt) throws IOException &#123; // common case first if (p.isExpectedStartObjectToken()) &#123; if (_vanillaProcessing) &#123; return vanillaDeserialize(p, ctxt, p.nextToken()); &#125; p.nextToken(); if (_objectIdReader != null) &#123; return deserializeWithObjectId(p, ctxt); &#125; return deserializeFromObject(p, ctxt); &#125; JsonToken t = p.getCurrentToken(); return _deserializeOther(p, ctxt, t);&#125; vanillaDeserialize 为 false，最后走到了第 11 行，最后到了1com.fasterxml.jackson.databind.deser.BeanDeserializer#_deserializeUsingPropertyBased 然后到1com.fasterxml.jackson.databind.deser.impl.PropertyBasedCreator#build 在这个函数里有这样一段代码：1Object bean = _valueInstantiator.createFromObjectWith(ctxt, buffer.getParameters(_allProperties)); 调用的是1com.fasterxml.jackson.databind.deser.ValueInstantiator#createFromObjectWith(com.fasterxml.jackson.databind.DeserializationContext, java.lang.Object[]) 可以发现，createFromObjectWith 的第二个参数是数组，json 解出来的字段都放在了这个数组里。然后调用了 Person 类的全参构造函数，对于缺失的字段自动补 null 值，这样就导致了 address 字段为 null。 解决方案去掉 @AllArgsConstructor 时，没有问题了，因为此时找到的 com.fasterxml.jackson.databind.deser.BeanDeserializer 的 vanillaDeserialize 字段为 true，会调用 vanillaDeserialize(p, ctxt, p.nextToken());，这个函数的实现非常明确：1234567891011121314151617181920212223private final Object vanillaDeserialize(JsonParser p, DeserializationContext ctxt, JsonToken t) throws IOException &#123; final Object bean = _valueInstantiator.createUsingDefault(ctxt); // [databind#631]: Assign current value, to be accessible by custom serializers p.setCurrentValue(bean); if (p.hasTokenId(JsonTokenId.ID_FIELD_NAME)) &#123; String propName = p.getCurrentName(); do &#123; p.nextToken(); SettableBeanProperty prop = _beanProperties.find(propName); if (prop != null) &#123; // normal case try &#123; prop.deserializeAndSet(p, ctxt, bean); &#125; catch (Exception e) &#123; wrapAndThrow(e, bean, propName, ctxt); &#125; continue; &#125; handleUnknownVanilla(p, ctxt, bean, propName); &#125; while ((propName = p.nextFieldName()) != null); &#125; return bean;&#125; 先用默认构造函数生成 bean，此时的 bean 是有默认值的，然后将 json 中出现的字段的值赋值给 bean，这样 address 就有值了。 根本原因看上去是声明了全参构造函数导致的，所以想尝试自己写全参构造函数，在 address 为 null 时给其赋默认值。写完如下：1234567public Person(String name, String address)&#123; this.name = name; this.address = address; if(this.address == null)&#123; this.address = "beijing"; &#125;&#125; 继续走刚才 debug 的流程，发现居然没有请求这个全参构造函数。 那问题就是 @AllArgsConstructor 生成的全参函数有不同之处，jackson 能够识别出来并用于反序列化。查看 jar 包中 Person 类的代码发现其全参构造函数如下：12345@ConstructorProperties(&#123;"name", "address"&#125;)public Person(String name, String address)&#123; this.name = name; this.address = address;&#125; 所以，区别就是 @ConstructorProperties({&quot;name&quot;, &quot;address&quot;}) 这个注解，这个注解的作用是指定构造函数参数的名字，Spring 可根据参数的名字注入 bean。 (补充自 liwei)jackson 调用了全参构造函数的原因在于@AllArgsConstructor 的构造函数有ConstructorProperties ,jackson在选择构造函数的时候会调用BasicDeserializerFactory._addDeserialzerContructors方法，他首先选择无参构造函数，并遍历所有的构造函数，如果存在具有@ConstructProperties注解的构造函数，则把该构造函数作为默认创建bean的构造函数，如下： 可以通过设置 @AllArgsConstructor(suppressConstructorProperties=true) 来禁用 @ConstructorProperties. 结论Lombok 的 @AllArgsConstructor 注解导致 Jackson 反序列化时调用了全参构造函数，将没有出现的字段都赋值为 null 了。 修改方式： 不使用 @AllArgsConstructor 使用 @AllArgsConstructor 但是不让其在全参构造函数上加入 ConstructorProperties 注解，声明方式改为 @AllArgsConstructor(suppressConstructorProperties = true)]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务调优]]></title>
    <url>%2F2017%2F08%2F13%2F%E6%9C%8D%E5%8A%A1%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[服务异常的处理流程 负载查看机器 cpu 的负载1top -b -n 1 |grep java|awk &apos;&#123;print &quot;VIRT:&quot;$5,&quot;RES:&quot;$6,&quot;cpu:&quot;$9&quot;%&quot;,&quot;mem:&quot;$10&quot;%&quot;&#125;&apos; 查找 cpu 占用率高的线程top -p 25603 -Hprintf 0x%x 25842jstack 25603 | grep 0x64f2 cat /proc/interrupts （1）CPU（2）Memory（3）IO（4）Network 可以从以下几个方面监控CPU的信息：（1）中断；（2）上下文切换；（3）可运行队列；（4）CPU 利用率。 内存系统内存free 命令[root@server ~]# free 1234 total used free shared buffers cachedMem: 3266180 3250000 10000 0 201000 3002000-/+ buffers/cache: 47000 3213000Swap: 2048276 80160 1968116 这里的默认显示单位是kb。各项指标解释 total:总计物理内存的大小。 used:已使用多大。 free:可用有多少。 Shared:多个进程共享的内存总额。 buffers: 磁盘缓存的大小。 cache:磁盘缓存的大小。 -/+ buffers/cached): used:已使用多大，free:可用有多少。 已用内存 = 系统used memory - buffers - cached（47000 = 3250000-201000-3002000） 可用内存 = 系统free memory + buffers + cached（3213000 = 10000+201000+3002000） 什么是buffer/cache？ buffer 指 Linux 内存的：Buffer cache，缓冲区缓 cache 指 Linux内存中的：Page cache，页面缓存 page cachepage cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read／write 操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用：mmap是不是很自然的也应该用到 page cache？在当前的系统实现里，page cache 也被作为其它文件类型的缓存设备来用，所以事实上 page cache 也负责了大部分的块设备文件的缓存工作。 buffer cachebuffer cache 主要用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用 buffer cache 进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache 的内容会被改变，而 buffer cache 则可以用来将 page 标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个 page 写回，而只需要写回修改的部分即可。 在当前的内核中，page cache 是针对内存页的缓存，说白了就是，如果有内存是以page进行分配管理的，都可以使用page cache作为其缓存来管理使用。当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到 cache 功能，则都集中到buffer cache中来使用。（从这个角度出发，是不是buffer cache改名叫做block cache更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在X86上无论是32位还是64位都是4k。 系统如何回收cache？Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 但是这种清缓存的工作也并不是没有成本。理解cache是干什么的就可以明白清缓存必须保证cache中的数据跟对应文件中的数据一致，才能对cache进行释放。所以伴随着cache清除的行为的，一般都是系统IO飙高。因为内核要对比cache中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。 在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以人工触发缓存清除的操作。 进程内存进程内存统计/proc/[pid]/status通过/proc//status可以查看进程的内存使用情况，包括虚拟内存大小（VmSize），物理内存大小（VmRSS），数据段大小（VmData），栈的大小（VmStk），代码段的大小（VmExe），共享库的代码段大小（VmLib）等等。 cat /proc/[pid]/status1234567891011121314151617Name: gedit /*进程的程序名*/State: S (sleeping) /*进程的状态信息,具体参见http://blog.chinaunix.net/u2/73528/showart_1106510.html*/Tgid: 9744 /*线程组号*/Pid: 9744 /*进程pid*/PPid: 7672 /*父进程的pid*/TracerPid: 0 /*跟踪进程的pid*/VmPeak: 60184 kB /*进程地址空间的大小*/VmSize: 60180 kB /*进程虚拟地址空间的大小reserved_vm：进程在预留或特殊的内存间的物理页*/VmLck: 0 kB /*进程已经锁住的物理内存的大小.锁住的物理内存不能交换到硬盘*/VmHWM: 18020 kB /*文件内存映射和匿名内存映射的大小*/VmRSS: 18020 kB /*应用程序正在使用的物理内存的大小，就是用ps命令的参数rss的值 (rss)*/VmData: 12240 kB /*程序数据段的大小（所占虚拟内存的大小），存放初始化了的数据*/VmStk: 84 kB /*进程在用户态的栈的大小*/VmExe: 576 kB /*程序所拥有的可执行虚拟内存的大小,代码段,不包括任务使用的库 */VmLib: 21072 kB /*被映像到任务的虚拟内存空间的库的大小*/VmPTE: 56 kB /*该进程的所有页表的大小*/Threads: 1 /*共享使用该信号描述符的任务的个数*/ JVM 内存分配java内存组成介绍：堆(Heap)和非堆(Non-heap)内存 按照官方的说法：“Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在JVM中堆之外的内存称为非堆内存(Non-heap memory)”。可以看出JVM主要管理两种类型的内存：堆和非堆。简单来说堆就是Java代码可及的内存，是留给开发人员使用的；非堆就是JVM留给 自己用的，所以方法区、JVM内部处理或优化所需的内存(如JIT编译后的代码缓存)、每个类结构(如运行时常数池、字段和方法数据)以及方法和构造方法 的代码都在非堆内存中。 JVM本身需要的内存，包括其加载的第三方库以及这些库分配的内存 NIO的DirectBuffer是分配的native memory 内存映射文件，包括JVM加载的一些JAR和第三方库，以及程序内部用到的。上面 pmap 输出的内容里，有一些静态文件所占用的大小不在Java的heap里，因此作为一个Web服务器，赶紧把静态文件从这个Web服务器中人移开吧，放到nginx或者CDN里去吧。 JIT， JVM会将Class编译成native代码，这些内存也不会少，如果使用了Spring的AOP，CGLIB会生成更多的类，JIT的内存开销也会随之变大，而且Class本身JVM的GC会将其放到Perm Generation里去，很难被回收掉，面对这种情况，应该让JVM使用ConcurrentMarkSweep GC，并启用这个GC的相关参数允许将不使用的class从Perm Generation中移除， 参数配置： -XX:+UseConcMarkSweepGC -X:+CMSPermGenSweepingEnabled -X:+CMSClassUnloadingEnabled，如果不需要移除而Perm Generation空间不够，可以加大一点： -X:PermSize=256M -X:MaxPermSize=512M JNI，一些JNI接口调用的native库也会分配一些内存，如果遇到JNI库的内存泄露，可以使用valgrind等内存泄露工具来检测 线程栈，每个线程都会有自己的栈空间，如果线程一多，这个的开销就很明显了 jmap/jstack 采样，频繁的采样也会增加内存占用，如果你有服务器健康监控，记得这个频率别太高，否则健康监控变成致病监控了。 方法区也称”永久代” 、“非堆”，它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。默认最小值为16MB，最大值为64MB，可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。 运行时常量池：是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种符号引用，这部分内容将在类加载后放到方法区的运行时常量池中。 虚拟机栈描述的是java 方法执行的内存模型：每个方法被执行的时候 都会创建一个“栈帧”用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。 局部变量表存放了编译器可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(引用指针，并非对象本身)，其中64位长度的long和double类型的数据会占用2个局部变量的空间，其余数据类型只占1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量是完全确定的，在运行期间栈帧不会改变局部变量表的大小空间。 本地方法栈与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务。 堆也叫做java 堆、GC堆是java虚拟机所管理的内存中最大的一块内存区域，也是被各个线程共享的内存区域，在JVM启动时创建。该内存区域存放了对象实例及数组(所有new的对象)。其大小通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 由于现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。 程序计数器是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。 直接内存直接内存并不是虚拟机内存的一部分，也不是Java虚拟机规范中定义的内存区域。jdk1.4中新加入的NIO，引入了通道与缓冲区的IO方式，它可以调用Native方法直接分配堆外内存，这个堆外内存就是本机内存，不会影响到堆内存的大小。 JVM 内存分析查看 JVM 堆内存情况jmap -heap [pid] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@server ~]$ jmap -heap 837Attaching to process ID 837, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.71-b01using thread-local object allocation.Parallel GC with 4 thread(s)//GC 方式Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40) MaxHeapFreeRatio = 100 //对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70) MaxHeapSize = 2082471936 (1986.0MB) //对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB)//对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小 MaxNewSize = 17592186044415 MB//对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小 OldSize = 5439488 (5.1875MB)//对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小 NewRatio = 2 //对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率 SurvivorRatio = 8 //对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB)//对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB)Heap Usage://堆内存使用情况PS Young GenerationEden Space://Eden区内存分布 capacity = 33030144 (31.5MB)//Eden区总容量 used = 1524040 (1.4534378051757812MB) //Eden区已使用 free = 31506104 (30.04656219482422MB) //Eden区剩余容量 4.614088270399305% used //Eden区使用比率From Space: //其中一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedTo Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedPS Old Generation //当前的Old区内存分布 capacity = 86507520 (82.5MB) used = 0 (0.0MB) free = 86507520 (82.5MB) 0.0% usedPS Perm Generation//当前的 “永生代” 内存分布 capacity = 22020096 (21.0MB) used = 2496528 (2.3808746337890625MB) free = 19523568 (18.619125366210938MB) 11.337498256138392% used670 interned Strings occupying 43720 bytes. 关于这里的几个generation网上资料一大把就不细说了，这里算一下求和可以得知前者总共给Java环境分配了644M的内存，而ps输出的VSZ和RSS分别是7.4G和2.9G，这到底是怎么回事呢？前面jmap输出的内容里，MaxHeapSize 是在命令行上配的，-Xmx4096m，这个java程序可以用到的最大堆内存。VSZ是指已分配的线性空间大小，这个大小通常并不等于程序实际用到的内存大小，产生这个的可能性很多，比如内存映射，共享的动态库，或者向系统申请了更多的堆，都会扩展线性空间大小，要查看一个进程有哪些内存映射，可以使用 pmap 命令来查看：pmap -x [pid]12345678910111213141516[root@server ~]$ pmap -x 837837: javaAddress Kbytes RSS Dirty Mode Mapping0000000040000000 36 4 0 r-x-- java0000000040108000 8 8 8 rwx-- java00000000418c9000 13676 13676 13676 rwx-- [ anon ]00000006fae00000 83968 83968 83968 rwx-- [ anon ]0000000700000000 527168 451636 451636 rwx-- [ anon ]00000007202d0000 127040 0 0 ----- [ anon ]......00007f55ee124000 4 4 0 r-xs- az.png00007fff017ff000 4 4 0 r-x-- [ anon ]ffffffffff600000 4 0 0 r-x-- [ anon ]---------------- ------ ------ ------total kB 7796020 3037264 3023928 这里可以看到很多anon，这些表示这块内存是由mmap分配的。 RSZ是Resident Set Size，常驻内存大小，即进程实际占用的物理内存大小， 在现在这个例子当中，RSZ和实际堆内存占用差了2.3G，这2.3G的内存组成分别为： 查看 JVM 堆各个分区的内存情况jstat -gcutil [pid]1234[root@server ~]$ jstat -gcutil 837 1000 20 S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 80.43 24.62 87.44 98.29 7101 119.652 40 19.719 139.371 0.00 80.43 33.14 87.44 98.29 7101 119.652 40 19.719 139.371 分析 JVM 堆内存中的对象查看存活的对象统计jmap -histo:live [pid] dump 内存jmap -dump:format=b,file=heapDump [pid] 然后用jhat命令可以参看jhat -port 5000 heapDump在浏览器中访问：http://localhost:5000/ 查看详细信息 服务指标响应时间(RT)响应时间是指系统对请求作出响应的时间。直观上看，这个指标与人对软件性能的主观感受是非常一致的，因为它完整地记录了整个计算机系统处理请求的时间。由于一个系统通常会提供许多功能，而不同功能的处理逻辑也千差万别，因而不同功能的响应时间也不尽相同，甚至同一功能在不同输入数据的情况下响应时间也不相同。所以，在讨论一个系统的响应时间时，人们通常是指该系统所有功能的平均时间或者所有功能的最大响应时间。当然，往往也需要对每个或每组功能讨论其平均响应时间和最大响应时间。 对于单机的没有并发操作的应用系统而言，人们普遍认为响应时间是一个合理且准确的性能指标。需要指出的是，响应时间的绝对值并不能直接反映软件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度。对于一个游戏软件来说，响应时间小于100毫秒应该是不错的，响应时间在1秒左右可能属于勉强可以接受，如果响应时间达到3秒就完全难以接受了。而对于编译系统来说，完整编译一个较大规模软件的源代码可能需要几十分钟甚至更长时间，但这些响应时间对于用户来说都是可以接受的。 吞吐量(Throughput)吞吐量是指系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。 对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。 并发用户数并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。一网站系统为例，假设用户只有注册后才能使用，但注册用户并不是每时每刻都在使用该网站，因此具体一个时刻只有部分注册用户同时在线，在线用户就在浏览网站时会花很多时间阅读网站上的信息，因而具体一个时刻只有部分在线用户同时向系统发出请求。这样，对于网站系统我们会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数。由于注册用户可能长时间不登陆网站，使用注册用户数作为性能指标会造成很大的误差。而在线用户数和同事发请求用户数都可以作为性能指标。相比而言，以在线用户作为性能指标更直观些，而以同时发请求用户数作为性能指标更准确些。 QPS每秒查询率(Query Per Second)每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 从以上概念来看吞吐量和响应时间是衡量系统性能的重要指标，QPS虽然和吞吐量的计量单位不同，但应该是成正比的，任何一个指标都可以含量服务器的并行处理能力。当然Throughput更关心数据量，QPS更关心处理笔数。 CPU利用率CPU Load Average &lt; CPU个数 核数 0.7 Context Switch Rate就是Process（Thread）的切换，如果切换过多，会让CPU忙于切换，也会导致影响吞吐量。《高性能服务器架构 》这篇文章的第2节就是说的是这个问题的。究竟多少算合适？google了一大圈，没有一个确切的解释。Context Switch大体上由两个部分组成：中断和进程(包括线程)切换，一次中断（Interrupt）会引起一次切换，进程（线程）的创建、激活之类的也会引起一次切换。CS的值也和TPS（Transaction Per Second）相关的，假设每次调用会引起N次CS，那么就可以得出 Context Switch Rate = Interrupt Rate + TPS* N CSR减掉IR，就是进程/线程的切换，假如主进程收到请求交给线程处理，线程处理完毕归还给主进程，这里就是2次切换。也可以用CSR、IR、TPS的值代入公式中，得出每次事物导致的切换数。因此，要降低CSR，就必须在每个TPS引起的切换上下功夫，只有N这个值降下去，CSR就能降低，理想情况下N=0，但是无论如何如果N &gt;= 4，则要好好检查检查。另外网上说的CSR&lt;5000，我认为标准不该如此单一。 这三个指标在 LoadRunner 中可以监控到；另外，在 linux 中，也可以用 vmstat 查看r（Load Arerage），in（Interrupt）和cs（Context Switch） 工具uptime dmesg top查看进程活动状态以及一些系统状况 vmstat查看系统状态、硬件和系统信息等 iostat查看CPU 负载，硬盘状况 sar综合工具，查看系统状况 mpstat查看多处理器状况 netstat查看网络状况 iptraf实时网络状况监测 tcpdump抓取网络数据包，详细分析 mpstat查看多处理器状况 tcptrace数据包分析工具 netperf网络带宽工具 dstat综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息 Reference&gt;http://tmq.qq.com/2016/07/it-is-necessary-to-know-the-background-performance-test/https://www.ibm.com/developerworks/java/library/j-nativememory-linux/http://www.oracle.com/technetwork/java/javase/index-137495.htmlhttp://www.hollischuang.com/archives/303]]></content>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 HBase 总结]]></title>
    <url>%2F2016%2F05%2F22%2F%E4%BD%BF%E7%94%A8-HBase-%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[HBase 简介HBase是Apache Hadoop的数据库，基于列存储、构建在HDFS上的分布式存储系统，能够对大型数据提供随机、实时的读写访问，是Google的BigTable的开源实现。HBase的目标是存储并处理大型的数据，仅用普通的硬件配置，就能够处理海量数据。 HBase 的优点 高可扩展性HBase 是真正意义上的线性水平扩展。数据量累计到一定程度(可配置)，HBase系统会自动对数据进行水平切分，并分配不同的服务器来管理这些数据。这些数据可以被扩散到上千个普通服务器上。这样一方面可以由大量普通服务器组成大规模集群，来存放海量数据(从几个 TB 到几十 PB 的数据)。另一方面，当数据峰值接近系统设计容量时，可以简单通过增加服务器的方式来扩大容量。这个动态扩容过程无需停机，HBase系统可以照常运行并提供读写服务，完全实现动态无缝无宕机扩容。 高性能HBase 的设计目的之一是支持高并发用户数的高速读写访问。这是通过两方面来实现的。首先数据行被水平切分并分布到多台服务器上，在大量用户访问时，访问请求也被分散到了不同的服务器上，虽然每个服务器的服务能力有限，但是数千台服务器汇总后可以提供极高性能的访问能力。其次，HBase 设计了高效的缓存机制，有效提高了访问的命中率，提高了访问性能。 高可用性HBase 建立在 HDFS 之上。HDFS 提供了数据自动复制和容错的功能。HBase 的日志和数据都存放在 HDFS 上，即使在读写过程中当前服务器出现故障(硬盘、内存、网络等故障)，日志也不会丢失，数据都可以从日志中自动恢复。HBase 系统会自动分配其他服务器接管并恢复这些数据。因此一旦成功写入数据，这些数据就保证被持久化并被冗余复制，整个系统的高可用性得到保证。 数据模型 表 数据量：一张表可以有数十亿行，上百万列。 最大版本数：通常是3，如果对于更新比较频繁的应用完全可以设置为1，能够快速的淘汰无用数据，对于节省存储空间和提高查询速度有效果。不过这类需求在海量数据领域比较小众。 压缩算法：可以尝试一下最新出炉的snappy算法，相对lzo来说，压缩率接近，压缩效率稍高，解压效率高很多。 inmemory：表在内存中存放，一直会被忽略的属性。如果完全将数据存放在内存中，那么hbase和现在流行的内存数据库memorycached和redis性能差距有多少，尚待实测。 bloomfilter：根据应用来定，看需要精确到rowkey还是column。不过这里需要理解一下原理，bloomfilter的作用是对一个region下查找记录所在的hfile有用。即如果一个region下的hfile数量很多，bloomfilter的作用越明显。适合那种compaction赶不上flush速度的应用。 无模式每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列； 面向列面向列（族）的存储和权限控制，列（族）独立检索； 稀疏对于空（null）的列，并不占用存储空间，表可以设计的非常稀疏； 数据多版本每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳； 数据类型单一HBase中的数据都是字符串，没有类型。 存储单元 Cell由{rowkey, colomnFamily:colomnQualifier, version} 确定的唯一单元，存储的数据是byte[]类型的。 HBase 的设计与实现HBase 的架构由上图可知，hbase包括Clinet、HMaster、HRegionServer、ZooKeeper组件各组件功能介绍： ClientClient主要通过ZooKeeper与Hbaser和HRegionServer通信，对于管理操作：client向master发起请求，对于数据读写操作：client向regionserver发起请求 ZooKeeperzk负责存储_root_表的地址，也负责存储当前服务的master地址,regsion server也会将自身的信息注册到zk中，以便master能够感知region server的状态，zk也会协调active master，也就是可以提供一个选举master leader,也会协调各个region server的容灾流程 HMastermaster可以启动多个master，master主要负责table和region的管理工作，响应用户对表的CRUD操作，管理region server的负载均衡，调整region 的分布和分配，当region server停机后，负责对失效的regionn进行迁移操作 HRegionServerregion server主要负责响应用户的IO请求，并把IO请求转换为读写HDFS的操作 HBase 的架构详解https://www.mapr.com/blog/in-depth-look-hbase-architecture#.VdMxvWSqqko HBase, Mysql 的比较Mysql 是关系型数据库，对于数据量不大(百万级别)，强依赖事务的业务，使用Mysql。HBase 适用于对大数据进行随机、实时访问的场合，支持海量数据，扩展性好。HBase 不适用的场景： 对分布式事务支持的不好 不支持多表的联合查询 对于复杂查询，需要扫描全表，且不支持索引 设计 HBase 表RowKey 的设计Rowkey唯一原则，必须在设计上保证其唯一性。但是还有几点需要注意的地方： RowKey 长度的设计Rowkey是一个二进制码流，可以是任意字符串，最大长度64KB，实际应用中一般为10~100bytes，存为byte[]字节数组。 定长定长的好处是 RowKey 排序时是按字典序且不受不同长度的影响 短不要超过16个字节。 数据的持久化文件 HFile 是按照 KeyValue 存储的，如果 Rowkey 过长比如100个字节，1000万列数据光 Rowkey 就要占用100*1000万=10亿个字节，将近1G数据，这会极大影响 HFile 的存储效率； MemStore 将缓存部分数据到内存，如果 Rowkey 字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。 16个字节目前操作系统是都是64位系统，内存8字节对齐。控制在16个字节，8字节的整数倍利用操作系统的最佳特性。 RowKey 含义的设计RowKey 虽然是越短越好，但也需要考虑 RowKey 的含义。由于 HBase 是按字典序存储，所以 RowKey 设计的合理可以提高查询效率(因为这会提高 RegionServer 的缓存命中率)，并且有意义的 RowKey 也便于在 scan 表的时候确定 startRow 和 stopRow。 RowKey 包含时间不要将时间放在二进制码的前面，建议将 RowKey 的高位作为散列字段（或者本身就已经是散列的其他id，例如userId），低位放时间字段。否则最新的数据都集中放在某个 RegionServer，而访问量又都集中在最新的数据上，将会导致 Hotspotting 现象，降低了访问速度，同时也增加了 RegionServer Crash 的概率。但考虑到是按字典序存储，如果想让最新的数据在最前面，可以使用 Long.MAX_VALUE – timestamp 作为 RowKey 的一部分。 RowKey 包含多个含义时各个含义用某种分隔符分开，比如包含用户，类型，时间三种含义的 RowKey, 可以设计为 userId#type#timestamp，这样如果需要查找某个用户某段时间的数据，scan 时只需要根据 userId 设置 startRow 和 stopRow 即可。 RowKey 性能的设计RowKey 是按照字典序存储，利用这个排序特点，将经常一起读取或者最近可能被访问到的数据存储到一块可以提高查询效率。 HotspottingIt is always advisable not to use sequential row keys, even though you get better scan results. More info here.Salting Row Key. To prevent hot spotting on writes, the row key may be “salted” by inserting a leading byte into the row key which is a mod over N buckets of the hash of the entire row key. This ensures even distribution of writes when the row key is a monotonically increasing value (often a timestamp representing the current time). Length of row keyFor each cell, rowkey details, column family, and qualifier details are stored. So it is always advisable to keep them as shot as possible, mainly because the same information is repeated on large scale. So whats nextsalt usage and its prefixing will help to distribute the rows among region servers.This can help you. ColumnFamily 的设计ColumnFamily 的长度The column family and column qualifier names are repeated for each row. Therefore, keep the names as short as possible to reduce the amount of data that HBase stores and reads. For example, use f:q instead of mycolumnfamily:mycolumnqualifier. ColumnFamily 的数量On the number of column familiesHBase currently does not do well with anything above two or three column families so keep the number of column families in your schema low. Currently, flushing and compactions are done on a per Region basis so if one column family is carrying the bulk of the data bringing on flushes, the adjacent families will also be flushed though the amount of data they carry is small. When many column families the flushing and compaction interaction can make for a bunch of needless i/o loading (To be addressed by changing flushing and compaction to work on a per column family basis). For more information on compactions, see compaction. (具体的细节见第2节) Try to make do with one column family if you can in your schemas. Only introduce a second and third column family in the case where data access is usually column scoped; i.e. you query one column family or the other but usually not both at the one time. Where multiple ColumnFamilies exist in a single table, be aware of the cardinality (i.e., number of rows). If ColumnFamilyA has 1 million rows and ColumnFamilyB has 1 billion rows, ColumnFamilyA’s data will likely be spread across many, many regions (and RegionServers). This makes mass scans for ColumnFamilyA less efficient. 建议HBASE列族的数量设置的越少越好。由于HBASE的FLUSHING和压缩是基于REGION的当一个列族所存储的数据达到FLUSHING阀值时，该表的所有列族将同时进行FLASHING操作，这将带来不必要的I/O开销。同时还要考虑到同一个表中不同列族所存储的记录数量的差别，即列族的势。当列族数量差别过大将会使包含记录数量较少的列族的数据分散在多个Region之上，而Region可能是分布是不同的RegionServer上。这样当进行查询等操作系统的效率会受到一定影响。 Column 的设计Column 的长度The column family and column qualifier names are repeated for each row. Therefore, keep the names as short as possible to reduce the amount of data that HBase stores and reads. For example, use f:q instead of mycolumnfamily:mycolumnqualifier. Column 的数量Column mapping: one to manyYou can map a single HBase entity (row key or a column) to multiple SQL columns. This kind of mapping is called one to many. HBase stores a lot of information for each value. If you stored each SQL column individually, the required storage space would be very large. For the best performance, put columns that are queried together into a single dense HBase column to help reduce the data that is fetched from HBase. A dense column is a single HBase column that maps to multiple SQL columns. For example, if table T1 has nine columns with 1.5 million rows. and you use a one-to-one mapping, this table requires 522 MB of storage. However, if table T1 uses a one-to-many mapping, the table requires only 276 MB of storage. 读 HBase 的性能HBase PoolUse pool of workers to parallel requests. You may find useful HTablePool class for managing connections in workers. 批量读通过调用 HTable.get(Get) 方法可以根据一个指定的 RowKey 获取一行记录，同样 HBase 提供了另一个方法：通过调用 HTable.get(List) 方法可以根据一个指定的 RowKey 列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高而且网络传输RTT高的情景下可能带来明显的性能提升。 Scan Scanner Cachinghbase.client.scanner.caching配置项可以设置HBase scanner一次从服务端抓取的数据条数，默认情况下一次一条。通过将其设置成一个合理的值，可以减少scan过程中next()的时间开销，代价是 scanner需要通过客户端的内存来维持这些被cache的行记录。 Scan AttributeSelectionscan时指定需要的Column Family，可以减少网络传输数据量，否则默认scan操作会返回整行所有Column Family的数据。 Close ResultScanner通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。 PrefixFilterPefixFilter Vs Scan HBase filters - even row filters - are really slow, since in most cases these do a complete table scan, and then filter on those results. Row key range scans however, are indeed much faster - they do the equivalent of a filtered table scan. This is because the row keys are stored in sorted order (this is one of the basic guarantees of HBase, which is a BigTable-like solution), so the range scans on row keys are very fast. Convert PrefixFilter to ScanPrefixFilter: abcScan ‘mytable’, {STARTROW =&gt; ‘abc’, ENDROW =&gt; ‘abd’} 如何解决事务 transactions over hbaseThe way HBase works is that locks are held in the regionserver (not in the client) when the Puts are applied to make sure that rows are written in an atomic block but it does not provide snapshot isolation (you need to use something like omid if you want that). Since HBase does not guarantee any consistency between regions (and each region is hosted at exactly one RegionServer) all MVCC data structures only need to be kept in memory on every region server. I would probably not use HBase for a use case like this. but if you must you can lock the row, read, update if needed - read more about lock and some of its problems here ngdata.com/hbase-row-locks . Again, I’d try to rethink the scenario for instance, HBase support multiple version so you can update anyway and sort things later (e.g. in a coprocessor that runs after update)RowLock and associated operations are deprecated in 0.94 and removed in 0.96.issues.apache.org/jira/browse/HBASE-7315 – Matt Ball hbase checkAndPuthbase checkandput performanceWhen you use checkAndPut() you do one RPC-call per request. So, you can’t achieve performance more then 1 / rtt requests per second (rtt is Round Trip Time). If you have rtt 1ms between your client and region server, your theoretical maximum is 1000 rps. When using batch operations like put(List) you need a lot less RPC-calls causing performance increase. Reference http://blog.linezing.com/2012/03/hbase-performance-optimization/https://www.ibm.com/support/knowledgecenter/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.analyze.doc/doc/bigsql_designhints.htmlhttp://blog.kissdata.com/2014/07/30/hbase-scheme-tips.htmlhttp://blog.chedushi.com/archives/9720https://www.mapr.com/blog/in-depth-look-hbase-architecture#.VdMxvWSqqkohttps://cloud.google.com/bigtable/docs/schema-designhttp://www.slideshare.net/alexbaranau/transactions-over-hbasehttps://hbase.apache.org/acid-semantics.html]]></content>
      <tags>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https详解]]></title>
    <url>%2F2016%2F04%2F17%2Fhttps%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[什么是https也称作HTTP over TLS 什么是SSL/TLS1994年，NetScape公司设计了SSL协议（Secure Sockets Layer）的1.0版，但是未发布。1995年，NetScape公司发布SSL 2.0版，很快发现有严重漏洞。1996年，SSL 3.0版问世，得到大规模应用。1999年，互联网标准化组织ISOC接替NetScape公司，发布了SSL的升级版TLS 1.0版。2006年和2008年，TLS进行了两次升级，分别为TLS 1.1版和TLS 1.2版。最新的变动是2011年TLS 1.2的修订版。TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。 为什么要有https在说HTTPS之前先说说什么是HTTP，HTTP就是我们平时浏览网页时候使用的一种协议。HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全。为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。 https保证安全的原理Client端和Server端如果用非对称加密的算法进行通信肯定是绝对安全的，因为私钥和密钥没有第三方知道。但是这样的问题是性能低下。但是如果用对称加密，很容易泄露密钥，安全性得不到保证。那么https是如何做的呢？大概原理就是使用非对称加密来交换一个密钥来进行对称加密。这个过程被称为SSL/TSL的四次握手，具体过程如下： Client端向Server端的443端口发出请求，带上随机数client_random和支持的加密方式列表 Server端返回随机数server_random ，选择的加密方式和服务器证书链 Client端验证这个证书是否合法，如果非法则提示用户是否“继续接受这个不可信的网站”，如果合法则使用证书中的公钥加密premaster secret发送给服务端 Server端使用私钥解密premaster secret，然后通过client_random，server_random 和premaster secret 生成master secret，用于对称加密后续通信内容。 Sever端用master secret加密最终需要返回的网站内容 Client端也用相同的方式生成这个master secret解密收到的消息 master_secret = PRF(pre_master_secret, “master secret”, ClientHello.random + ServerHello.random)[0..47]; 随机数为什么要三个？这是由于SSL/TLS设计，就假设服务器不相信所有的客户端都能够提供完全随机数，假如某个客户端提供的随机数不随机的话，就大大增加了“对话密钥”被破解的风险，所以由三组随机数组成最后的随机数，保证了随机数的随机性，以此来保证每次生成的“对话密钥”安全性。 那么问题来了 证书的安全性，Client端是如何验证证书合法性的，这个证书第三方无论如何都伪造不了吗？ 对称加密密钥的安全性，生成的master secret密钥第三方为什么拿不到？ 要解答这两个问题，首先得弄清楚什么是证书。 为什么证书是安全的？什么是证书数字证书就是互联网通讯中标志通讯各方身份信息的一串数字，提供了一种在Internet上验证通信实体身份的方式，数字证书不是数字身份证，而是身份认证机构盖在数字身份证上的一个章或印（或者说加在数字身份证上的一个签名）。它是由权威机构——CA机构，又称为证书授权（Certificate Authority）中心发行的，人们可以在网上用它来识别对方的身份。数字证书的格式普遍采用的是X.509V3国际标准，一个标准的X.509数字证书包含以下一些内容： 证书的版本信息； 证书的序列号，每个证书都有一个唯一的证书序列号； 证书所使用的签名算法； 证书的发行机构名称，命名规则一般采用X.500格式； 证书的有效期，通用的证书一般采用UTC时间格式，它的计时范围为1950-2049； 证书所有人的名称，命名规则一般采用X.500格式； 证书所有人的公开密钥； 证书发行者对证书的签名。 证书里的公钥的作用？证书里的签名的作用？数字证书的签发机构CA，在接收到申请者的资料后进行核对并确定信息的真实有效，然后就会制作一份符合X.509标准的文件。证书中的证书内容包含的持有者信息和公钥等都是由申请者提供的，而数字签名则是CA机构对证书内容进行hash加密后得到的，而这个数字签名就是我们验证证书是否是有可信CA签发的数据。 证书的产生 证书的类型实际上，我们使用的证书分很多种类型，SSL证书只是其中的一种。证书的格式是由X.509标准定义。SSL证书负责传输公钥，是一种PKI（Public Key Infrastructure，公钥基础结构）证书。我们常见的证书根据用途不同大致有以下几种：1、SSL证书，用于加密HTTP协议，也就是HTTPS。2、代码签名证书，用于签名二进制文件，比如Windows内核驱动，Firefox插件，Java代码签名等等。3、客户端证书，用于加密邮件。4、双因素证书，网银专业版使用的USB Key里面用的就是这种类型的证书。这些证书都是由受认证的证书颁发机构——我们称之为CA（Certificate Authority）机构来颁发，针对企业与个人的不同，可申请的证书的类型也不同，价格也不同。CA机构颁发的证书都是受信任的证书，对于SSL证书来说，如果访问的网站与证书绑定的网站一致就可以通过浏览器的验证而不会提示错误。 证书的安全问题如果让证书安全，那么就需要让客户端拿到的证书是真正想要的证书，即不能让证书被冒充或者被篡改。那么如何保证这一点呢？ 如果证书自己有一个id 证书的这个id无法被伪造 客户端知道自己想要的证书id是多少 如果做到了这三点就能保证证书的安全性了。上面说提到的id就是证书的数字签名。那么什么是数字签名？ 数字签名（digital signature）数字签名是证书的防伪标签，是将待签名内容通过哈希和私钥加密处理后生成的。目前使用最广泛的 SHA-RSA 数字签名的制作和验证过程如下： 数字签名的签发。首先是使用哈希函数对待签名内容进行安全哈希，生成数字摘要，然后使用CA自己的私钥对数字摘要进行加密。 数字签名的校验。使用CA的公钥解密签名，然后使用相同的签名函数对待签名证书内容进行签名并和服务端数字签名里的签名内容进行比较，如果相同就认为校验成功。 签发：待签名内容 -&gt; 哈希 -&gt; 数字摘要 -&gt; CA私钥加密 -&gt; 数字签名校验： 数字签名 -&gt; CA公钥解密 -&gt; 数字摘要1 待签名内容 -&gt; 哈希 -&gt; 数字摘要2 比较「数字摘要1」和「数字摘要2」是否相等 这里有几点需要说明： 数字签名签发和校验使用的密钥对是 CA 自己的公私密钥，跟证书申请者提交的公钥没有关系。 数字签名的签发过程跟公钥加密的过程刚好相反，即是用私钥加密，公钥解密。 现在大的 CA 都会有证书链，证书链的好处一是安全，保持根 CA 的私钥离线使用。第二个好处是方便部署和撤销，即如果证书出现问题，只需要撤销相应级别的证书，根证书依然安全。 根 CA 证书都是自签名，即用自己的公钥和私钥完成了签名的制作和验证。而证书链上的证书签名都是使用上一级证书的密钥对完成签名和验证的。 那么问题又来了。CA的私钥和公钥是安全的吗？可以被冒充吗？ CA的安全性从根CA开始到直接给客户发放证书的各层次CA，都有其自身的密钥对。CA中心的密钥对一般由硬件加密服务器在机器内直接产生，并存储于加密硬件内，或以一定的加密形式存放于密钥数据库内。加密备份于IC卡或其他存储介质中，并以高等级的物理安全措施保护起来。密钥的销毁要以安全的密钥冲写标准，彻底清除原有的密钥痕迹。需要强调的是，根CA密钥的安全性至关重要，它的泄露意味着整个公钥信任体系的崩溃，所以CA的密钥保护必须按照最高安全级 的保护方式来进行设置和管理。 CA的私钥是自己靠上述方法保管的，不对外公开。CA的公钥是厂商跟浏览器和操作系统合作，把公钥默认装到浏览器或者操作系统环境里。比如firefox 就自己维护了一个可信任的 CA 列表，而chrome 和 IE 使用的是操作系统的 CA 列表。 证书验证失败的原因1、SSL证书不是由受信任的CA机构颁发的(注意这种情况并不一定说明有SSL劫持发生)2、证书过期3、访问的网站域名与证书绑定的域名不一致 至此，可以知道证书在一定程度上是非常安全的，客户端只要收到的证书是合法的，就能很大程度上保证整个会话是安全的。 客户端具体是如何验证SSL证书的为了抵御这种中间人攻击，SSL证书需要由可信的SSL证书颁发机构颁发，形成一个证书链（比如Gmail的证书链为：最底层为网域 mail.google.com，上一层为Thawte SGC CA证书颁发机构，最顶层为很有名的VeriSign证书颁发机构）。那么，浏览器除了需要验证域和有效期外，还要检查证书链中的上级证书公钥是否有效，上级的上级证书公钥是否有效，直至根证书公钥为止。这样就可以有效避免中间人攻击了，因为根证书公钥都是预装在操作系统中的，黑客如果不是暴力破解，无法得到根证书的私钥。如果黑客自己生成一个私钥，浏览器验证根证书公钥的时候发现无法通过操作系统中预装的公钥加密数据后使用这个私钥进行解密，从而判定这个公钥是无效的。这个方案也是现在https通讯通常的方案。 那么，这个现在所有的浏览器正在使用的https通讯方案就无懈可击了吗？答案仍是否定的。我们可以看到，在后一个方案中，https的安全性需要在证书颁发机构公信力的强有力保障前提下才能发挥作用。如果证书颁发机构在没有验证黑客为mail.google.com的持游者的情况下，给黑客颁发了网域为mail.google.com的证书，那么黑客的中间人攻击又可以顺利实施然而，不验证域名持有者就颁发证书的情况在国外几乎不会发生，但是在国内就不一定了。针对破解目标，国内证书颁发机构WoSign（在此只是举例国内比较有名的证书颁发机构WoSign，并不代表WoSign今后一定会这么做）很有可能为了上级要求颁发了证书给非域名持有者的黑客，从而使得破解目标的Gmail密码被黑客截取。 涉及到的算法非对称加密算法：RSA，DSA/DSS对称加密算法：AES，RC4，3DESHASH算法：MD5，SHA1，SHA256 总结整个过程是递进的，一步一步了解https安全的原理。 https如何保证安全又高效？https使用非对称加密算法来交换对称加密的密钥，最后使用对称加密算法来进行通信。 如何保证非对称加密时的安全性？服务端发送证书来传递非对称加密的公钥。保证了公钥和私钥的保密性。 客户端怎么知道证书是不是真的？客户端根据CA证书的公钥校验证书的数字签名来保证其合法性。 客户端的CA证书不会被伪造或泄露吗？CA证书是默认预装到浏览器和操作系统中的，所以CA证书的公钥是安全的。 Reference http://op.baidu.com/2015/04/https-s01a01/https://cipherstuff.wordpress.com/http://oncenote.com/2014/10/21/Security-1-HTTPS/http://www.williamlong.info/archives/2058.htmlhttp://www.ruanyifeng.com/blog/2014/02/ssl_tls.html]]></content>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - Perfect Squares]]></title>
    <url>%2F2016%2F03%2F27%2FLeetCode-Perfect-Squares%2F</url>
    <content type="text"><![CDATA[Problem Description：Given a positive integer n, find the least number of perfect square numbers (for example, 1, 4, 9, 16, …) which sum to n.For example, given n = 12, return 3 because 12 = 4 + 4 + 4; given n = 13, return 2 because 13 = 4 + 9. Solution:Solution1:Dynamic ProgrammingTime Complexity: O(n*sqrt(n))Space: O(n) Solution2:Number Theory Legendre’s three-square theorem Lagrange’s four-square theorem Time Complexity: O(sqrt(n))Space: O(1) Code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.zane.algorithm.leetcode;/** * Author: luojinping * Date: 15/9/23 * Time: 17:23 * &lt;p/&gt; * &lt;p/&gt; * Given a positive integer n, find the least number of perfect square numbers * (for example, 1, 4, 9, 16, ...) which sum to n. * For example, given n = 12, return 3 because 12 = 4 + 4 + 4; given n = 13, * return 2 because 13 = 4 + 9. */public class PerfectSquares_279 &#123; /** * cannot use greedy algorithm, counter example： * 98=81+16+1=49+49 * 101=100+1=49+1+49+2 * 7=4+1+1+1 * 12=4+4+4=9+1+1+1 * 思路: * 使用DP, dp[]数组记录历史使用最少平方数的情况.例如dp[5]=2,记录的是使用最少(1+4)平方数的数量,即2. * * @param n * @return */ public int numSquares(int n) &#123; if (n &lt;= 2) &#123; return n; &#125; // record the least number of perfect numbers when index = i int[] dp = new int[n + 1]; dp[0] = 0; dp[1] = 1; dp[2] = 2; for (int i = 3; i &lt;= n; i++) &#123; int leastNum = i; for (int j = 1; j * j &lt;= i; j++) &#123; leastNum = Math.min(leastNum, dp[i - j * j] + 1); &#125; dp[i] = leastNum; &#125; return dp[n]; &#125; private boolean isSquare(int n) &#123; int sqrt_n = (int) (Math.sqrt(n)); return (sqrt_n * sqrt_n == n); &#125; /** * Legendre's three-square theorem: * The three squares theorem tells you that a positive integer n can be represented as the sum * of 3 squares (n = x^2 + y^2 + z^2) if and only if it is not of the form n = 4^a * (8 * b+7) * &lt;p/&gt; * Lagrange's four-square theorem: * Every natural number can be represented as the sum of four integer squares: * n= a^2 + b^2 + c^2 + d^2 * &lt;p/&gt; * &lt;p/&gt; * So the are only 4 possible results: 1, 2, 3, 4. * &lt;p/&gt; * Refer: * https://leetcode.com/discuss/58056/summary-of-different-solutions-bfs-static-and-mathematics */ public int numSquaresByMath(int n) &#123; // If n is a perfect square, return 1. if (isSquare(n)) &#123; return 1; &#125; // The result is 4 if and only if n can be written in the // form of 4^k*(8*m + 7). Please refer to // Legendre's three-square theorem. while ((n &amp; 3) == 0) // n%4 == 0 &#123; n &gt;&gt;= 2; &#125; if ((n &amp; 7) == 7) // n%8 == 7 &#123; return 4; &#125; // Check whether 2 is the result. int sqrt_n = (int) (Math.sqrt(n)); for (int i = 1; i &lt;= sqrt_n; i++) &#123; if (isSquare(n - i * i)) &#123; return 2; &#125; &#125; return 3; &#125; public static void main(String[] args) &#123; PerfectSquares_279 perfectSquares279 = new PerfectSquares_279(); System.out.println(perfectSquares279.numSquares(4)); System.out.println(perfectSquares279.numSquares(7)); System.out.println(perfectSquares279.numSquares(12)); System.out.println(perfectSquares279.numSquares(61)); System.out.println(perfectSquares279.numSquares(100)); System.out.println(perfectSquares279.numSquares(101)); &#125;&#125; Reference https://leetcode.com/discuss/58056/summary-of-different-solutions-bfs-static-and-mathematics]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode - The Skyline Problem]]></title>
    <url>%2F2016%2F03%2F26%2FLeetCode-The-Skyline-Problem%2F</url>
    <content type="text"><![CDATA[Problem DescriptionA city’s skyline is the outer contour of the silhouette formed by all the buildings in that city when viewed from a distance. Now suppose you are given the locations and height of all the buildings as shown on a cityscape photo (Figure A), write a program to output the skyline formed by these buildings collectively (Figure B). Buildings Skyline ContourThe geometric information of each building is represented by a triplet of integers [Li, Ri, Hi], where Li and Ri are the x coordinates of the left and right edge of the ith building, respectively, and Hi is its height. It is guaranteed that 0 ≤ Li, Ri ≤ INT_MAX, 0 &lt; Hi ≤ INT_MAX, and Ri - Li &gt; 0. You may assume all buildings are perfect rectangles grounded on an absolutely flat surface at height 0. For instance, the dimensions of all buildings in Figure A are recorded as: [ [2 9 10], [3 7 15], [5 12 12], [15 20 10], [19 24 8] ] . The output is a list of “key points” (red dots in Figure B) in the format of [ [x1,y1], [x2, y2], [x3, y3], … ] that uniquely defines a skyline. A key point is the left endpoint of a horizontal line segment. Note that the last key point, where the rightmost building ends, is merely used to mark the termination of the skyline, and always has zero height. Also, the ground in between any two adjacent buildings should be considered part of the skyline contour. For instance, the skyline in Figure B should be represented as:[ [2 10], [3 15], [7 12], [12 0], [15 10], [20 8], [24, 0] ]. Notes: The number of buildings in any input list is guaranteed to be in the range [0, 10000]. The input list is already sorted in ascending order by the left x position Li. The output list must be sorted by the x position.There must be no consecutive horizontal lines of equal height in the output skyline. For instance, […[2 3], [4 5], [7 5], [11 5], [12 7]…] is not acceptable; the three lines of height 5 should be merged into one in the final output as such: […[2 3], [4 5], [12 7], …] problem link:https://leetcode.com/problems/the-skyline-problem/ Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TheSkylineProblem_218 &#123; public List&lt;int[]&gt; getSkylineSimpleSolution(int[][] buildings) &#123; List&lt;int[]&gt; result = new ArrayList&lt;&gt;(); List&lt;int[]&gt; height = new ArrayList&lt;&gt;(); // height &lt; 0: the height of building started // height &gt; 0: the height of building ended for (int[] b : buildings) &#123; height.add(new int[]&#123;b[0], -b[2]&#125;); height.add(new int[]&#123;b[1], b[2]&#125;); &#125; // sorted by x value, if x equals then sorted by y value Collections.sort(height, (a, b) -&gt; &#123; if (a[0] != b[0]) return a[0] - b[0]; return a[1] - b[1]; &#125;); // record the height of visited buildings by reverse order Queue&lt;Integer&gt; pq = new PriorityQueue&lt;&gt;((a, b) -&gt; (b - a)); pq.offer(0); int prevHeight = 0; for (int[] h : height) &#123; if (h[1] &lt; 0) &#123; // save the height of building pq.offer(-h[1]); &#125; else &#123; // remove the height of building pq.remove(h[1]); &#125; int curHeight = pq.peek(); if (prevHeight != curHeight) &#123; // find the turn point result.add(new int[]&#123;h[0], curHeight&#125;); prevHeight = curHeight; &#125; &#125; return result; &#125;&#125; 算法解释算法思路 遍历所有的点，height用来存放每个顶点，左顶点的高度转为负数，右顶点的高度仍然是正数 对height数组排序，首先按x的值排序，当x的值相等时按z排序，这样保证了即使矩形的起点一样，也是最先处理最高的点。对于[{1,2,1},{1,2,2},{1,2,3}]这样的情况会优先处理{1,2,3}这个点。 使用优先级队列pq来保存当前最近buildings的高度，这个结构很重要！ 遍历height数组，碰到左顶点时，将高度放入pq中，否则，碰到右顶点时则将高度从pq从移除。这样做的好处是，每次走完一个矩形时，高度能回归到之前的buildings的高度。 获取当前的最高高度，因为如果比当前矮的话，是不需要放入拐点中的，这点很重要！ 如果当前的最高高度和之前的高度不一致，说明出现了拐点。**如果当前的最高高度矮于之前的值，说明之前的很高的建筑遇到了它的右顶点从而被移除了，所以目前的最高高度即使矮于之前的点，但是是新的隔离的building了，所以可以加入。那么如果高呢？当前高度比之前高，那肯定会是拐点了。 总结几个关键点： 对顶点进行排序保存，对左右顶点根据正负号来加以区分 使用一个优先级队列来保存目前最高的建筑 碰到右顶点时消除目前的建筑高度 根据之前的高度和处理目前顶点以后(可能是加入了高度也可能是消除了之前的高度)的高度，对两者进行比较来找到拐点 Reference https://leetcode.com/discuss/54201/short-java-solution]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扔鸡蛋测楼层]]></title>
    <url>%2F2016%2F03%2F03%2F%E6%89%94%E9%B8%A1%E8%9B%8B%E6%B5%8B%E6%A5%BC%E5%B1%82%2F</url>
    <content type="text"><![CDATA[扔瓶子测楼层一栋楼有n层，需要测试某种材质的玻璃瓶从哪一层掉下来恰好会碎。现在仅有两个这样的瓶子。请问怎样仍才能最快的测出楼层的临界值？ A. 只用一个瓶子从第一层扔到第n层找到临界值的扔瓶子次数的期望为每一层的期望次数之和 1E(x) = 1/n * 1 + 1/n * 2 + 1/n * 3 + ... + 1/n * n = (1+n)/2 所以时间复杂度是O(n) B. 用贪心的思维第一个瓶子从第1层开始扔，每次层数翻倍，依次为，1，2，4，8，16，直至在第 2^k 层碎掉。第二个瓶子从第 2^(k-1) 层开始扔，直至第 2^k 层为止，中间肯定能找到临界值。所以时间复杂度是O(lgn) C. 用二分法第一个瓶子每次以(i, j)为区间，扔的位置为(i+j)/2, 初始情况, i=0,j=n, 如果瓶子没碎，则i=j，直至碎掉。第二个瓶子从第 i 层开始扔，直至第 j 层为止，中间肯定能找到临界值。 对于第 i 层，扔的情况为： 第一个瓶子：n/2, $/2+n/4 i, n/2+n/4+n/8 第二个瓶子：n/2+n/4, (n/2+n/k+1), …, i 显而易见，时间复杂度是O(n) D. 数学推算这个题目是需要最快的找出临界值，可以转换为，即使在最坏的情况下，也能最快地找出临界值。 我们先假设最坏情况下，瓶子下落次数为x，即我们为了找出N，一共用瓶子做了x次的实验。 那么，我们第一次应该在哪层楼往下扔瓶子呢？ 先让我们假设第一次是在第y层楼扔的瓶子，如果第一个瓶子在第一次扔就碎了，我们就只剩下一个瓶子，要用它准确地找出N，只能从第一层向上，一层一层的往上测试，直到它摔坏为止，答案就出来了。 由于第一个瓶子在第y层就摔破了，所以最坏的情况是第二个瓶子要把第1到第y-1层的楼都测试一遍，最后得出结果，噢，原来瓶子在第y-1层才能摔破(或是在第y-1层仍没摔破，答案就是第y层。) 这样一来测试次数是1+(y-1)=x，即第一次测试要在第x层。 OK，那如果第一次测试鸡蛋没摔破呢，那N肯定要比x大，要继续往上找，需要在哪一层扔呢？我们可以模仿前面的操作，如果第一个瓶子在第二次测试中摔破了，那么第二个瓶子的测试次数就只剩下x-2次了(第一个瓶子已经用了2次)。这样一来，第二次扔瓶子的楼层和第一次扔瓶子的楼层之间就隔着x-2层。 我们再回过头来看一看，第一次扔瓶子的楼层在第x层，第1层到第x层间共x层；第1次扔鸡蛋的楼层到第2次扔瓶子的楼层间共有x-1层(包含第2次扔瓶子的那一层)，同理继续往下，我们可以得出，第2次扔瓶子的楼层到第3次扔瓶子的楼层间共有x-2层，最后把这些互不包含的区间数加起来，应该大于等于总共的楼层数量100，即 123x + (x-1) + (x-2) + ... + 1 &gt;= 100(x+1)*x/2 &gt;= 100得出答案是14 即我先用第1个瓶子在以下序列表示的楼层数不断地向上测试，直到它摔破。 再用第2个瓶子从上一个没摔破的序列数的下一层开始，向上测试，即可保证在最坏情况下也只需要测试14次，就能用2个瓶子找出从哪一层开始，往下扔鸡蛋，瓶子就会摔破。 114, 27, 39, 50, 60, 69, 77, 84, 90, 95, 99, 100 E. DP的解法假设f(n)表示从第n层楼扔下鸡蛋，没有摔碎的最少尝试次数。第一个鸡蛋，可能的落下位置[1,n],第一个鸡蛋从第i层扔下，有两种情况： 碎了，第二个鸡蛋，需要从第一层开始试验，有i-1次机会 没碎，两个鸡蛋，还有n-i层。这个就是子问题了f(n-i) 所以，当第一个鸡蛋，由第i个位置落下的时候，要尝试的次数为 1 + max{i - 1, f(n - i)}，那么对于每一个i，尝试次数最少的，就是f(n)的值。状态转移方程如下： 1f(n) = min&#123;1 + max&#123;i - 1, f(n - 1)&#125;&#125; 其中: i的范围为[1, n], f(1) = 1. F. 推广到一般化的问题为n层楼，m个鸡蛋。如下分析： 假设f(n,m)表示n层楼、m个鸡蛋时找到最高楼层的最少尝试次数。当第一个鸡蛋从第i层扔下，有两种情况： 碎了，还剩m-1个鸡蛋，为确定下面楼层中的安全楼层，还需要f(i-1,m-1)次，找到子问题 不碎，上面还有n-i层，还需要f(n-i,m)次，又一个子问题。 状态转移方程如下： 1f(n, m) = min&#123;1 + max&#123;f(n - 1, m - 1), f(n - i, m)&#125;&#125; 其中： i为[1, n], f(i, 1) = 1 Reference http://www.cricode.com/3558.htmlhttps://gist.github.com/sing1ee/5971946]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快排算法]]></title>
    <url>%2F2016%2F02%2F27%2F%E5%BF%AB%E6%8E%92%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[快速排序的思路12345algorithm quicksort(A, lo, hi) is if lo &lt; hi then p := partition(A, lo, hi) quicksort(A, lo, p – 1) quicksort(A, p + 1, hi) 快速排序的partition方式一种是Lomuto partition scheme，另外一种是Hoare partition scheme。 Lomuto partitionThis scheme is attributed to Nico Lomuto and popularized by Bentley in his book lomuto的partition实现方式i指示最前面的大于pivot的元素位置，j从前往后滑动来调整元素位置。每次j碰到小于pivot的元素，则swap i位置的元素和j位置的元素，再i指向下一个大于pivot的元素。最后，记得swap i位置的元素和最末尾的元素。 12345678910111213private int lomutoPartition(int nums[], int lo, int hi) &#123; int pivot = nums[hi]; int i = lo; for (int j = lo; j &lt; hi; j++) &#123; if (nums[j] &lt;= pivot) &#123; swap(nums, i, j); i++; &#125; &#125; swap(nums, i, hi); // replace the guard element return i; &#125; Hoare partition schemeThe original partition scheme described by C.A.R. Hoare uses two indices that start at the ends of the array being partitioned, then move toward each other, until they detect an inversion. Hoare’s scheme is more efficient than Lomuto’s partition scheme because it does three times fewer swaps on average, and it creates efficient partitions even when all values are equal. hoare的partition实现方式i从前往后找到大于pivot的元素，j从后往前找到小于pivot的元素，然后两者swap. 12345678910111213141516171819private int hoarePartition(int nums[], int lo, int hi) &#123; int pivot = nums[lo]; int i = lo, j = hi; while (true) &#123; while (nums[i] &lt; pivot) &#123; i++; &#125; while (nums[j] &gt;= pivot) &#123; j--; &#125; if (i &gt;= j) &#123; return j; &#125; swap(nums, i, j); &#125; &#125;]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬币找零问题]]></title>
    <url>%2F2016%2F02%2F20%2F%E7%A1%AC%E5%B8%81%E6%89%BE%E9%9B%B6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[硬币找零问题(Coin Change)QuestionYou are given coins of different denominations and a total amount of money amount. Write a function to compute the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return -1. Example 1:coins = [1, 2, 5], amount = 11return 3 (11 = 5 + 5 + 1) Example 2:coins = [2], amount = 3return -1. Note:You may assume that you have an infinite number of each kind of coin. DP求解如果是用DP求解，那么思路首先就是找到子问题。子问题很容易确定，那就是amount-x是子问题的amount。比较容易想到的代码实现如下： 12345678910111213141516public int coinChange(int[] coins, int amount) &#123; if (amount == 0) return 0; int n = amount + 1; // the answer must smaller than [amount+1], nice! for (int coin : coins) &#123; int curr = 0; if (amount &gt;= coin) &#123; int next = coinChange(coins, amount - coin); if (next &gt;= 0) curr = 1 + next; &#125; if (curr &gt; 0) n = Math.min(n, curr); &#125; return (n == amount + 1) ? -1 : n; &#125; 上述算法的时间复杂度为O(c^n),c是coin的数量，n是amount的值。 时间复杂度较大的原因是，中间存在很多重复计算。那么需要用到DP的备忘录，不用全局变量来保存计算过的值，也不用递归的方法来实现，而是只用一个一维数组，再用循环来实现。代码如下： 12345678910111213141516public int coinChange(int[] coins, int amount) &#123; if (coins == null || coins.length == 0 || amount &lt;= 0) return 0; int[] minNumber = new int[amount + 1]; for (int i = 1; i &lt;= amount; i++) &#123; minNumber[i] = amount + 1; for (int j = 0; j &lt; coins.length; j++) &#123; if (coins[j] &lt;= i &amp;&amp; minNumber[i - coins[j]] != amount + 1) minNumber[i] = Integer.min(minNumber[i], 1 + minNumber[i - coins[j]]); &#125; &#125; if (minNumber[amount] == amount + 1) return -1; else return minNumber[amount]; &#125;]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[判断图是否为树]]></title>
    <url>%2F2016%2F02%2F02%2F%E5%88%A4%E6%96%AD%E5%9B%BE%E6%98%AF%E5%90%A6%E4%B8%BA%E6%A0%91%2F</url>
    <content type="text"><![CDATA[题目输入二维数组，a[i][j]=1 表示从i结点指向j结点。 eg10 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 是一棵树，树为： 123456789 a / \ b c / d eg20 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 不是一颗树，是有环(a-b-d-c-a)的图： 123456789 a / \ b c / / d - — - 关键点判断一张图是否是一颗树的两个关键点： 不存在环路(对于有向图，不存在环路也就意味着不存在强连通子图) 满足边数加一等于顶点数的规律(不考虑重边和指向自身的边) 方法 DFS 如果存在回路，则必存在一个子图，是一个环路。环路中所有顶点的度&gt;=2。时间复杂度O(ve)，v是顶点数，e是边数。第一步：删除所有度&lt;=1的顶点及相关的边，并将另外与这些边相关的其它顶点的度减一。 第二步：将度数变为1的顶点排入队列，并从该队列中取出一个顶点重复步骤一。如果最后还有未删除顶点，则存在环，否则没有环。这个复杂度也很高 结合树的特性(边数+1 = 顶点数)和并查集来做，代码见下文。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import java.util.ArrayList;import java.util.List;public class TreeJudgeUnionB &#123; private static class Edge &#123; int start; int end; public Edge(int start, int end) &#123; this.start = start; this.end = end; &#125; &#125; // the number of edges private int n; // edge list private List&lt;Edge&gt; edges = new ArrayList&lt;&gt;(); // the index of group private int[] group; // the size of tree private int[] size; public TreeJudgeUnionB(int n, List&lt;Edge&gt; edges) &#123; this.n = n; this.edges = edges; group = new int[n]; size = new int[n]; for (int i = 0; i &lt; n; i++) &#123; group[i] = i; size[i] = 1; &#125; &#125; private int find(int i) &#123; // find the root of a tree which contains i node while (i != group[i]) &#123; i = group[i]; &#125; return i; &#125; private boolean union(int groupI, int groupJ) &#123; int iRoot = find(groupI); int jRoot = find(groupJ); if (iRoot != jRoot) &#123; if (size[iRoot] &lt; size[jRoot]) &#123; group[iRoot] = jRoot; size[jRoot] += size[iRoot]; &#125; else &#123; group[jRoot] = iRoot; size[iRoot] += size[jRoot]; &#125; return true; &#125; else &#123; return false; &#125; &#125; public boolean isTree() &#123; for (Edge edge : edges) &#123; if (!union(edge.start, edge.end)) &#123; System.out.println("input two nodes in the same tree"); return false; &#125; &#125; boolean hasRoot = false; for (int i = 0; i &lt; group.length; i++) &#123; if (i == group[i]) &#123; if (!hasRoot) &#123; hasRoot = true; &#125; else &#123; System.out.println("exist more than one tree root"); return false; &#125; &#125; &#125; printGroup(); return hasRoot; &#125; public void printGroup() &#123; for (int i = 0; i &lt; n; i++) &#123; System.out.print(group[i] + ", "); &#125; System.out.println(); &#125; public static void main(String[] args) &#123; int n = 5; List&lt;Edge&gt; edges = new ArrayList&lt;&gt;(); addEdge(edges, 0, 1); addEdge(edges, 0, 2); addEdge(edges, 2, 3); addEdge(edges, 2, 4); isTree(n, edges); // true n = 5; edges.clear(); addEdge(edges, 0, 1); addEdge(edges, 1, 2); addEdge(edges, 0, 2); addEdge(edges, 2, 3); addEdge(edges, 2, 4); isTree(n, edges); // false n = 4; edges.clear(); addEdge(edges, 0, 1); addEdge(edges, 2, 3); isTree(n, edges); // false n = 7; edges.clear(); addEdge(edges, 0, 1); addEdge(edges, 1, 2); addEdge(edges, 4, 5); addEdge(edges, 3, 4); addEdge(edges, 2, 3); addEdge(edges, 0, 6); isTree(n, edges); // true &#125; protected static void addEdge(List&lt;Edge&gt; edges, int i, int j) &#123; edges.add(new Edge(i, j)); &#125; protected static void isTree(int n, List&lt;Edge&gt; edges) &#123; TreeJudgeUnionB treeJudgeUnionA = new TreeJudgeUnionB(n, edges); boolean isTree = treeJudgeUnionA.isTree(); System.out.println("This is a tree? " + isTree); &#125;&#125;]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并查集(Union-Find)算法]]></title>
    <url>%2F2016%2F02%2F02%2F%E5%B9%B6%E6%9F%A5%E9%9B%86-Union-Find-%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[介绍在计算机科学中，并查集是一种树型的数据结构，其保持着用于处理一些不相交集合（Disjoint Sets）的合并及查询问题。有一个联合-查找算法（union-find algorithm）定义了两个操作用于此数据结构： Find：确定元素属于哪一个子集。它可以被用来确定两个元素是否属于同一子集。 Union：将两个子集合并成同一个集合。 适用场景适合于判断，给出一组结点，判断他们是否联通。 实现思路 建立n个分组，每个分组代表一堆可以互相联通的结点。 遍历每对结点，找到他们各自所属的分组A, B 如果A != B，则将A, B分组union起来，表示A, B分组联通了 如果A == B，则跳过 Simple Find 操作用 group[] 数组来判断某个id属于的组。初始状态时，每个id都属于不同的组。 12for(int i = 0; i &lt; size; i++) group[i] = i; Simple Union 操作1234567891011121314151617public void union(int p, int q) &#123; // get the groupId of every node int pId = find(p); int qId = find(q); // the two nodes are connected, return if (pId == qId) &#123; return; &#125; // union the two nodes, change groupId for (int i = 0; i &lt; id.length; i++) &#123; if (group[i] == pId) &#123; group[i] = qId; &#125; &#125;&#125; 优化上面最后一步的union操作存在性能问题，即每次都需要改变其中一个分组中的所有结点的分组id。优化的做法是，用一颗树来表示每个分组，树的根节点表示当前组的id。 但如果用树来表示会引入一个问题，即可能存在树退化为链表的情况，这样一来，每一次加入一个结点再找根结点也会很耗时，没有达到优化的目的。针对树可能退化为链表的解决方案是，每次合并树时，总是将矮的树挂到高的树下。这种方式也称为「按秩合并」 除了使用树来优化union性能以外，还有一种方式，称为「路径压缩」，即 Find 递归地经过树，改变每一个节点的引用到根节点。得到的树将更加扁平，为以后直接或者间接引用节点的操作加速。 总结： 使用树来存储分组，Union时「按秩合并」 「路径压缩」，Find时改变每一个节点的引用到根节点 Find 操作123// store every tree's sizefor (int i = 0; i &lt; N; i++) size[i] = 1; 12345678private int find(int p) &#123; if(p != group[p])&#123; group[p] = find(group[p]) &#125; return group[p]&#125; Union 操作1234567891011121314151617public void union(int p, int q)&#123; int i = find(p); int j = find(q); if (i == j) &#123; return; &#125; if (size[i] &lt; size[j]) &#123; group[i] = j; size[j] += size[i]; &#125; else &#123; group[j] = i; size[i] += size[j]; &#125;&#125; 时间复杂度Statement: If m operations, either Union or Find, are applied to n elements, the total run time is O(m logn), where log is the iterated logarithm.Proof of O(logn) time complexity of union-find: https://en.wikipedia.org/wiki/Proof_of_O\(logn)_time_complexity_of_union%E2%80%93find Reference https://zh.wikipedia.org/wiki/%E5%B9%B6%E6%9F%A5%E9%9B%86http://blog.csdn.net/dm_vincent/article/details/7655764https://en.wikipedia.org/wiki/Proof_of_O(log*n)_time_complexity_of_union%E2%80%93find]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初学Spark]]></title>
    <url>%2F2016%2F01%2F22%2F%E5%88%9D%E5%AD%A6Spark%2F</url>
    <content type="text"><![CDATA[避免使用 GroupByKey当调用 groupByKey 时，所有的键值对(key-value pair) 都会被移动。在网络上传输这些数据非常没有必要。 以下函数应该优先于 groupByKey : combineByKey组合数据，但是组合之后的数据类型与输入时值的类型不一样。 foldByKey合并每一个 key 的所有值，在级联函数和“零值”中使用。 combineByKeycombineByKey的定义123456789def combineByKey[C]( createCombiner: V =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt; C, partitioner: Partitioner, mapSideCombine: Boolean = true, serializer: Serializer = null): RDD[(K, C)] = &#123; // do something&#125; combineByKey函数主要接受了三个函数作为参数，分别为createCombiner、mergeValue、mergeCombiners。这三个函数足以说明它究竟做了什么。理解了这三个函数，就可以很好地理解combineByKey。 createCombinercreateCombiner：在遍历RDD的过程中，对于遍历到的(k,v)，如果是第一次遇到，则对这个(k,v)调用createCombiner函数，它的作用是将v转换为c(类型是C，即聚合对象的类型，c作为聚合对象的初始值) mergeValuemergeValue：在遍历RDD的过程中，对于遍历到的(k,v)，如果不是第一次(而是第i次, 1 &lt; i &lt;= n)遇到，那么将对这个(k,v)调用mergeValue函数，它的作用是将v累加到聚合对象（类型C）中，mergeValue的类型是(C,V)=&gt;C,参数中的C遍历到此处的聚合对象，然后对v进行聚合得到新的聚合对象值 mergeCombinersmergeCombiners：因为combineByKey是在分布式环境下执行，RDD的每个分区单独进行combineByKey操作，最后需要对各个分区的结果进行最后的聚合。它的函数类型是(C,C)=&gt;C，每个参数是分区聚合得到的聚合对象。 combineByKey的流程 假设一组具有相同 K 的 records 正在一个个流向 combineByKey()，createCombiner 将第一个 record 的value 初始化为 c （比如，c = value），然后从第二个 record 开始，来一个 record 就使用 mergeValue(c, record.value) 来更新 c，比如想要对这些 records 的所有 values 做 sum，那么使用 c = c + record.value。等到records 全部被 mergeValue()，得到结果 c。假设还有一组 records（key 与前面那组的 key 均相同）一个个到来， combineByKey() 使用前面的方法不断计算得到 c’。现在如果要求这两组 records 总的 combineByKey() 后的结果，那么可以使用 final c = mergeCombiners(c, c’) 来计算。 Example1234567var rdd1 = sc.makeRDD(Array(("A",1),("A",2),("A",3),("B",1),("B",2),("C",3)))// result: ((A,1_$2_@3), (B,1_$2_), (C,3_))rdd1.combineByKey( (v : Int) =&gt; v + "_", (c : String, v : Int) =&gt; c + "@" + v, (c1 : String, c2 : String) =&gt; c1 + "$" + c2 ).collect combineByKey应用举例求均值1234567891011121314151617181920val rdd = sc.textFile("气象数据")val rdd2 = rdd.map(x=&gt;x.split(" ")).map(x =&gt; (x(0).substring("从年月日中提取年月"),x(1).toInt))val createCombiner = (k: String, v: Int)=&gt; &#123; (v,1)&#125;val mergeValue = (c:(Int, Int), v:Int) =&gt; &#123; (c._1 + v, c._2 + 1)&#125;val mergeCombiners = (c1:(Int,Int),c2:(Int,Int))=&gt;&#123; (c1._1 + c2._1, c1._2 + c2._2)&#125;val vdd3 = vdd2.combineByKey( createCombiner, mergeValue, mergeCombiners)rdd3.foreach(x=&gt;println(x._1 + ": average tempreture is " + x._2._1/x._2._2)]]></content>
      <tags>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Run Age of Empires II in Max OS 10.11]]></title>
    <url>%2F2016%2F01%2F04%2FRun-Age-of-Empires-II-in-Max-OS-10-11%2F</url>
    <content type="text"><![CDATA[Step1 Find the resourcesearch in Google， steam 上已经没有了。 Step2 Fix the Max OS 10.11 bugAn error occured while starting the X11 server: Failed to activate core devices” Click Quit to quit X11. Click Report to see more details or send a report to Apple. 在 https://www.reddit.com/r/OSXElCapitan/comments/3d64sd/wineskin/ 找到解决方法。即:open terminal: mkdir/libcp -r /Applications/aoeHD.app/Contents/Frameworks/* /lib 此时再打开游戏，成功运行，听到了熟悉的声音。 Referencehttps://www.reddit.com/r/OSXElCapitan/comments/3d64sd/wineskin/]]></content>
      <tags>
        <tag>Mix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 技巧]]></title>
    <url>%2F2016%2F01%2F03%2Fskills%2F</url>
    <content type="text"><![CDATA[将数据转成json格式：python -m json.tool1234$ echo '&#123;"json":"obj"&#125;' | python -m json.tool&#123;"json": "obj"&#125; 查看gzip数据使用python的zlib库来解压 12345s=&apos;\x1F\x8B\x08\x00\x00\x00\x00\x00\x00\x005N\xCD\x0A\xC3 \x18&#123;\x97\xEF,\xE5s\xF3gz\xAB\xA0/1z\x18\xC31\x87m\xA5\xEA\xA1\x94\xBE\xFB\xBE\xC3vJHB\x92\x03z\x8D\xDBXJ\x05&#123;?\xA0,`\xE1\xB9\xCEC\xEB\x9F\xF4\x18\xDEk\x8B\x19\x18\xD4\x99d\xC9/\xCE\xF9\x10Ft\xE1\xAA\x9DFm\x8C\x92B)w\xF3\x02\xBD\xA1\x5C\xA3\x16.\x84\xE4\x5CHD\x94\x82Ao`\x97\x9E3\x83Df\xDBzdP\xD2_&#123;\x11C\x06\xB9\x13\x9C\x13\x0D\xED\xF5\xF7e:\xBF\xAB \xDB\x10\x9B\x00\x00\x00&apos; import zlibd=zlib.decompressobj(16+zlib.MAX_WBITS) data=d.decompress(s) 统计服务器上的历史登录记录1last -ad | awk '&#123;print $1&#125;' | sort | uniq -c | sort -t$'\t' -k1,1 -nr linux文件格式转换在linux下，不可避免的会用VIM打开一些windows下编辑过的文本文件。我们会发现文件的每行结尾都会有一个^M符号，这是因为DOS下的编辑器和Linux编辑器对文件行末的回车符处理不一致，对于回车符的定义： windows：0D0A unix\linux: 0A MAC: 0D去除这些符号的方法有： vim下 :set fileformat=unix 终端 dos2unix filename git图形化提交历史1git log --pretty=format:"%h %an %s" --graph echo 总结 echo默认是带换行符做结尾的 echo -n 可以去掉换行符 printf是没有换行符结尾的 tr可以删掉一个字符，如 tr -d ‘\n’ 删除空行 grep: grep -v ‘^$’ file sed: sed ‘/^$/d’ file 或 sed -n ‘/./p’ file awk: awk ‘/./ {print}’ file shell读文件读取 md5s 文件，对每行做处理。 12345678cat md5s | while read line do md5=$line level2Path=`expr substr "$md5" 30 2` #50 level1Path=`expr substr "$md5" 32 1` #a storagePath=hdfs:///ljp/apk/path/$level1Path/$level2Path/$md5 echo $storagePathdone]]></content>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java序列化]]></title>
    <url>%2F2016%2F01%2F03%2FJava%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[什么是序列化java 序列化是将对象转化为二进制流。不同的序列化框架会将对象转成不同的二进制流。通过 透过byte数组简单分析Java序列化、Kryo、ProtoBuf序列化 这篇文章里可以看到，不同的序列化框架最终转成的二进制流是不一样的。 Java 默认序列化默认序列化机制如果仅仅只是让某个类实现Serializable接口，而没有其它任何处理的话，则就是使用默认序列化机制。使用默认机制，在序列化对象时，不仅会序列化当前对象本身，还会对该对象引用的其它对象也进行序列化，同样地，这些其它对象引用的另外对象也将被序列化，以此类推。所以，如果一个对象包含的成员变量是容器类对象，而这些容器所含有的元素也是容器类对象，那么这个序列化的过程就会较复杂，开销也较大。 整个过程都是Java虚拟机（JVM）独立的，也就是说，在一个平台上序列化的对象可以在另一个完全不同的平台上反序列化该对象。 serialVersionUIDserialVersionUID的作用不仅取决于类路径和功能代码是否一致，一个非常重要的一点是两个类的序列化 ID 是否一致（就是 private static final long serialVersionUID = 1L） Java 序列化实现ObjectInputStream &amp;&amp; ObjectOutputStream类ObjectInputStream 和ObjectOutputStream是高层次的数据流，它们包含序列化和反序列化对象的方法。ObjectOutputStream 类包含很多写方法来写各种数据类型，但是一个特别的方法例外： 1public final void writeObject(Object x) throws IOException 上面的方法序列化一个对象，并将它发送到输出流。相似的ObjectInputStream 类包含如下反序列化一个对象的方法：1public final Object readObject() throws IOException, ClassNotFoundException 该方法从流中取出下一个对象，并将对象反序列化。它的返回值为Object，因此，你需要将它转换成合适的数据类型。 Serializable 接口情境：一个子类实现了 Serializable 接口，它的父类都没有实现 Serializable 接口，序列化该子类对象，然后反序列化后输出父类定义的某变量的数值，该变量数值与序列化时的数值不同。解决：要想将父类对象也序列化，就需要让父类也实现Serializable 接口。如果父类不实现的话的，就 需要有默认的无参的构造函数。在父类没有实现 Serializable 接口时，虚拟机是不会序列化父对象的，而一个 Java 对象的构造必须先有父对象，才有子对象，反序列化也不例外。所以反序列化时，为了构造父对象，只能调用父类的无参构造函数作为默认的父对象。因此当我们取父对象的变量值时，它的值是调用父类无参构造函数后的值。如果你考虑到这种序列化的情况，在父类无参构造函数中对变量进行初始化，否则的话，父类变量值都是默认声明的值，如 int 型的默认是 0，string 型的默认是 null。 Externalizable 接口无论是使用transient关键字，还是使用writeObject()和readObject()方法，其实都是基于Serializable接口的序列化。JDK中提供了另一个序列化接口—Externalizable，使用该接口之后，之前基于Serializable接口的序列化机制就将失效。writeExternal：把一个Java对象写入到流中readExternal：从流中读取一个Java对象 java序列化一览 Java 序列化框架比较性能比较 测试方法jvm-serializers 提供了一个很好的比较各种Java序列化的的测试套件。 它罗列了各种序列化框架， 可以自动生成测试报告。 适用性比较 jsonjson的序列化框架有fastjson,jackson,gson等。适用于数据量小，实时性较低（例如秒级别）的服务。JSON格式具有非常强的前后兼容性，并且调式方便，所以对客户端与服务端的通讯尤其适用。 xmlxml的序列化框架有XStream。XML的序列化和反序列化的空间和时间开销都比较大，对于对性能要求在ms级别的服务，不推荐使用。 hessianhessian主要用于java序列化。它的实现机制是着重于数据，附带简单的类型信息的方法： 对于简单的数据类型。就像Integer a = 1，hessian会序列化成I 1这样的流，I表示int or Integer，1就是数据内容。 对于复杂对象，通过Java的反射机制，hessian把对象所有的属性当成一个Map来序列化，产生类似M className propertyName1 I 1 propertyName S stringValue 对于引用对象，在序列化过程中，如果一个对象之前出现过，hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。 thiftThrift是Facebook开源提供的一个高性能，轻量级RPC服务框架，其产生正是为了满足当前大数据量、分布式、跨语言、跨平台数据通讯的需求。 但是，Thrift并不仅仅是序列化协议，而是一个RPC框架。相对于JSON和XML而言，Thrift在空间开销和解析性能上有了比较大的提升，对于对性能要求比较高的分布式系统，它是一个优秀的RPC解决方案；但是由于Thrift的序列化被嵌入到Thrift框架里面，Thrift框架本身并没有透出序列化和反序列化接口，这导致其很难和其他传输层协议共同使用（例如HTTP）。 protobuf 序列化数据非常简洁，紧凑，析速度非常快，提供了非常友好的动态库。使用简介，反序列化只需要一行代码。但是在JavaBean和proto之间的转换较麻烦。 avroAvro的产生解决了JSON的冗长和没有IDL的问题。 Avro提供两种序列化格式：JSON格式或者Binary格式。Binary格式在空间开销和解析性能方面可以和Protobuf媲美，JSON格式方便测试阶段的调试。 动态类型：Avro并不需要生成代码，模式和数据存放在一起，而模式使得整个数据的处理过程并不生成代码、静态数据类型等等。这方便了数据处理系统和语言的构造。 未标记的数据：由于读取数据的时候模式是已知的，那么需要和数据一起编码的类型信息就很少了，这样序列化的规模也就小了。 不需要用户指定字段号：即使模式改变，处理数据时新旧模式都是已知的，所以通过使用字段名称可以解决差异问题。 Reference https://www.ibm.com/developerworks/cn/java/j-lo-serial/http://www.infoq.com/cn/articles/serialization-and-deserializationhttp://sqtds.github.io/2015/05/13/2015/java-serizable/http://www.solinx.co/archives/377]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地连机房Spark的调试过程]]></title>
    <url>%2F2015%2F11%2F13%2F%E6%9C%AC%E5%9C%B0%E8%BF%9E%E6%9C%BA%E6%88%BFSpark%E7%9A%84%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[调试过程本地运行代码，输出如下： 1234515/11/12 12:09:51 INFO SparkContext: Running Spark version 1.5.1Exception in thread "main" java.lang.NoClassDefFoundError: scala/collection/GenTraversableOnce$class at org.apache.spark.util.TimeStampedWeakValueHashMap.&lt;init&gt;(TimeStampedWeakValueHashMap.scala:42) at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:287)Caused by: java.lang.ClassNotFoundException: scala.collection.GenTraversableOnce$class 查了半天没有任何结果，大家分析的原因各式各样。后来看到了一位仁兄总结的帖子：solve spark issue of all masters are unresponsive，跑去spark机器看了一下log，果然有收获。 spark日志： 1ReliableDeliverySupervisor: Association with remote system [akka.tcp://sparkDriver@100.64.80.93:57108] has failed, address is now gated for [5000] ms. Reason is: [scala.Option; local class incompatible: stream classdesc serialVersionUID = -114498752079829388, local class serialVersionUID = -2062608324514658839]. 根据 scala.Option; local class incompatible 可以发现是 scala 的版本不对，spark 默认的是 scala-2.10，需要改变依赖的scala版本。 改完以后又发现，还是连接不上。本地的输出： 12345615/11/12 21:46:22 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[appclient-registration-retry-thread,5,main]java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@5430d0ff rejected from java.util.concurrent.ThreadPoolExecutor@7819693b[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 1] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369) at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112) spark的日志如下： A 115/11/12 21:46:03 ERROR ErrorMonitor: dropping message [class akka.actor.ActorSelectionMessage] for non-local recipient [Actor[akka.tcp://sparkMaster@10.19.27.215:4041/]] arriving at [akka.tcp://sparkMaster@10.19.27.215:4041] inbound addresses are [akka.tcp://sparkMaster@master1:4041] B 115/11/12 22:00:41 WARN ReliableDeliverySupervisor: Association with remote system [akka.tcp://sparkDriver@100.64.80.93:61812] has failed, address is now gated for [5000] ms. Reason is: [Disassociated]. 关于B这部分的log，怀疑是测试环境的spark的网络访问权限没有打开！最后打开网络访问权限后解决。spark master和worker之间的通信使用的是akka，tcp协议。 spark的A部分log和本地的log是一致的。 第二天接着查，查了很多地方。怀疑是Spark的配置不正确。对于Spark的配置，官网说的是： Options for the daemons used in the standalone deploy mode SPARK_MASTER_IP, to bind the master to a different IP address or hostname 而我spark机器上的设置是： conf/spark-env.sh: export SPARK_MASTER_IP=master1 /etc/hosts: 10.x.xxx.215 master1 一切配置正确但依然不行。Google上到处寻觅，找到 spark 的 group 里面的一个帖子，https://groups.google.com/forum/#!topic/spark-users/SKE4UOUQ_U8，提到 Yes, this message means that one of the workers tried to contact you using your IP address (10.129.7.154), but Akka is (somewhat stupidly) configured to rely on a DNS name (namely ip-10-129-7-154). If you’ve set up the Spark standalone mode, there was a bug in the scripts where they would use an IP address for the master instead of a hostname. 所以当我将 SMART_IP 改成 ip 而不是 hostname 后，本地终于能连上spark了，设置如下： conf/spark-env.sh: export SPARK_MASTER_IP=10.x.xxx.215 几点备忘 通过 %% 方法获取正确的 Scala 版本如果你用是 groupID %% artifactID % revision 而不是 groupID % artifactID % revision（区别在于 groupID 后面是 %%），sbt 会在 工件名称中加上项目的 Scala 版本号。 这只是一种快捷方法。你可以这样写不用 %%： enable build.sbt auto import修改了 build.sbt，但是包没有引入生效 ./spark-shell 加载配置文件在Spark 集群上运行一个应用,只需通过master的 spark://IP:PORT 链接传递到SparkContext构造器在集群上运行交互式的Spark 命令, 运行如下命令：MASTER=spark://IP:PORT ./spark-shell注意，如果你在一个 spark集群上运行了spark-shell脚本，spark-shell 将通过在conf/spark-env.sh下的SPARK_MASTER_IP和SPARK_MASTER_PORT自动设置MASTER]]></content>
      <tags>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql Memo]]></title>
    <url>%2F2015%2F11%2F10%2FMysql-Memo%2F</url>
    <content type="text"><![CDATA[1. contactMySQL CONCAT function is used to concatenate two strings to form a single string. MySQL GROUP_CONCAT() function returns a string with concatenated non-NULL value from a group. 数据库Person表的内容如下： id name source age 1 A GP 6 2 B GP 2 3 A FB 1 4 C FB 4 5 D FB 5 6 A FB 3 7 C TW 7 1.SQL: 1234select name, count(distinct source) as sourceCount,group_concat(distinct source separator &quot;/&quot;) as sourcesfrom Persongroup by name; Query Result: name sourceCount sources A 2 GP/FB B 1 GP C 2 GP/TW D 1 FB 2.SQL: 12345select name, count(distinct source) as sourceCount,group_concat(distinct source separator &quot;/&quot;) as sourcesfrom Persongroup by namehaving sourceCount = 1 and sources = &apos;FB&apos;; Query Result: name sourceCount sources D 1 FB 3.SQL: 123select name, count(distinct age) as ageCount,group_concat(age order by age separator &quot;#&quot;) as agesfrom Person; Query Result: name ageCount ages A 3 1#3#6 B 1 2 C 2 4#7 D 1 5 2. mysql -N 不显示字段名普通的查询语句，查询结果中带字段名 12 mysql -h xxxx -P 8000 -u&apos;xxx&apos; -p&apos;xxx&apos; -D xxdb-e &quot;select name from Person where name = &apos;A&apos;&quot;; +—————-+ | name | +—————-+ | not found | +—————-+ 带-N的查询语句，查询结果中不带字段名 12 mysql -N -h xxxx -P 8000 -u&apos;xxx&apos; -p&apos;xxx&apos; -D xxdb-e &quot;select name from Person where name = &apos;A&apos;&quot;; +—————-+ | not found | +—————-+ 3. IFNULL使用IFNULL能判断是否有查到结果。在shell中跑mysql的指令容易出现空行，此时用IFNULL是最合适的了。 1234 mysql -N -h xxxx -P 8000 -u&apos;xxx&apos; -p&apos;xxx&apos; -D xxdb-e &quot;select IFNULL((select name from Person where name = &apos;A&apos; and age = 100),&apos;not found&apos;)&quot; +—————-+ | not found | +—————-+]]></content>
      <tags>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的内存泄露与垃圾回收]]></title>
    <url>%2F2015%2F11%2F02%2FJava%E7%9A%84%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[什么是内存泄露内存泄露 memory leak，是指已申请的无用内存无法被回收。 内存泄漏有两种情况： 一种情况如在C/C++语言中的，在堆中的分配的内存，在没有将其释放掉的时候，就将所有能访问这块内存的方式都删掉（如指针重新赋值) 一种情况则是在内存对象明明已经不需要的时候，还仍然保留着这块内存和它的访问方式（引用） 第一种情况，在Java中已经由于垃圾回收机制的引入，得到了很好的解决。所以，Java中的内存泄漏，主要指的是第二种情况。 内存泄露的一个例子： 12345for (int i = 0; i &lt; 1000; i++) &#123; Object obj = new Object( list.add(obj); obj = null;&#125; 这段代码是：for循环中，new一个Object对象obj，然后将其添加到list中，最后将obj置空。 这个时候就发生了内存泄露，因为obj是可达的无用对象。发生GC时，尽管obj已经被置空成为了无用对象，但是obj能够从list可达，从而GC无法将其释放掉。次数obj占用的内存就是泄露了。 内存泄露与内存溢出内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory。当发生内存溢出时，程序将无法进行，强制终止。在java中常见的java.lang.OutOfMemoryError就是内存溢出的log。 内存长期泄露终将导致内存溢出。 内存泄露的危害一次内存泄露危害可以忽略，但内存长期泄露，可用内存会逐渐减少，导致降低性能，最终内存溢出。 在移动设备对于内存和CPU都有较严格的限制的情况下，Java的内存泄露还会导致程序性能降低甚至崩溃。 怎么产生内存泄露容易引起内存泄漏的几大原因 静态集合类 像HashMap、Vector 等静态集合类的使用最容易引起内存泄漏，因为这些静态变量的生命周期与应用程序一致，如示例1，如果该Vector 是静态的，那么它将一直存在，而其中所有的Object对象也不能被释放，因为它们也将一直被该Vector 引用着。 监听器 在java 编程中，我们都需要和监听器打交道，通常一个应用当中会用到很多监听器，我们会调用一个控件的诸如addXXXListener()等方法来增加监听器，但往往在释放对象的时候却没有记住去删除这些监听器，从而增加了内存泄漏的机会。 物理连接 一些物理连接，比如数据库连接和网络连接，除非其显式的关闭了连接，否则是不会自动被GC 回收的。Java 数据库连接一般用DataSource.getConnection()来创建，当不再使用时必须用Close()方法来释放，因为这些连接是独立于JVM的。对于Resultset 和Statement 对象可以不进行显式回收，但Connection 一定要显式回收，因为Connection 在任何时候都无法自动回收，而Connection一旦回收，Resultset 和Statement 对象就会立即为NULL。但是如果使用连接池，情况就不一样了，除了要显式地关闭连接，还必须显式地关闭Resultset Statement 对象（关闭其中一个，另外一个也会关闭），否则就会造成大量的Statement 对象无法释放，从而引起内存泄漏。 内部类和外部模块等的引用 内部类的引用是比较容易遗忘的一种，而且一旦没释放可能导致一系列的后继类对象没有释放。 垃圾回收可以手动执行垃圾回收吗？ 只能建议jvm进行GC，但什么时候做GC由JVM决定 System.gc()可以通过调用System.gc()建议JVM执行垃圾回收，但JVM不保证一定会执行GC操作。通常不推荐使用System.gc()。 finalize()finalize()方法存在于java.lang.Object类中，可以被所有对象所使用。默认情况下其不执行任何动作。当垃圾回收器确定了一个对象没有任何引用时，其会调用finalize()方法。但是，finalize方法并不一定会被执行，因此也不建议覆写finalize()该方法。 内存泄露，会被垃圾回收吗内存泄露 memory leak，是指已申请的无用内存无法被回收。GC只能回收第一种情况的内存泄露，见前面的释义。 设置null能防止内存泄露吗最基本的建议就是尽早释放无用对象的引用，大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域后，自动设置为null。 不过这个真的有用吗？ 查阅了网上的一些讨论以后有以下结论： 首先，jdk远比我们想象中的聪明，完全能判断出对象是否已经可以回收。但是在极少数情况下，这么做依然是有效的。 这些情况是：方法前面中有定义大的对象,然后又跟着非常耗时的操作,且没有触发JIT编译。 JVM即时编译器：即时编译器（Just In Time Compiler) 简称JIT JAVA程序最初是通过解释器（Interpreter）进行解释执行的，当JVM发现某个方法或代码块运行特别频繁的时候，就会认为这是“热点代码”（Hot Spot Code)。 为了提高热点代码的执行效率，就会将这些“热点代码”编译成与本地机器相关的机器码，进行各个层次的优化。 完成这个任务的编译器就是即时编译器（JIT）。 例如： 123456private void processObj() &#123; BigObject obj = … // 声明大对象obj doSomethingWith(obj); // 使用obj obj = null; // explicitly set to null doSomethingElse(); //非常耗时的操作&#125; 此时显示的设置无用的对象obj为null才有效。 How to avoid Memory Leak in Java贴出 How to avoid Memory leak issue in Java 一文中提到的防止java内存泄露的一些建议。 How to avoid Memory Leak in Java? While coding if we take care of a few points we can avoid memory leak issue. Use time out time for the session as low as possible. Release the session when the same is no longer required. We can release the session by using HttpSession.invalidate(). Try to store as less data as possible in the HttpSession. Avoid creating HttpSession in jsp page by default by using the page directive &lt;%@page session=”false”%&gt; Try to use StringBuffer’s append() method instead of string concatenation. String is an immutable object and if we use string concatenation, it will unnecessarily create many temporary objects on heap which results in poor performance. For ex. if we write String query = “SELECT id, name FROM t_customer whereMsoNormal” style=”margin-bottom: 0.0001pt;”&gt; it will create 4 String Objects. But if we write the same query using StringBuffer’s append() it will create only one object as StringBuffer is mutable i.e. can be modified over and over again. In JDBC code, While writting the query try to avoid “*”. It is a good practice to use column name in select statement. Try to use PreparedStatement object instead of Statement object if the query need to be executed frequently as PreparedStatement is a precompiled SQL statement where as Statement is compiled each time the Sql statement is sent to the database. Try to close the ResultSet and Statement before reusing those. If we use stmt = con.prepareStatement(sql query) inside loop, we should close it in the loop. Try to close ResultSet, Statement, PreparedStatement and Connection in finally block. 在测试内存泄露时，对GC有一些收获 cannot disable java gc 我们不能决定什么时候发生GC。 System.gc() vs GC button in JVisualVM/JConsoleAs far as I know, Jconsole or any other tool, uses System.gc() only. There is no other option. As everyone know, java tells everyone not to rely on System.gc(), but that doesn’t mean it doesn’t work at all. Reference&gt; http://wwsun.me/posts/jvm-gc.html http://java.dzone.com/articles/jvm-and-garbage-collection http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html http://chenjingbo.iteye.com/blog/1980908 http://www.mindfiresolutions.com/How-to-avoid-Memory-leak-issue-in-Java-1001.php http://www.infoq.com/cn/articles/cf-java-garbage-references]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域请求]]></title>
    <url>%2F2015%2F10%2F29%2F%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[碰到的问题今天做了一个feature的admin的接口api/xxv/abc/feature，便于ops在admin上直接管理配置信息。但是我们的域名是 ttt.company.com，所以admin应该访问http://ttt.company.com/api/xxv/abc/feature但是admin的域名是admin(-test).company.com，而且admin后台是需要登录的。这样就导致了前端跨域传cookie会有问题。 解决的方案nginx 做请求转发目前的做法是在服务端之前做一个反向代理，admin请求同域名的http://admin-test.company.com/api/abc/feature然后在nginx层将请求转发到http://ttt.company.com/api/xxv/abc/feature 对于staging和online不同的环境，将请求转发到不同的server即可。 请求转发http://admin-test.company.com/api/abc/feature-&gt;http://ttt.company.com/api/xxv/abc/feature ngin配置 123456789101112server &#123; listen 80; server_name admin-test.company.com; location /api/abc &#123; rewrite /api/abc/(.*) /api/xxv/$1 break; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://staging.server.hostname:8080; &#125;&#125; 123456789101112server &#123; listen 80; server_name admin.company.com; location /api/abc &#123; rewrite /api/abc/(.*) /api/xxv/$1 break; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://myserver-write-nodes; &#125;&#125; 服务端处理跨域请求在返回的response header中加入允许跨域访问的属性。例如： Access-Control-Allow-Origin: {允许的域名} 更多信息参考：跨域 HTTP 请求(Cross-site HTTP request)]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Btrace详解]]></title>
    <url>%2F2015%2F08%2F20%2FBtrace%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Btrace的简介Btrace是由Kenai 开发的一个开源项目，是一种动态跟踪分析JAVA源代码的工具。它可以用来帮我们做运行时的JAVA程序分析，监控等等操作。 官方参考手册https://kenai.com/projects/btrace/pages/UserGuide 实例12345678910111213141516171819202122232425262728293031323334353637import com.sun.btrace.annotations.*;import com.sun.btrace.AnyType;import static com.sun.btrace.BTraceUtils.*;@BTracepublic class TestServiceImplTrace &#123; @TLS private static long service_get_data_startTime = 0; @OnMethod( clazz = "com.xxx.mms.test.impl.TestServiceImpl", method = "getTestData" ) public static void startTestServiceImplExecute() &#123; section_facade_impl_startTime = timeMillis(); &#125; @OnMethod( clazz = "com.xxx.mms.test.impl.TestServiceImpl", method = "getTestData" location = @Location(Kind.RETURN) ) public static void endTestServiceImplExecute(AnyType[] args) &#123; // 传入所有参数 long time = timeMillis() - section_facade_impl_startTime; Object obj = args[4]; Integer end = (Integer)obj; // 将第5个参数转成Integer printFields(args[0]); // 打印第1个参数的所有成员变量的值 if(end == 6)&#123; print(strcat(“service getTestData execute time(millis): ", str(time))); print(strcat(“\t string param: ", str(args[3]))); // 将第4个参数转成string并打印 println(strcat(“\t end: ", str(end))); &#125; &#125;&#125; 心得 btrace脚本的函数都没有走进去时，btrace pid tracing.java 是得不到结果的。 Kind.LINE指向的行必须是代码能运行到的行。比如，以括号结束的行和空行都是无效的。 在刚启动btrace脚本监控时，会存在较大的耗时 print有很多功能： printNumberMap printFields： print 每个域 printArray：print 数组 如果服务的qps较低(0.2),直接去机器上app222通过ip请求，btrace的event不好用也达不到触发某个请求的目的，这个时候可以直接在本机请求此server的api，虽然与实际情况不符，但是能知道耗时的比例关系。 Btrace的原理Btrace是由：Attach API + BTrace脚本解析引擎 + ASM + JDK6 Instumentation组成。简单来说就是：用Attach API附加*.jar然后使用BTrace脚本解析引擎 + ASM来实现对类的修改，在使用Instumentation实现类的内存替换。可详细的说明可以看refers的几篇文章。 使用Btrace对java进程的影响 装载时的影响：btrace每次使用，都会重新load所有的class。当然如果OnMethod不匹配，是不会被重新装载。所以跟你的OnMethod的匹配规则很有关系，如果使用+java.lang.Object。那就死定了。 退出后的影响：btrace监控每次退出后，原先所有的class都不会被恢复，你的所有的监控代码依然一直在运行 抓取了下btrace改写过后的类： 123456public InstrumentServer(String ip, String port)&#123; $btrace$com$agapple$btrace$Instrumentor$InstrumentTracer$bufferMonitor(this); this.ip = ip; this.port = port;&#125; 1234567891011121314private static void $btrace$com$agapple$btrace$Instrumentor$InstrumentTracer$bufferMonitor(@Self Object arg0)&#123; if (!BTraceRuntime.enter(InstrumentTracer.runtime)) return; try &#123; Field ipField = BTraceUtils.field("com.agapple.btrace.Instrumentor.InstrumentServer", "ip"); Field portField = BTraceUtils.field("com.agapple.btrace.Instrumentor.InstrumentServer", "port"); String ip = (String)BTraceUtils.get(ipField, self); String port = (String)BTraceUtils.get(portField, self); BTraceUtils.println(BTraceUtils.strcat(BTraceUtils.strcat(BTraceUtils.strcat("ip : ", BTraceUtils.str(ip)), " port : "), BTraceUtils.str(port))); BTraceRuntime.leave(); return; &#125; catch (Throwable localThrowable) &#123; BTraceRuntime.handleException(localThrowable); &#125;&#125; 注意其中的 1if (!BTraceRuntime.enter(InstrumentTracer.runtime)) return; 再看一下BTraceRuntime中对应方法的实现： 12345private volatile boolean disabled;public static boolean enter(BTraceRuntime current) &#123; if (current.disabled) return false; return map.enter(current);&#125; 每次执行你的监控代码之前会先进行一个判断，判断当前是否处于监控中。你的客户端发起了exit指令后，该方法判断false，直接return。 所以btrace使用退出后会让你的代码多走了一个方法调用+一个对象属性判断，所以说影响还是非常少的。 推荐阅读Btrace系列之一：Btrace的基本原理 http://victorzhzh.iteye.com/blog/965789btrace一些你不知道的事(源码入手) http://agapple.iteye.com/blog/1005918 Reference&gt;Java SE 6 新特性: Instrumentation 新功能 http://www.ibm.com/developerworks/cn/java/j-lo-jse61/Btrace系列之一：Btrace的基本原理 http://victorzhzh.iteye.com/blog/965789btrace一些你不知道的事(源码入手) http://agapple.iteye.com/blog/1005918]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注入]]></title>
    <url>%2F2015%2F08%2F08%2FSpring%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[设值注入（推荐）1234&lt;bean id="myService" class="com.zane.test.MyServiceImpl"&gt; &lt;property name="serializer" ref="Serializer"/&gt; &lt;property name="httpService" ref="httpService"/&gt;&lt;/bean&gt; 构造器注入（死的应用）1234&lt;bean id="myModel" class="com.zane.test.MyModel"&gt; &lt;constructor-arg index="0" value="$&#123;name&#125;"/&gt; &lt;constructor-arg index="1" value=“20"/&gt;&lt;/bean&gt; 注入List123456789&lt;bean id="myTypes" class="java.util.ArrayList"&gt; &lt;constructor-arg&gt; &lt;list&gt; &lt;value type="com.zane.test.MyType"&gt;A&lt;/value&gt; &lt;value type="com.zane.test.MyType"&gt;B&lt;/value&gt; &lt;value type="com.zane.test.MyType"&gt;C&lt;/value&gt; &lt;/list&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 注入Map123456789101112131415&lt;bean id="myTypeValueMap" class="java.util.HashMap"&gt; &lt;constructor-arg&gt; &lt;map&gt; &lt;entry key="#&#123;T(com.zane.test.MyType).A&#125;"&gt; &lt;value type="java.lang.Integer"&gt;3&lt;/value&gt; &lt;/entry&gt; &lt;entry key="#&#123;T(com.zane.test.MyType).B&#125;"&gt; &lt;value type="java.lang.Integer"&gt;4&lt;/value&gt; &lt;/entry&gt; &lt;entry key="#&#123;T(com.zane.test.MyType).C&#125;"&gt; &lt;value type="java.lang.Integer"&gt;5&lt;/value&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/constructor-arg&gt;&lt;/bean&gt; 当注入的是第三方的jar包的key类型时，需要使用@Resource注入 123@Resource@Qualifier("myTypeValueMap")private Map&lt;MyType, String&gt; myTypeValueMap; 否则使用Autowired即可 123@Autowired@Qualifier("myTypeValueMap")private Map&lt;MyType, String&gt; myTypeValueMap;]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的wait和notify]]></title>
    <url>%2F2015%2F07%2F30%2FJava%E7%9A%84wait%E5%92%8Cnotify%2F</url>
    <content type="text"><![CDATA[Java 线程同步原理java会为每个object对象分配一个monitor，当某个对象的同步方法（synchronized methods ）或同步快被多个线程调用时，该对象的monitor将负责处理这些访问的并发独占要求。 当一个线程调用一个对象的同步方法时，JVM会检查该对象的monitor。如果monitor没有被占用，那么这个线程就得到了monitor的占有权，可以继续执行该对象的同步方法；如果monitor被其他线程所占用，那么该线程将被挂起，直到monitor被释放。 当线程退出同步方法调用时，该线程会释放monitor，这将允许其他等待的线程获得monitor以使对同步方法的调用执行下去。 注意：java对象的monitor机制和传统的临界检查代码区技术不一样。java的一个类一个同步方法并不意味着同时只有一个线程独占执行（不同对象的同步方法可以同时执行），但临界检查代码区技术确会保证同步方法在一个时刻只被一个线程独占执行。 java的monitor机制的准确含义是：任何时刻，对一个指定object对象的某同步方法只能由一个线程来调用。 java对象的monitor是跟随object实例来使用的，而不是跟随程序代码。两个线程可以同时执行相同的同步方法，比如：一个类的同步方法是xMethod()，有a,b两个对象实例，一个线程执行a.xMethod()，另一个线程执行b.xMethod(). 互不冲突。 wait(), notify(),notifyAll()首先看一下Java中java.lang.Object类的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Object &#123; private static native void registerNatives(); static &#123; registerNatives(); &#125; public final native Class&lt;?&gt; getClass(); public native int hashCode(); public boolean equals(Object obj) &#123; return (this == obj); &#125; protected native Object clone() throws CloneNotSupportedException; public String toString() &#123; return getClass().getName() + "@" + Integer.toHexString(hashCode()); &#125; public final native void notify(); public final native void notifyAll(); public final native void wait(long timeout) throws InterruptedException; public final void wait(long timeout, int nanos) throws InterruptedException &#123; if (timeout &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException("nanosecond timeout value out of range"); &#125; if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; timeout == 0)) &#123; timeout++; &#125; wait(timeout); &#125; public final void wait() throws InterruptedException &#123; wait(0); &#125; protected void finalize() throws Throwable &#123; &#125;&#125; wait()方法是object类的方法，解决的问题是线程间的同步，该过程包含了同步锁的获取和释放，调用wait方法将会将调用者的线程挂起，直到其他线程调用同一个对象的notify()方法才会重新激活调用者。 注意:线程调用notify()之后，只有该线程完全从 synchronized代码里面执行完毕后，monitor才会被释放，被唤醒线程才可以真正得到执行权。 使用： obj.wait()方法使本线程挂起，并释放obj对象的monitor，只有其他线程调用obj对象的notify()或notifyAll()时，才可以被唤醒。 obj.notifyAll()方法唤醒所有阻塞在obj对象上的沉睡线程，然后被唤醒的众多线程竞争obj对象的monitor占有权，最终得到的那个线程会继续执行下去，但其他线程继续等待。 obj.notify()方法是随机唤醒一个沉睡线程，过程更obj.notifyAll()方法类似。 wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，例如： 1234synchronized(x)&#123; x.notify() //或者wait()&#125; 以上内容说明了为什么调用wait()，notify()，notifyAll()的线程必须要拥有obj实例对象的monitor占有权。 每个对象实例都有一个等待线程队列。这些线程都是等待对该对象的同步方法的调用许可。对一个线程来说，有两种方法可以进入这个等待线程队列。一个是当其他线程执行同步方法时，自身同时也要执行该同步方法；另一个是调用obj.wait()方法。 当同步方法执行完毕或者执行wait()时，其他某个线程将获得对象的访问权。当一个线程被放入等待队列时，必须要确保可以通过notify()的调用来解冻该线程，以使其能够继续执行下去。 nativenative is a java keyword. It marks a method, that it will be implemented in other languages, not in Java. The method is declared without a body and cannot be abstract. It works together with JNI (Java Native Interface).Native methods were used in the past to write performance critical sections but with java getting faster this is now less common. Native methods are currently needed when You need to call from java a library, written in another language.You need to access system or hardware resources that are only reachable from the other language (typically C). Actually, many system functions that interact with real computer (disk and network IO, for instance) can only do this because they call native code.]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synchronized详解]]></title>
    <url>%2F2015%2F07%2F14%2Fsynchronized%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[synchronized关键字简洁、清晰、语义明确，因此即使有了Lock接口，使用的还是非常广泛。其应用层的语义是可以把任何一个非null对象作为”锁”。synchronized在软件层面依赖JVM，Lock在硬件层面依赖特殊的CPU指令。 JVM如何实现synchronized在java语言中存在两种内建的synchronized语法：synchronized语句和synchronized方法。synchronized语句被javac编译成bytecode时，会在同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令。synchronized方法被javac编译成bytecode时，会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。 hotspot当前对synchronized的实现当前的hotspot共有3种类型的锁，来实现synchronize的语义，之所以有3种，是因为这3种要解决的问题不同，所做的优化也不同。这3种锁分别为biased locking，stack lock，infalted(ObjectMonitor).简单除暴的来讲，从轻量级上来说，biased lock最优，inflated 最差。 synchronized锁住的是什么synchronized锁定的是对象而非函数或代码。当synchronized作用在方法上时，锁住的便是对象实例（this）；当作用在静态方法时锁住的便是对象对应的Class实例，因为Class数据存在于永久带，因此静态方法锁相当于该类的一个全局锁；当synchronized作用于某一个对象实例时，锁住的便是对应的代码块。每个对象只有一把锁(Lock)与之关联，当进行到synchronized语句或函数的时候，这把锁就会被当前的线程（thread）拿走，其他的（thread）再去访问的时候拿不到锁就被暂停了。在HotSpot JVM实现中，锁有个专门的名字：对象监视器。 synchronized的使用场景 public synchronized void method1 锁住的是该对象,类的其中一个实例，当该对象(仅仅是这一个对象)在不同线程中执行这个同步方法时，线程之间会形成互斥。达到同步效果，但如果不同线程同时对该类的不同对象执行这个同步方法时，则线程之间不会形成互斥，因为他们拥有的是不同的锁。 synchronized(this){ //TODO } 同一 public synchronized static void method3 锁住的是该类，当所有该类的对象(多个对象)在不同线程中调用这个static同步方法时，线程之间会形成互斥，达到同步效果，但如果多个线程同时调用method1，method3，则不会引互斥，具体讲看最后讲解。 synchronized(Test.class){ //TODO} 同三 synchronized(o) {} 这里面的o可以是一个任何Object对象或数组，并不一定是它本身对象或者类，谁拥有o这个锁，谁就能够操作该块程序代码。 Reference 周志明的《深入理解Java虚拟机》https://blogs.oracle.com/dave/entry/biased_locking_in_hotspothttp://www.javaworld.com/article/2076971/java-concurrency/how-the-java-virtual-machine-performs-thread-synchronization.htmlhttp://f.dataguru.cn/thread-472518-1-1.html]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java锁优化]]></title>
    <url>%2F2015%2F07%2F09%2Fjava%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[同步的原理JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。 Java对象头锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。 长度 内容 说明 32/64bit Mark Word 存储对象的hashCode或锁信息等 32/64bit Class Metadata Address 存储到对象类型数据的指针 32/64bit Array length 数组的长度（如果当前对象是数组） Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下： 25 bit 4bit 1bit是否是偏向锁 2bit锁标志位 无锁状态 对象的hashCode 对象分代年龄 0 01 在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据： 几种锁的类型线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。 Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。 锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 偏向锁Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。 偏向锁的进一步理解偏向锁的释放不需要做任何事情，这也就意味着加过偏向锁的MarkValue会一直保留偏向锁的状态，因此即便同一个线程持续不断地加锁解锁，也是没有开销的。 另一方面，偏向锁比轻量锁更容易被终结，轻量锁是在有锁竞争出现时升级为重量锁，而一般偏向锁是在有不同线程申请锁时升级为轻量锁，这也就意味着假如一个对象先被线程1加锁解锁，再被线程2加锁解锁，这过程中没有锁冲突，也一样会发生偏向锁失效，不同的是这回要先退化为无锁的状态，再加轻量锁，如图： 另外，JVM对那种会有多线程加锁，但不存在锁竞争的情况也做了优化，听起来比较拗口，但在现实应用中确实是可能出现这种情况，因为线程之前除了互斥之外也可能发生同步关系，被同步的两个线程（一前一后）对共享对象锁的竞争很可能是没有冲突的。对这种情况，JVM用一个epoch表示一个偏向锁的时间戳（真实地生成一个时间戳代价还是蛮大的，因此这里应当理解为一种类似时间戳的identifier），对epoch，官方是这么解释的： A similar mechanism, called bulk rebiasing, optimizes situations in which objects of a class are locked and unlocked by different threads but never concurrently. It invalidates the bias of all instances of a class without disabling biased locking. An epoch value in the class acts as a timestamp that indicates the validity of the bias. This value is copied into the header word upon object allocation. Bulk rebiasing can then efficiently be implemented as an increment of the epoch in the appropriate class. The next time an instance of this class is going to be locked, the code detects a different value in the header word and rebiases the object towards the current thread. 偏向锁的获取当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 偏向锁的设置关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 自旋锁线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。 所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。 自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。 对自旋锁周期的选择上，HotSpot认为最佳时间应是一个线程上下文切换的时间，但目前并没有做到。经过调查，目前只是通过汇编暂停了几个CPU周期，除了自旋周期选择，HotSpot还进行许多其他的自旋优化策略，具体如下： 如果平均负载小于CPUs则一直自旋 如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞 如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋 自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差） 轻量级锁轻量级锁加锁线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。 轻量级锁解锁轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 重量级锁重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex互斥的功能，它还负责实现了Semaphore的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。 锁的优缺点对比 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块场景 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度 如果始终得不到锁竞争的线程使用自旋会消耗CPU 追求响应时间,锁占用时间很短 重量级锁 线程竞争不使用自旋，不会消耗CPU 线程阻塞，响应时间缓慢 追求吞吐量,锁占用时间较长 Reference&gt;周志明的《深入理解Java虚拟机》https://blogs.oracle.com/dave/entry/biased_locking_in_hotspothttps://www.usenix.org/legacy/event/jvm01/full_papers/dice/dice.pdfhttp://www.javaworld.com/article/2076971/java-concurrency/how-the-java-virtual-machine-performs-thread-synchronization.htmlhttp://www.infoq.com/cn/articles/java-se-16-synchronizedhttp://www.majin163.com/2014/03/17/synchronized2/http://www.cnblogs.com/javaminer/p/3889023.htmlhttp://blog.csdn.net/coslay/article/details/41526635]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile详解]]></title>
    <url>%2F2015%2F06%2F22%2Fvolatile%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[volatile的含义volatile是一个类型修饰符（type specifier）。它是被设计用来修饰被不同线程访问和修改的变量。volatile变量自身具有下列特性： 可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量的写入。 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 volatile与synchronized的比较Java语言包含两种内在的同步机制：被synchronized修饰的同步块（或方法）和被volatile修饰的变量。这两种机制都是为了实现代码线程的安全性。与 synchronized 块相比，volatile 变量的同步性较差，使用时容易出错，但它更简单且开销更低。 锁提供了两种主要特性：互斥(mutual exclusion)和可见性(visibility)。互斥即一次只允许一个线程持有某个特定的锁，因此可使用该特性实现对共享数据的协调访问协议，这样，一次就只有一个线程能够使用该共享数据。可见性要更加复杂一些，它必须确保释放锁之前对共享数据做出的更改对于随后获得该锁的另一个线程是可见的 —— 如果没有同步机制提供的这种可见性保证，线程看到的共享变量可能是修改前的值或不一致的值，这将引发许多严重问题。 volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。这就是说线程能够自动发现 volatile 变量的最新值。volatile 变量可用于提供线程安全，但是只能应用于非常有限的一组用例：多个变量之间或者某个变量的当前值与修改后值之间没有约束。因此，单独使用 volatile 还不足以实现计数器、互斥锁或任何具有与多个变量相关的不变式（Invariants）的类（例如 “start &lt;=end”）。 出于简易性或可伸缩性的考虑，一般倾向于使用 volatile 变量而不是锁。但是当使用 volatile 变量时，某些习惯用法（idiom）更加易于编码和阅读。此外，volatile 变量不会像锁那样造成线程阻塞。在某些情况下，如果读操作远远大于写操作，volatile 变量还可以提供优于锁的性能优势。 volatile的适用范围您只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件：对变量的写操作不依赖于当前值。该变量没有包含在具有其他变量的不变式中。 volatile的内存语义volatile写的内存语义如下： 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。volatile读的内存语义如下： 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。后续线程读此变量时，将从主内存中读取并load到本地内存。 volatile内存语义的实现JMM(Java Memory Model) 如何实现volatile写/读的内存语义。JMM内部会实现指令重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。 从JSR-133开始，volatile变量的写-读可以实现线程之间的通信。从内存语义的角度来说，volatile与监视器锁有相同的效果：volatile写和监视器的释放有相同的内存语义；volatile读与监视器的获取有相同的内存语义。 更进一步地说明 处理器为了提高处理速度，不直接和内存进行通讯，而是先将系统内存的数据读到内部缓存（L1,L2或其他）后再进行操作，但操作完之后不知道何时会写到内存，如果对声明了Volatile变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题，所以在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作的时候，会强制重新从系统内存里把数据读到处理器缓存里。 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。 这里A线程写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。 下面对volatile写和volatile读的内存语义做个总结：线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所在修改的）消息。线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 volatile的性能在目前大多数的处理器架构上，volatile 读操作开销非常低 —— 几乎和非 volatile 读操作一样。而 volatile 写操作的开销要比非 volatile 写操作多很多，因为要保证可见性需要实现内存栅栏(Memory barrier)，即便如此，volatile 的总开销仍然要比锁获取低。 volatile的使用场景很多并发性专家事实上往往引导用户远离 volatile 变量，因为使用它们要比使用锁更加容易出错。然而，如果谨慎地遵循一些良好定义的模式，就能够在很多场合内安全地使用 volatile 变量。要始终牢记使用 volatile 的限制 —— 只有在状态真正独立于程序内其他内容时才能使用 volatile —— 这条规则能够避免将这些模式扩展到不安全的用例。 场景1：状态标志一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 123456789volatile boolean shutdownRequested;public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 场景2：一次性安全发布（one-time safe publication）缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原语值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。（这就是造成著名的双重检查锁定（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象）。实现安全发布对象的一种技术就是将对象引用定义为 volatile 类型。 12345678910111213141516171819public class BackgroundFloobleLoader &#123; public volatile Flooble theFlooble; public void initInBackground() &#123; // do lots of stuff theFlooble = new Flooble(); // this is the only write to theFlooble &#125;&#125;public class SomeOtherClass &#123; public void doWork() &#123; while (true) &#123; // do some stuff... // use the Flooble, but only if it is ready if (floobleLoader.theFlooble != null) doSomething(floobleLoader.theFlooble); &#125; &#125;&#125; 上面的代码中，如果 theFlooble 引用不是 volatile 类型，doWork() 中的代码在解除对 theFlooble 的引用时，将会得到一个不完全构造的 Flooble。volatile 类型的引用可以确保对象的发布形式的可见性，但是如果对象的状态在发布后将发生更改，那么就需要额外的同步。 场景3：结合 volatile 和 synchronized 实现的”开销较低的读－写锁”目前为止，您应该了解了 volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作（读、添加、存储）的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。 然而，如果读操作远远超过写操作，您可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。清单 6 中显示的线程安全的计数器使用synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。 123456789101112@ThreadSafepublic class CheesyCounter &#123; // Employs the cheap read-write lock trick // All mutative operations MUST be done with the 'this' lock held @GuardedBy("this") private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; 之所以将这种技术称之为 “开销较低的读－写锁” 是因为您使用了不同的同步机制进行读写操作。因为本例中的写操作违反了使用 volatile 的第一个条件，因此不能使用 volatile 安全地实现计数器 —— 您必须使用锁。然而，您可以在读操作中使用 volatile 确保当前值的可见性，因此可以使用锁进行所有变化的操作，使用 volatile 进行只读操作。其中，锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作，因此当使用 volatile 保证读代码路径时，要比使用锁执行全部代码路径获得更高的共享度 —— 就像读－写操作一样。然而，要随时牢记这种模式的弱点：如果超越了该模式的最基本应用，结合这两个竞争的同步机制将变得非常困难。 总结与锁相比，volatile 变量是一种非常简单但同时又非常脆弱的同步机制，它在某些情况下将提供优于锁的性能和伸缩性。如果严格遵循 volatile 的使用条件 —— 即变量真正独立于其他变量和自己以前的值 —— 在某些情况下可以使用 volatile 代替 synchronized 来简化代码。然而，使用 volatile 的代码往往比使用锁的代码更加容易出错。本文介绍的模式涵盖了可以使用 volatile 代替 synchronized 的最常见的一些用例。遵循这些模式（注意使用时不要超过各自的限制）可以帮助您安全地实现大多数用例，使用 volatile 变量获得更佳性能。 Reference http://www.ibm.com/developerworks/cn/java/j-jtp06197.htmlhttp://www.infoq.com/cn/articles/java-memory-model-1http://www.infoq.com/cn/articles/ftf-java-volatilehttp://zhhphappy.iteye.com/blog/2086149]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存栅栏]]></title>
    <url>%2F2015%2F06%2F22%2F%E5%86%85%E5%AD%98%E6%A0%85%E6%A0%8F%2F</url>
    <content type="text"><![CDATA[什么是内存栅栏内存栅栏(Memory Barriers)，是让一个CPU处理单元中的内存状态对其它处理单元可见的一项技术。 内存栅栏提供了两个功能 确保从另一个CPU来看栅栏的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性； 实现内存数据可见性，确保内存数据会同步到CPU缓存子系统。 为什么需要内存栅栏对主存的一次访问一般花费硬件的数百次时钟周期。为了减少这种操作，CPU通过使用Cache来达到高效获取数据的目的。然后Cache为了提高性能，会对指令进行重排序。当重排序对最终的结果没有影响的时候，这种优化是有益的。但是当多线程共享数据时，重排序将导致错误的结果。所以为了在共享变量的情况下依然可以使用指令重排序，产生了内存栅栏来保证程序的正确性。 内存栅栏是怎么实现的在底层，内存栅栏是一组指令，一般包括Store Barrier、Load Barrier和Full Barrier。 几乎所有的处理器至少支持一种粗粒度的屏障指令，通常被称为“栅栏（Fence）”，它保证在栅栏前初始化的load和store指令，能够严格有序的在栅栏后的load和store指令之前执行。 不同的CPU架构有不同的实现方式，以X86为例： Store Barrier,强制所有在store屏障指令之前的store指令，都在该store屏障指令执行之前被执行，并把store缓冲区的数据都刷到主存 Load Barrier,强制所有在load屏障指令之后的load指令，都在该load屏障指令执行之后被执行，并且一直等到load缓冲区被该CPU读完才能执行之后的load指令。 Full Barrier，复合了load和store屏蔽指令。无论在何种处理器上，这几乎都是最耗时的操作之一（与原子指令差不多，甚至更消耗资源），所以大部分处理器还会支持更细粒度的屏障指令。 下图是CPU的Local Memory与主存的通信过程： Java中内存栅栏的使用Java内存模型中volatile变量在写操作之后会插入一个store屏障，在读操作之前会插入一个load屏障。一个类的final字段会在初始化后插入一个store屏障，来确保final字段在构造函数初始化完成并可被使用时可见。 内存栅栏对性能的影响内存栅栏阻止了 CPU 很多隐式的内存延迟技术的执行，因此是有性能损耗的，不过在上层看来这种损耗并不大。在合适的时候使用内存栅栏，仍然是一种高效的做法。 Reference http://mechanical-sympathy.blogspot.jp/2011/07/memory-barriersfences.htmlhttp://ifeve.com/memory-barriers-or-fences/http://www.infoq.com/cn/articles/memory_barriers_jvm_concurrency]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这些年数据挖掘及反思]]></title>
    <url>%2F2015%2F06%2F19%2F%E8%BF%99%E4%BA%9B%E5%B9%B4%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%8F%8A%E5%8F%8D%E6%80%9D%2F</url>
    <content type="text"><![CDATA[转至： http://news.dbanotes.net/item?id=23383 写这篇文章，缘自于前几天部门内部成员们进行了一次部门内部现有涉及的一些算法的review以及整理。不过比较囧的就是，由于Boss不在，我们讨论讨论着就成了吐槽大会，倒是有一半时间在吐槽产品以及业务部门了。不过这也算是一件可喜可贺的事情了，这也可以看做是我们数据部门，已经由开轻型挖掘机向深挖阶段迈步了。 因此，借此机会，也对自己接触过的，了解过的，或者做过的一些勉强称得上算法的东西做一个梳理。其实，就个人来说，本身就不是做算法出身的，在大学时代，学习的反倒是网络方面多一些，更不知数据挖掘算法为何物。 其实，就所谓算法而言，个人认为，我有个同事说的很对：所谓算法，并不是说那些复杂的数学模型才是算法，哪怕是你写的一个简单的计算公式，只要能够解决现有业务的痛点，有了自己的模型思路，它就是一个算法，只是它可能不够通用，只能解决特定业务需求而已。 在大规模的数据前提下，其实很多复杂的算法过程，反而效果没有这么好，或者说，我们会想方设法去简化其过程。 举个简单栗子：假设有一批大规模数据集，就以近千万篇博文为例。如果提供一篇博文，让你去查询与其相似度最高的top N，那我们的通常思路是什么？通常的做法是计算这篇博文与其他博文的相似度，至于相似度的计算方法就很多了，最简单的就是计算其向量夹角，根据向量夹角判定相似程度。OK，就算你用最简单的计算过程，你试想一下，运算近千万次需要多久？或许，有的人说，俺使用hadoop，利用分布式的计算能力来完成这个任务，但如果实际操作起来，你就会发现这是一个多么蛋疼的事情。 再举一个简单栗子（好吧，多吃点栗子）：比如SVM，这是一种难以收敛的算法，在大数据的前提下，有些人希望使用它，但又希望使用更多的数据来训练模型，毕竟手里数据量太大，很多人还是希望使用尽量多的数据训练的，以达到模型更准确的目的。但是，随着训练数据量的增大，像SVM这种难以收敛的算法，其耗费的计算资源还是很巨大的。 东拉西扯说了这么多，自个的梳理工作还没有完成呢！ 一、这些年，我开过的挖掘机 （1）最早接触的应该是贝叶斯的分类了 贝叶斯算是分类算法中最简单的算法了，初学挖掘机算法的人十有八九第一个爱上的绝对是它。其实，贝叶斯的原理真的很简单，就是依据统计学的最大概率原理。这么简单，但是就是尼玛这么好用，多年依然屹立不倒。 训练过程就缺乏可陈了，基本上贝叶斯的都这样，由于是文本，所以一套流程下来，分词，去停词，作为最基本的知识点向量，然后就计算模型概率了。不过比较有趣的是，分类过程是放在Storm里头做的，相当于这是一个实时的分类业务。 （2）说到了文本，自然少不了分词算法了 其实说到分词算法，反倒没啥可说的。如今互联网上各种开源的分词工具，都已经做的很好了，效果也差不了多少，想进一步改进的话也够呛。至于说深入到分词算法的内部，涉及上下文法分析，隐含马尔科夫模型等东西，如果是个人出于兴趣去研究，那我没话说；如果是小公司，花费人力物力去优化分词效果，我只能说他们闲着蛋疼；如果是大公司，人家金多任性也是可以理解的。 所以，至今来说，个人对于分词方面的东西，也仅限于初步了解分词算法的衍变，内部大概涉及的算法，以及几种分词工具的使用。 其实，在文本挖掘方面，仅仅针对于文本的分词是不够的，因为我们使用分词拆分出来的单词，往往很多跟业务都是没有关系的，通常做法是，建立对应业务字典，至于字典的建立，当然也是需要分词的，再进行进一步的加工，甚至可能会加上一些人工的工作。 （3）下一个就是实时热点分析了 我也不知道这算不算是算法，说到实时，自然跟Storm又有关系了（好吧，我承认我是搞这个之后开始接触数据的）。说到实时热点，可能大伙儿都摸不着头脑，举个简单栗子就明了了。 玩hadoop的童鞋都知道WordCount这个经典栗子，MapReduce在Map到Reduce的过程中，自动将相同的Key通过类似hash的方法聚合到一起了，所以，统计单词这个需求通过MR来做是辣么的简单。 那Storm的实时WordCount呢？好吧，这也是一个能够记录到实时技术领域史书上的经典案例（好吧，其实它就是一个Storm的HelloWorld）。Storm虽然没有类似MR那种自动Hash的功能，不过它也提供了一种数据分组流策略，也能达到类似的效果，并且它不像MR那样是批量的，它是实时的、流式的，也就是说你能动态的获取到当前变换的单词词频。 实时热点分析，如果我们把热点映射成单词，那我们是不是就可以实时的获取到当前Top N的热点了。这个方向可是有很大的研究价值的，实时地掌握了用户的热点导向，我们就可以动态的调整业务策略，从而衍生更大的数据价值。 不过，总体来说，这个数据模型更多依靠的是Storm这个实时工具的本身功能，模型设计上的东西反倒是少了。至于说算不算是算法模型，就跟前面所说的那样，看个人看法吧，你说是就是了~~ （4）国内很成熟的一种建模——推荐 就目前在国内做数据挖掘的来说，可能分类与推荐是做的最多的两种方向。分类就不多说了，就比如刚才所说的贝叶斯，简直就是分类中的鼻祖算法了。 可能一说到推荐算法，有人脑海里立马就闪现出关联规则、协同过滤、余弦相似性等这些词。这是没错的，但我要说的不是这个。其实个人想说的是推荐就两个方向：基于用户，基于内容。 我们需要注意两点，我们推荐的对象是用户，或者说是类似用户这种有动作行为的实体；而推荐的东西则就是内容，他没有动作行为，但是他有不同的属性，或者用更砖业说法描述就是他必然有知识点。 基于用户推荐，我们看重的不是内容这个实体，而是用户本身的行为，我们认为用户的行为必然隐含着一些信息，比如，人的兴趣导向，那么既然你有了相关的行为，那么我按照你的行为去给你推荐一些东西，这总是有一定道理的。 基于内容的推荐，我们的侧重点则是内容，这就跟用户的历史行为无关了。我们潜意识的认为，既然你会看这个内容，那么跟这个内容有关系的内容，你是不是也感兴趣呢？或许这样说有失偏颇，但是大体方向是对的。 至于之前说的那些关联规则也好，协同过滤也好，余弦相似性也好，其实就是研究知识点与知识点之间关系所建立的模型。 针对于基于内容推荐，其知识点就是内容之中的各种属性，比如影片推荐，其知识点可能就是各种评论数据、点播数据、顶踩数据、影片类型、演员、导演以及其中的一些情感分析等等；又比如博文，其知识点可能就是一个个带权的词，至于这个词就涉及到词的抽取了，再说到词的权重，可能就会涉及到TFIDF模型、LDA模型了。 而针对基于用户，其知识点最直接的体现就是用户的行为了，就是用户与内容之间的关系，不过深究下去，又会发现，其实跟内容的知识点也紧密联系，只不过这可能不止一个内容实体，而是多个内容实体的集合。 （5）文本单词的加权模型 前面正好提到了TFIDF以及LDA模型，所以顺带也就讲讲文本单词相关的加权模型吧。 说到文本挖掘，可能大部分人都熟悉TFIDF模型，既然涉及到了，那就简单的说一说。我们知道，文本的知识点就是一个个的单词，虽然都是单词，但也总有哪个词重要程度高一点，哪些词重要程度会低一点吧。 或许有人会说，出现多的词就重要。没错，那就是词频，简单的来想，这种思路并没有错，并且，早期的文本挖掘模型就是这么做的。当然，效果肯定是一般般的。因为那些经常出现的词往往都是一些没用的常用词，对文章的作用并不大。 直到TFIDF模型的出现，才根本性地解决了文本挖掘知识点建模的问题。如何判断一个词的重要程度，或者专业点的说法就是判断其对文章的贡献度？TFIDF通过词的词频来加大词在文章中的权重，然后通过其在多个文章中的文档频率来降低其在文章中的权重。说白了就是降低了那些公共词的权重，把真正贡献度大的词给暴露出来。这基本就是TFIDF的基本思路了，至于词频权重怎么加大，文档频的权重怎么降低，这就涉及到具体的模型公式了，根据不同的需求进行调整就OK了。 关于文章知识点主题建模的另外一种很重要的模型，那就是LDA模型了。它是一种比较通用的文章主题模型，它通过概率学原理，说白了就是贝叶斯，建立起知识点（也就是词），主题和文章的三层关系结构。词到主题有一个概率矩阵，主题到文章也有一个概率矩阵的映射关系。 好吧，LDA不能再说下去了，再说下去就露馅了。因为，俺也不是很懂啊。对于LDA，虽然部门内部有在使用，但是我没有做过具体的模型，只是和同事讨论过它，或者更确切的说向同事请教过它的一些原理以及一些设计思路。 （6）相似度计算 相似度计算，比如文本的相似度计算。它是一个很基础的建模，很多地方就用的到它，比如刚才我们说到的推荐，其内部关联的时候，有时候就会涉及到计算实体间的相似度。 关于文本的相似度，其实方法有很多。通常会涉及到TFIDF模型，拿到文本的知识点，也就是带权的词，然后通过这些带权的词去做一些相似度的计算。 比如，余弦相似模型，就是计算两个文本的余弦夹角，其向量自然就是那些带权的词了；又比如，各种算距离的方法，最著名的欧式距离，其向量也依然是这些词。还有很多诸如最长公共子串、最长公共子序列之类的模型，个人就不是很清楚了。 总之，方法很多，也都不是很复杂，原理都很像。至于哪个合适，就得看具体的业务场景了。 （7）文本主题程度——信息熵 曾经和同事尝试对数百万的博文进行领域划分，把技术博文划分成不同的领域，比如大数据领域、移动互联网领域、安全领域等等，其实说白了还是分类。 一开始我们使用贝叶斯进行分类，效果还行，不过最终还是使用SVM去建模了。这都不是重点，重点是我们想对划分到某一领域下的技术博文进行领域程度判断。 我们想了很多办法，尝试建立了数据模型，但效果都不是很理想，最终回归到了一个最本质的方法，那就是使用文本的信息熵去尝试描述程度，最终结果还是不错。这又让我再一次想到同事说过的那句话：简单的东西不一定不好用！ 信息熵描述的是一个实体的信息量，通俗一点说就是它能够描述一个实体的信息混乱程度。在某一个领域内，知识点都是相似的，都是那些TFIDF权重的词，因此，是不是可以认为，一个文本其信息熵越小，其主题越集中越明显，信息的混乱度越低，反过来说，有些文本主题很杂乱，可能包含了多种领域的一些东西，其领域的程度就会降低。 最起码表面上，这种说法是行得通的，并且实际的效果还不错。 （8）用户画像 用户画像这个方向可能是近两年比较火的方向了。近年来，各大互联网公司，各大IT企业，都有意识的开始从传统的推荐到个性化推荐的道路衍变，有些可能做的深一些，有些可能浅一些。 商业价值的核心是用户，这自然不用多说。那么如何结合用户进行推荐呢，那就是用户的属性，那关键是用户的属性也不是一开始就有的，我们所有的只是少量用户的固有属性以及用户的各种行为记录。我们连用户是啥子里情况都不清楚，推个毛啊！ 所以，我们需要了解用户，于是对用户进行用户画像分析就很有必要了，其实就是把用户标签化，把用户标记成一个个属性标签，这样，我们就知道每一个用户大概是什么情况了。一些商业行为，也就有了目的性。 至于说如何对用户的每一个画像属性进行填充，这就看具体的情况了。简单的，用几个简单模型抽取到一些信息填充进去；复杂的，使用复杂的算法，通过一些复杂的转换，给用户打上标签。 （9）文章热度计算 给你一大坨文章，你如何判断哪篇文章比较热，哪篇文章比较矬，换个说法就是，我进入一个文章列表页，你能给我提供一个热文章的排序列表吗？ 可能大部分的思路都很直接，拿到文章能够体现热度的属性，比如点击率、评论情感分析、文章的顶踩情况，弄个简单加权计算模型，咔咔就出来了。 本质上这没错，简单的模型在实际的情况中不一定不好使，部分属性也的确能够体现出一篇文章的热度，通过加权计算的方式也是对的，具体的权重就需要看具体情况了。 但如果这么做的话，实际上会出现什么情况？今天我来了，看见了这个热度推荐列表，明天我来了，还是看到这个列表，后天我来了，依然是这个列表。 尼玛，这是啥情况，咋天天都是这个破列表，你要我看几遍？！不错，这就是现实情况，造成的结果就是，越热的文章越来越热，越冷的文章越冷，永远的沉底了，而热的文章永远在前头。 如何解决这个问题？我们把时间也加入参考，我们要把老文章通过降权的方式，把他人为的沉下去，让新文章有出头的机会。这就是说，需要我们把创建时间也加入权重中，并且随着时间推移，衰减其热度权重，这样，就不会出现热的一直热，冷的一直冷了。至于衰减的曲线，就需要看具体业务了。 这样就能解决根本问题了吗？如果文章本身信息量就不够呢，比如，本身大部分就是新文章，没有顶踩，没有评论，甚至连点击曝光都很少，那用之前的模型就行不通了。 那是不是就无解了呢？方法还是有的，比如，我们寻找到一个相似的站点，他也提供了类似最热文章推荐的功能，并且效果还很不错。那么，我们是不是就可以借助它的热度呢？我们通过计算文章相似度的方法，复刻出一个最热列表出来，如果站点性质相似，用户性质相似，文章质量不错，相似度计算够准确，相信这个热度列表的效果也是会不错滴（这方法太猥琐了~~）。 （10）Google的PageRank 首先，别误会，我真心没有写过这个模型，我也没有条件去写这个模型。 认识它了解它，缘自于跟几个老同学合伙搞网站（酷抉网）。既然搞网站吧，作为IT人猿，一些基本的SEO的技术还是需要了解的。于是，我了解到：想要增大网站的权重，外链是不可缺少的。 我跟我几个老同学说，你们去做外链吧，就是逮住网站就放咱网站的链接。他们问到：一个网站放的链接越多越好吗？放的网站越多越好吗？啥网站放比较好？这都不是重点，关键是他们问：为毛啊？ 把我问的那个是哑口无言啊，于是我一怒之下就去研究PageRank了。PageRank具体的推演过程我就不说了（况且凭借我这半吊子的水平也不一定能说清楚），其核心思想有几个：当一个网页被引用的次数越多时，其权重越大；当一个网页的权重越大时，其引用的网页权重也随之增大；当一个网页引用的次数越多时，它引用的网页给它带来的权重越低。 当我们反复迭代路上过程时，我们会发现某个网页的的排名基本就固定了，这就是PageRank的基本思路。当然也有个问题需要解决，比如，初始网页如何给定其初始权重，高计算迭代过程如何简化其计算过程等等。这些问题，在Google的实际操作中，都做了比较好的优化。 （11）从互联网上定向抓取数据 其实我估摸着这跟算法没很大关系了，不过既然有数据的获取设计流程，也勉强算是吧。 之所以有这个需求，是那段时间搞网站搞嗨了，给自己整了个工作室网站，想给别人尤其是一些小企业搭建包括轻度定制企业网站（是不是挺瞎折腾的-_-），也确实是做了几个案例（我的工作室网站：www.mite8.com，有兴趣去看看）。 于是乎，俺就想啊，如何给自己找客户？工作室的客户应该是那些小企业的老板，并且还必须是目前没有企业门户的。作为一个搞数据的程序猿，并且还是开挖掘机的，虽然是半路出身非蓝翔毕业且无证上岗，但好歹是挖过几座山头的呀。 如今是互联网横行的时代，他们总会在互联网上留下一些蛛丝马迹，我要把它给逮出来！我的目标很明确，我要拿到那些无企业网站的企业邮箱，然后做自己EDM营销（电子邮件营销）。 1）我先从智联检索页面，抓取了企业规模小于40人的企业名称，事实证明智联招聘的页面还是很好解析的，都是静态的，并且格式很规整，所以很容易就分析出一批小企业的企业名来了； 2）拿到了企业名，我如何判断这个企业已经有了独立的企业官网？通过分析，我发现通过搜索引擎检索这个企业名的时候，如果有企业官网的话，一定是在首页。并且其页面地址也是有一定规律的，那就是：独立官网的开头通常是www开头的，长度一般不会太长，收尾通常是index.html、index.php以及index.asp等等。 通过这些规则，我就可以将那些有企业官网的企业名给pass掉了。其中遇到了两个难点，一个就是搜索引擎的很多页面源码都是动态加载的，于是我模拟了浏览器访问的过程，把页面源码给抓取下来了，这也是爬虫的通用做法；第二个就是，一开始我尝试的是通过百度去获取，结果百度貌似是有放结果抓取的一些措施，导致结果不如人意，于是我换了目的，使用的是360的检索，问题就解决了（事实证明百度在搜索引擎方面比360还是强了不少的），并且效果也差不多。 3）解决了排除的问题，那根本的问题就来了，我如何拿到企业的企业邮箱？通过分析搜索引擎的返回结果，我发现很多小企业喜欢用第三方网站提供的一些公司黄页，里头包含了企业联系邮箱；还有部分公司发布的招聘信息上会带有企业邮箱。 通过数据解析，终于拿到了这部分数据，最后还做了一些类似邮箱是否有效的基本解析等等。最终拿到了大概3000多个企业邮箱，有效率达到了80%以上。 问题是解决了，但还是有些地方需要优化的：首先就是效率问题，我整整跑了近12个小时，才把这3000多个邮箱给跑出来，太多需要解析的地方，并且模拟的浏览器在效率上不高；其次就是对邮箱的有效不是很好判断，有些邮箱根本就是人为瞎写的；还有就是部分网站对邮箱进行了图片化混杂处理，即做成了类似的验证码的东西，防抓取，我没有对图片类的邮箱数据进行解析，其实这个问题也是有解决办法的，我们拿到一些样本图片，进行图片字母识别的训练，这样就能解析出其中的邮箱了。 总体来说，这次体验还是挺有成就感的，毕竟在业余的时间解决了自己实际中的一些痛点，熟练了一些所学到的东西，或者说实施的过程中学到了很多东西。 ps：github上检索webmite就是这个项目了，我把代码托管到了github上，或者从我的博客上进入。 二、对自己做一个总结吧 其实个人的缺点很明显，首先就是没有经过系统的数据挖掘学习（没去过蓝翔，挖掘机自学的），也就是野路子出身。因此对很多算法的原理不够清楚，这样的话，对于有些业务场景，可能就提不出有建设性的意见了。并且，对于很多算法库的使用，还是不够了解的。 其次就是在数学功底上有所欠缺。我们知道，一些复杂的算法，是需要有强大的数学基础的。算法模型，其本质就是数学模型。因此，这方面也是我的短板吧。 由于个人是由做大数据偏向挖掘的，基于大数据模式下的数据挖掘过程，可能跟传统的数据过程有很大的不一样。比如，数据的预处理过程，大数据挖掘的预处理很多依赖的是目前比较流行的分布式的一些开源系统，比如实时处理系统Storm、消息队列Kafka、分布式数据收集系统Flume、数据离线批处理Hadoop等等，在数据分析存储上可能依赖的Hive以及一些Nosql会多一些。反倒对于传统的一些挖掘工具，比如SAS、SPSS、Excel等工具，个人还是比较陌生的。不过这也说不上是缺点吧，侧重点不一样。总体而言，大规模数据的挖掘将会是趋势。 三、给小伙伴们的一些建议 说了这么多，前面的那些东西可能对大伙儿的用处并不是很大，当然对于开挖掘机的朋友还是有一定帮助的。现在我想表达的东西可能跟挖掘就没有直接的关系了，更多的给动物园动物（程序猿，攻城狮）的学习以及自我进化的建议。 （1）为了学到东西，脸皮是毛玩意儿？ 对于这点，个人可是深有体会。想当年（好吧，这个词还是很蛋疼的），大学那会儿专业是信息安全，偏向于网络多一点，因此在语言方面更多的是c和c++，对于java可是连课都没有开的，说白了就是用java写个HelloWorld都不会。 刚毕业那会儿，兴冲冲地跑去公司写c，结果不到一个月，新项目来了，需求变了（尼玛，开发最怕的就是这句话），变了就变了吧，尼玛要研究大数据，用c能干毛啊！一些个开源系统工具，十个倒是有九个是java写的。当时我就哭了！ 于是就纠缠着一个同组的伙伴，逮住时间就问他问题，有些问题在熟悉java的人看来，绝对是白痴又白痴的。但是对于初学者来说，绝对是金玉良言，人家一句话的事，如果自己去查找，可能是几个小时都搞不定。一个月之后，总算入门了，后面就轻松多了。 往后的一些日子里，遇到了一些问题，总是会厚着脸皮缠着交流群中的一些大拿们死问，慢慢地就进步了。近段时间，开始学习scala，幸好旁边有个scala小高手，哈哈，可苦了他了~~ 所以，遇到自己不懂的东西，不要怕自己的问题简单不好意思问，一定要脸皮厚！你连这么简单的问题都不懂，你还有资格担心自己的脸皮？！ （2）交流与分享 对于交流与分享这点感想，缘自于2012年末研究Storm的那段时间。Storm在2012年那会儿，并不像今天这样火，研究的人也不多，无处交流，可用的资料就更少了，所以解决起问题来很费事。 当然其中有几个博客给我的帮助还是很大的，包括了“大园那些事儿”、“庄周梦蝶”等几个博客，都是早期研究Storm并且分享经验技术的博客。当时我就萌生了写博客的想法。 在往后的时间里，我花费了很大一部分精力，将我学到的Storm相关的东西整理了出来，并且由于当时感叹没有一个很好的交流平台，创建了“Storm-分布式-IT”技术群（群号191321336，主要搞Storm以及大数据方面的，有兴趣的可以进来），并把整理的资料、代码、经验分享到了平台以及博客中。 由于我一直主张“进步始于交流，收获源于分享”这个理念，不断有搞技术的朋友加入到这个大家庭中，并且不断的把一些经验技术反馈到群贡献中，达到了一个良性的循环。 短短不到两年的时间，群已经发展到了千人，并且无论是技术氛围还是群员素质，在IT技术群中绝对可以算的上名列前茅的。 就个人从中的收获来看，这种交流是能够学到很多的东西的，你要相信三人行必有我师，这句话是有道理的。而分享则是促进交流的基石，只有让大家意识到自己所收获的东西是源自于别人的分享，这样才能让更多的人参与进来。 其实说了这么多，想表达的意思就两点：多多与他人交流，听取他人的意见；至于分享自己的所得，这就是属于良心发现了。 （3）多看书，随时给自己大脑补充营养 其实这点也不止是给大伙儿的建议，也算是给自己的一个告诫吧。 个人在这方面做的也不是很好，很久之前给自己定了一个目标：一个月看完一本书。结果工作的问题，其他杂七杂八的事情很多，这个一直没有落实下来，至今买来的《我的互联网方法论》才看了前几章。最好的案例算是上上一个月，我花费了近一个月上下班等地铁、倒地铁的零碎时间，终于把《构建之法：现代软件工程》给看完了。 书中有没有颜如玉我不知道，但书中肯定有黄金屋。平时多看一些书，多学一些，跳槽时跟面试官总是能多唠一些的，哈哈，提薪酬的时候是不是底气就足了些？！ 关于说看书的内容，工作中涉及的一些必须了解，必须看的我就不多说了。如果业余时间比较多，还是推荐多涉猎一些其他相关领域，毕竟，人不可能一辈子就只窝在自己那一亩三分地上的；就算你一直坚持某个技术方向，随着时间的推移，技术的升华也必然会涉及到其他很多的相关知识。 所以，多看书，多充实一下自己，这一定是对的！ （4）经常梳理一下自己，整理一下自己 经常给自己做一下梳理工作：自己目前掌握了哪些东西，目前自己缺乏什么东西，掌握的东西够不够，缺乏的东西如何去弥补。这些都是需要我们经常去反思的，只有整理清楚了自己，才知道自己要干什么，才有目标。 当然梳理完了，你还需要去实际操作，不然的话，你会发现，每一次梳理，结果都是一样的。我们需要在每一次梳理过后，进行对比，了解自己进步了多少。当然每一次梳理，都是为了给自己做一个计划，计划自己大概需要在哪些方向进行加强。 其实很多人一到了跳槽季就犹犹豫豫，其实他们对目前的工作已经是有所不满的了，但是总感觉自己能力不够，可能辞了也难找工作。这是因为他们对自己认识的不够，连他自己都不明白自己到底有多少料，那么，请问面试官会知道吗？ 如果，你对自己掌握了多少东西都一清二楚，核心领域已经熟悉了，相关领域也有所涉猎，那么你还在担心什么呢？如果真有面试官对你说no，你可以说：hi，刚好我也没什么时间，我还回去挑选offer呢！ （5）善于在实际生活中寻找学习的动力 人是懒惰的，很多时候，有些事情可做可不做的，往往人都是不去做的，也不愿意去深根究底。 这个我很想学，那个我也很想了解，关键是一到大周末，我更想躺被窝！说到底，就是没有学习的动力！也就是说，我们要善于在实际的生活中，寻找到推动我们取学习的理由。举几个简单的栗子： 1）之前也说过，有段时间在研究网站。为了让网站推广出去，各种去研究SEO，现在来看，自己虽然远远达不到一个SEO专业人员的标准，但最起码是知道了为毛通过搜索引擎检索，有些网页就排在前面有些就排在后面（PageRank算法）；也知道了怎么去编译一篇文章，更好的方便搜索引擎收录（等俺失业了，不搞挨踢了，去做网编估计也是行的，又多了一条活路，哈哈）等等。 2）为了给EDM寻找目标，我自己使用业余的时间去分析互联网上的数据，然后写代码，跑数据，测试数据等。其实，在那之前，我对爬虫的了解是不多的，对于网页数据的解析也不在行，这完全都是通过“从互联网抓取有用数据”的个人需求上去驱动的。还不止如此，拿到邮箱之后，为了让EDM邮件看起来更“砖业”一点，我开始自学如何使用html来制作好看的电子营销邮件页面。 3）曾经有一段时间，工作很是清闲，突发奇想的把大学时想写小说的梦给圆了。于是就开始在纵横小说网上写小说。不过，这都不是重点，重点是纵横要求每一个作者给自己的小说配小说封面。我去问了一下，尼玛一张破封面需要20多大洋。心想，一张破封面就要20大洋，自己都是搞IT的人，干脆不自己P一个呢。于是，我开始捡起了大学时期放弃的PS学习计划，只用了两个星期，PS基本功能就熟练了。后来的话，自己的封面当然是搞定了，并且还服务了至少数十位作者朋友们。当然，这都是题外话了。至于小说，哈哈，不但签约了，稿费还是挣了上千大洋，关键是过了一把写小说的瘾。在PS技术方面，虽然跟专业的前端人员比不得，但是改改图、修修照片还是木有问题滴。 4）远的太远，说一个近一点的事吧。前一段时间开始学习scala，其实就个人需求来说，写那个项目用java来写也完全能够搞定，但关键是我对我自己说，错过了这次机会，下次说不定啥时候才有决心去学习这个很有前途的语言了。于是，狠下心使用这个全新的语言去开发，过程虽然磕磕绊绊，毕竟马上使用一种陌生的语言去敲代码是很蛋疼的事，但一个星期来，结果还是不错的，最起码一些基本的用法是会了。完事开头难，熟悉了一些基本的东西，剩下的就是累积的过程了。 其实这些归结起来就一个观点：我们要适时的给自己找一些理由，逼着我们自己去学习，去获取新的东西，去提升自己。 或许有人会说，哥我天天加班，还有毛线时间去问问题、去交流、去看书，大周末的好不容易有假期了，吃饱了我不去睡觉去给自己找动力干不给钱的活，我脑抽啊？！好吧，如果你是这么想的，抱歉耽误了你这么多睡觉的时间。 其实上面说了这么多零碎的栗子，关键还是在于态度！你有没有想学习的欲望，有没有提升自己、升华自己的想法，有没有升职、加薪、当上UFO、迎娶白富美的念头。是的，这些东西都是自己去做的，没人逼你。如果你有这些想法的话，那么这些东西多多少少还是有一些帮助的。 除了对待事情的态度，我们的心态也很重要，看待事情要乐观一点。前几天，群里有个搞互联网招聘的朋友问我：你是搞技术的吧？我说是。他说我认识很多搞技术的都很闷，不像你这么开朗。我说我不想哪天死在了马桶上~~ 搞IT的给大部分人的映象确实是闷骚、不善言谈、不善交际。其实也是，每天大量的工作，领导又开会训人了、产品这边需求又改了，确实让人疯狂。工作压力大是IT人的标准属性了。 我们需要调整好自己的心态，就像之前所说的，学习一个东西，虽然可能会占用本来就不多的业余时间，但是我们应该不是那种单纯为了解决问题而去学习，去获取，当成一种提升自己、升华自己的途径，而不是逼不得已的无奈之举。如果一份工作，你确认自己不喜欢，那就别犹豫，果断跳吧！脑中有货还怕找不到买家！ 时刻警醒自己对待任何事情要有一个好的态度，认清自己，抓住一切机会提升自己、升华自我，保持一个良好的心态，这就是我想说的东西。 吭吭唧唧说了一大坨，其实我也知道很多是废话，但是我依然希望，我的这些废话能够帮助到你，做为同一个动物园里的人，一起努力吧！]]></content>
      <tags>
        <tag>Introspect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AbstractQueuedSynchronizer详解]]></title>
    <url>%2F2015%2F06%2F19%2FAbstractQueuedSynchronizer%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[AQS简介AQS介绍AbstractQueuedSynchronizer提供了一个基于FIFO队列，可以用于构建锁或者其他相关同步装置的基础框架。该同步器（以下简称同步器）利用了一个int来表示状态，期望它能够成为实现大部分同步需求的基础。使用的方法是继承，子类通过继承同步器并需要实现它的方法来管理其状态，管理的方式就是通过类似acquire和release的方式来操纵状态。然而多线程环境中对状态的操纵必须确保原子性，因此子类对于状态的把握，需要使用这个同步器提供的以下三个方法对状态进行操作： 123java.util.concurrent.locks.AbstractQueuedSynchronizer.getState()java.util.concurrent.locks.AbstractQueuedSynchronizer.setState(int)java.util.concurrent.locks.AbstractQueuedSynchronizer.compareAndSetState(int, int) 子类推荐被定义为自定义同步装置的内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干acquire之类的方法来供使用。该同步器即可以作为排他模式也可以作为共享模式，当它被定义为一个排他模式时，其他线程对其的获取就被阻止，而共享模式对于多个线程获取都可以成功。 AQS用处 同步器与锁同步器是实现锁的关键，利用同步器将锁的语义实现，然后在锁的实现中聚合同步器。 可以这样理解：锁的API是面向使用者的，它定义了与锁交互的公共行为，而每个锁需要完成特定的操作也是透过这些行为来完成的（比如：可以允许两个线程进行加锁，排除两个以上的线程），但是实现是依托给同步器来完成；同步器面向的是线程访问和资源控制，它定义了线程对资源是否能够获取以及线程的排队等操作。锁和同步器很好的隔离了二者所需要关注的领域，严格意义上讲，同步器可以适用于除了锁以外的其他同步设施上（包括锁）。同步器的开始提到了其实现依赖于一个FIFO队列，那么队列中的元素Node就是保存着线程引用和线程状态的容器，每个线程对同步器的访问，都可以看做是队列中的一个节点。Node的主要包含以下成员变量： 1234567Node &#123; int waitStatus; Node prev; Node next; Node nextWaiter; Thread thread;&#125; 以上五个成员变量主要负责保存该节点的线程引用，同步等待队列（以下简称sync队列）的前驱和后继节点，同时也包括了同步状态。 属性名称 描述 int waitStatus 表示节点的状态。其中包含的状态有： CANCELLED，值为1，表示当前的线程被取消；SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark；CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中；PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行；值为0，表示当前节点在sync队列中，等待着获取锁。 Node prev 前驱节点，比如当前节点被取消，那就需要前驱节点和后继节点来完成连接。 Node next 后继节点。 Node nextWaiter 存储condition队列中的后继节点。 Thread thread 入队列时的当前线程。 节点成为sync队列和condition队列构建的基础，在同步器中就包含了sync队列。同步器拥有三个成员变量：sync队列的头结点head、sync队列的尾节点tail和状态state。对于锁的获取，请求形成节点，将其挂载在尾部，而锁资源的转移（释放再获取）是从头部开始向后进行。对于同步器维护的状态state，多个线程对其的获取将会产生一个链式的结构。 API说明实现自定义同步器时，需要使用同步器提供的getState()、setState()和compareAndSetState()方法来操纵状态的变迁。 方法名称 描述 protected boolean tryAcquire(int arg) 排它的获取这个状态。这个方法的实现需要查询当前状态是否允许获取，然后再进行获取（使用compareAndSetState来做）状态。 protected boolean tryRelease(int arg) 释放状态。 protected int tryAcquireShared(int arg) 共享的模式下获取状态。 protected boolean tryReleaseShared(int arg) 共享的模式下释放状态。 protected boolean isHeldExclusively() 在排它模式下，状态是否被占用。 实现这些方法必须是非阻塞而且是线程安全的，推荐使用该同步器的父类java.util.concurrent.locks.AbstractOwnableSynchronizer来设置当前的线程。开始提到同步器内部基于一个FIFO队列，对于一个独占锁的获取和释放有以下伪码可以表示。获取一个排他锁。 1234567891011while(获取锁) &#123; if (获取到) &#123; 退出while循环 &#125; else &#123; if(当前线程没有入队列) &#123; 那么入队列 &#125; 阻塞当前线程 &#125;&#125;释放一个排他锁。 1234if (释放成功) &#123; 删除头结点 激活原头结点的后继节点&#125; Mutex 示例下面通过一个排它锁的例子来深入理解一下同步器的工作原理，而只有掌握同步器的工作原理才能够更加深入了解其他的并发组件。排他锁的实现，一次只能一个线程获取到锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Mutex implements Lock, java.io.Serializable &#123; // 内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 是否处于占用状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) &#123; assert releases == 1; // Otherwise unused if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; &#125; 可以看到Mutex将Lock接口均代理给了同步器的实现。使用方将Mutex构造出来之后，调用lock获取锁，调用unlock进行解锁。下面以Mutex为例子，详细分析以下同步器的实现逻辑。 独占模式acquire实现分析public final void acquire(int arg)该方法以排他的方式获取锁，对中断不敏感，完成synchronized语义。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上述逻辑主要包括： 尝试获取（调用tryAcquire更改状态，需要保证原子性）；在tryAcquire方法中使用了同步器提供的对state操作的方法，利用compareAndSet保证只有一个线程能够对状态进行成功修改，而没有成功修改的线程将进入sync队列排队。 如果获取不到，将当前线程构造成节点Node并加入sync队列；进入队列的每个线程都是一个节点Node，从而形成了一个双向队列，类似CLH队列，这样做的目的是线程间的通信会被限制在较小规模（也就是两个节点左右）。 再次尝试获取，如果没有获取到那么将当前线程从线程调度器上摘下，进入等待状态。使用LockSupport将当前线程unpark，关于LockSupport后续会详细介绍。 1234567891011121314151617181920212223242526272829private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 快速尝试在尾部添加 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125;&#125; 上述逻辑主要包括： 使用当前线程构造Node；对于一个节点需要做的是将当节点前驱节点指向尾节点（current.prev = tail），尾节点指向它（tail = current），原有的尾节点的后继节点指向它（t.next = current）而这些操作要求是原子的。上面的操作是利用尾节点的设置来保证的，也就是compareAndSetTail来完成的。 先行尝试在队尾添加；如果尾节点已经有了，然后做如下操作： 分配引用T指向尾节点； 将节点的前驱节点更新为尾节点（current.prev = tail）； 如果尾节点是T，那么将当尾节点设置为该节点（tail = current，原子更新）； T的后继节点指向当前节点（T.next = current）。注意第3点是要求原子的。这样可以以最短路径O(1)的效果来完成线程入队，是最大化减少开销的一种方式。 如果队尾添加失败或者是第一个入队的节点。如果是第1个节点，也就是sync队列没有初始化，那么会进入到enq这个方法，进入的线程可能有多个，或者说在addWaiter中没有成功入队的线程都将进入enq这个方法。可以看到enq的逻辑是确保进入的Node都会有机会顺序的添加到sync队列中，而加入的步骤如下： 如果尾节点为空，那么原子化的分配一个头节点，并将尾节点指向头节点，这一步是初始化； 然后是重复在addWaiter中做的工作，但是在一个for(;;)的循环中，直到当前节点入队为止。 进入sync队列之后，接下来就是要进行锁的获取，或者说是访问控制了，只有一个线程能够在同一时刻继续的运行，而其他的进入等待状态。而每个线程都是一个独立的个体，它们自省的观察，当条件满足的时候（自己的前驱是头结点并且原子性的获取了状态），那么这个线程能够继续运行。 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp;tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 上述逻辑主要包括： 获取当前节点的前驱节点；需要获取当前节点的前驱节点，而头结点所对应的含义是当前占有锁且正在运行。 当前驱节点是头结点并且能够获取状态，代表该当前节点占有锁；如果满足上述条件，那么代表能够占有锁，根据节点对锁占有的含义，设置头结点为当前节点。 否则进入等待状态。如果没有轮到当前节点运行，那么将当前线程从线程调度器上摘下，也就是进入等待状态。这里针对acquire做一下总结： 状态的维护；需要在锁定时，需要维护一个状态(int类型)，而对状态的操作是原子和非阻塞的，通过同步器提供的对状态访问的方法对状态进行操纵，并且利用compareAndSet来确保原子性的修改。 状态的获取；一旦成功的修改了状态，当前线程或者说节点，就被设置为头节点。 sync队列的维护。在获取资源未果的过程中条件不符合的情况下(不该自己，前驱节点不是头节点或者没有获取到资源)进入睡眠状态，停止线程调度器对当前节点线程的调度。这时引入的一个释放的问题，也就是说使睡眠中的Node或者说线程获得通知的关键，就是前驱节点的通知，而这一个过程就是释放，释放会通知它的后继节点从睡眠中返回准备运行。下面的流程图基本描述了一次acquire所需要经历的过程： 如上图所示，其中的判定退出队列的条件，判定条件是否满足和休眠当前线程就是完成了自旋spin的过程。 releasepublic final boolean release(int arg)在unlock方法的实现中，使用了同步器的release方法。相对于在之前的acquire方法中可以得出调用acquire，保证能够获取到锁（成功获取状态），而release则表示将状态设置回去，也就是将资源释放，或者说将锁释放。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 上述逻辑主要包括： 尝试释放状态；tryRelease能够保证原子化的将状态设置回去，当然需要使用compareAndSet来保证。如果释放状态成功过之后，将会进入后继节点的唤醒过程。 唤醒当前节点的后继节点所包含的线程。通过LockSupport的unpark方法将休眠中的线程唤醒，让其继续acquire状态。 123456789101112131415161718192021private void unparkSuccessor(Node node) &#123; // 将状态设置为同步状态 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * 获取当前节点的后继节点，如果满足状态，那么进行唤醒操作 * 如果没有满足状态，从尾部开始找寻符合要求的节点并将其唤醒 */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 上述逻辑主要包括，该方法取出了当前节点的next引用，然后对其线程(Node)进行了唤醒，这时就只有一个或合理个数的线程被唤醒，被唤醒的线程继续进行对资源的获取与争夺。回顾整个资源的获取和释放过程：在获取时，维护了一个sync队列，每个节点都是一个线程在进行自旋，而依据就是自己是否是首节点的后继并且能够获取资源；在释放时，仅仅需要将资源还回去，然后通知一下后继节点并将其唤醒。这里需要注意，队列的维护（首节点的更换）是依靠消费者（获取时）来完成的，也就是说在满足了自旋退出的条件时的一刻，这个节点就会被设置成为首节点。 tryAcquireprotected boolean tryAcquire(int arg)tryAcquire是自定义同步器需要实现的方法，也就是自定义同步器非阻塞原子化的获取状态，如果锁该方法一般用于Lock的tryLock实现中，这个特性是synchronized无法提供的。 public final void acquireInterruptibly(int arg)该方法提供获取状态能力，当然在无法获取状态的情况下会进入sync队列进行排队，这类似acquire，但是和acquire不同的地方在于它能够在外界对当前线程进行中断的时候提前结束获取状态的操作，换句话说，就是在类似synchronized获取锁时，外界能够对当前线程进行中断，并且获取锁的这个操作能够响应中断并提前返回。一个线程处于synchronized块中或者进行同步I/O操作时，对该线程进行中断操作，这时该线程的中断标识位被设置为true，但是线程依旧继续运行。如果在获取一个通过网络交互实现的锁时，这个锁资源突然进行了销毁，那么使用acquireInterruptibly的获取方式就能够让该时刻尝试获取锁的线程提前返回。而同步器的这个特性被实现Lock接口中的lockInterruptibly方法。根据Lock的语义，在被中断时，lockInterruptibly将会抛出InterruptedException来告知使用者。 12345678910111213141516171819202122232425262728293031public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125;private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; // 检测中断标志位 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 上述逻辑主要包括： 检测当前线程是否被中断；判断当前线程的中断标志位，如果已经被中断了，那么直接抛出异常并将中断标志位设置为false。 尝试获取状态；调用tryAcquire获取状态，如果顺利会获取成功并返回。 构造节点并加入sync队列；获取状态失败后，将当前线程引用构造为节点并加入到sync队列中。退出队列的方式在没有中断的场景下和acquireQueued类似，当头结点是自己的前驱节点并且能够获取到状态时，即可以运行，当然要将本节点设置为头结点，表示正在运行。 中断检测。在每次被唤醒时，进行中断检测，如果发现当前线程被中断，那么抛出InterruptedException并退出循环。 doAcquireNanosprivate boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException该方法提供了具备有超时功能的获取状态的调用，如果在指定的nanosTimeout内没有获取到状态，那么返回false，反之返回true。可以将该方法看做acquireInterruptibly的升级版，也就是在判断是否被中断的基础上增加了超时控制。针对超时控制这部分的实现，主要需要计算出睡眠的delta，也就是间隔值。间隔可以表示为nanosTimeout = 原有nanosTimeout – now（当前时间）+ lastTime（睡眠之前记录的时间）。如果nanosTimeout大于0，那么还需要使当前线程睡眠，反之则返回false。 1234567891011121314151617181920212223242526272829private boolean doAcquireNanos(int arg, long nanosTimeout)throws InterruptedException &#123; long lastTime = System.nanoTime(); final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp;tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; if (nanosTimeout &lt;= 0) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); long now = System.nanoTime(); //计算时间，当前时间减去睡眠之前的时间得到睡眠的时间，然后被 //原有超时时间减去，得到了还应该睡眠的时间 nanosTimeout -= now - lastTime; lastTime = now; if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 上述逻辑主要包括： 加入sync队列；将当前线程构造成为节点Node加入到sync队列中。 条件满足直接返回；退出条件判断，如果前驱节点是头结点并且成功获取到状态，那么设置自己为头结点并退出，返回true，也就是在指定的nanosTimeout之前获取了锁。 获取状态失败休眠一段时间；通过LockSupport.unpark来指定当前线程休眠一段时间。 计算再次休眠的时间；唤醒后的线程，计算仍需要休眠的时间，该时间表示为nanosTimeout = 原有nanosTimeout – now（当前时间）+ lastTime（睡眠之前记录的时间）。其中now – lastTime表示这次睡眠所持续的时间。 休眠时间的判定。唤醒后的线程，计算仍需要休眠的时间，并无阻塞的尝试再获取状态，如果失败后查看其nanosTimeout是否大于0，如果小于0，那么返回完全超时，没有获取到锁。 如果nanosTimeout小于等于1000L纳秒，则进入快速的自旋过程。那么快速自旋会造成处理器资源紧张吗？结果是不会，经过测算，开销看起来很小，几乎微乎其微。Doug Lea应该测算了在线程调度器上的切换造成的额外开销，因此在短时1000纳秒内就让当前线程进入快速自旋状态，如果这时再休眠相反会让nanosTimeout的获取时间变得更加不精确。上述过程可以如下图所示： 上述这个图中可以理解为在类似获取状态需要排队的基础上增加了一个超时控制的逻辑。每次超时的时间就是当前超时剩余的时间减去睡眠的时间，而在这个超时时间的基础上进行了判断，如果大于0那么继续睡眠（等待），可以看出这个超时版本的获取状态只是一个近似超时的获取状态，因此任何含有超时的调用基本结果就是近似于给定超时。 共享模式acquireSharedpublic final void acquireShared(int arg)调用该方法能够以共享模式获取状态，共享模式和之前的独占模式有所区别。以文件的查看为例，如果一个程序在对其进行读取操作，那么这一时刻，对这个文件的写操作就被阻塞，相反，这一时刻另一个程序对其进行同样的读操作是可以进行的。如果一个程序在对其进行写操作，那么所有的读与写操作在这一时刻就被阻塞，直到这个程序完成写操作。以读写场景为例，描述共享和独占的访问模式，如下图所示： 上图中，红色代表被阻塞，绿色代表可以通过。 12345678910111213141516171819public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 上述逻辑主要包括： 尝试获取共享状态；调用tryAcquireShared来获取共享状态，该方法是非阻塞的，如果获取成功则立刻返回，也就表示获取共享锁成功。 获取失败进入sync队列；在获取共享状态失败后，当前时刻有可能是独占锁被其他线程所把持，那么将当前线程构造成为节点（共享模式）加入到sync队列中。 循环内判断退出队列条件；如果当前节点的前驱节点是头结点并且获取共享状态成功，这里和独占锁acquire的退出队列条件类似。 获取共享状态成功；在退出队列的条件上，和独占锁之间的主要区别在于获取共享状态成功之后的行为，而如果共享状态获取成功之后会判断后继节点是否是共享模式，如果是共享模式，那么就直接对其进行唤醒操作，也就是同时激发多个线程并发的运行。 获取共享状态失败。通过使用LockSupport将当前线程从线程调度器上摘下，进入休眠状态。对于上述逻辑中，节点之间的通知过程如下图所示： 上图中，绿色表示共享节点，它们之间的通知和唤醒操作是在前驱节点获取状态时就进行的，红色表示独占节点，它的被唤醒必须取决于前驱节点的释放，也就是release操作，可以看出来图中的独占节点如果要运行，必须等待前面的共享节点均释放了状态才可以。而独占节点如果获取了状态，那么后续的独占式获取和共享式获取均被阻塞。 releaseSharedpublic final boolean releaseShared(int arg)调用该方法释放共享状态，每次获取共享状态acquireShared都会操作状态，同样在共享锁释放的时候，也需要将状态释放。比如说，一个限定一定数量访问的同步工具，每次获取都是共享的，但是如果超过了一定的数量，将会阻塞后续的获取操作，只有当之前获取的消费者将状态释放才可以使阻塞的获取操作得以运行。 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 上述逻辑主要就是调用同步器的tryReleaseShared方法来释放状态，并同时在doReleaseShared方法中唤醒其后继节点。 一个例子 TwinsLock在上述对同步器AbstractQueuedSynchronizer进行了实现层面的分析之后，我们通过一个例子来加深对同步器的理解：设计一个同步工具，该工具在同一时刻，只能有两个线程能够并行访问，超过限制的其他线程进入阻塞状态。对于这个需求，可以利用同步器完成一个这样的设定，定义一个初始状态，为2，一个线程进行获取那么减1，一个线程释放那么加1，状态正确的范围在[0，1，2]三个之间，当在0时，代表再有新的线程对资源进行获取时只能进入阻塞状态（注意在任何时候进行状态变更的时候均需要以CAS作为原子性保障）。由于资源的数量多于1个，同时可以有两个线程占有资源，因此需要实现tryAcquireShared和tryReleaseShared方法，这里谢谢luoyuyou和同事小明指正，已经修改了实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class TwinsLock implements Lock &#123; private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -7889272986162341211L; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException("count must large than zero."); &#125; setState(count); &#125; public int tryAcquireShared(int reduceCount) &#123; for (;;) &#123; int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current, newCount)) &#123; return newCount; &#125; &#125; &#125; public boolean tryReleaseShared(int returnCount) &#123; for (;;) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; return true; &#125; &#125; &#125; &#125; public void lock() &#123; sync.acquireShared(1); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt;= 0; &#125; public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); &#125; public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return null; &#125;&#125; 上述测试用例的逻辑主要包括： ​1. 打印线程Worker在两次睡眠之间打印自身线程，如果一个时刻只能有两个线程同时访问，那么打印出来的内容将是成对出现。​2. 分隔线程不停的打印换行，能让Worker的输出看起来更加直观。该测试的结果是在一个时刻，仅有两个线程能够获得到锁，并完成打印，而表象就是打印的内容成对出现。 总结AQS简核心是通过一个共享变量来同步状态，变量的状态由子类去维护，而AQS框架做的是： 线程阻塞队列的维护 线程阻塞和唤醒 共享变量的修改都是通过Unsafe类提供的CAS操作完成的。AbstractQueuedSynchronizer类的主要方法是acquire和release，典型的模板方法， 下面这4个方法由子类去实现： 1234protected boolean tryAcquire(int arg)protected boolean tryRelease(int arg)protected int tryAcquireShared(int arg)protected boolean tryReleaseShared(int arg) acquire方法用来获取锁，返回true说明线程获取成功继续执行，一旦返回false则线程加入到等待队列中，等待被唤醒，release方法用来释放锁。 一般来说实现的时候这两个方法被封装为lock和unlock方法。 refer http://ifeve.com/introduce-abstractqueuedsynchronizer/http://www.cnblogs.com/zhanjindong/p/java-concurrent-package-aqs-AbstractQueuedSynchronizer.htmlhttp://www.cnblogs.com/zhanjindong/p/java-concurrent-package-aqs-overview.html]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划算法]]></title>
    <url>%2F2015%2F05%2F21%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[动态规划的适用场景动态规划常常适用于有重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法。 动态规划的基本思想动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再合并子问题的解以得出原问题的解。通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。 重叠子问题动态规划在查找有很多重叠子问题的情况的最优解时有效。它将问题重新组合成子问题。为了避免多次解决这些子问题，它们的结果都逐渐被计算并被保存，从简单的问题直到整个问题都被解决。因此，动态规划保存递归时的结果，因而不会在解决同样的问题时花费时间。 最优子结构动态规划只能应用于有最优子结构的问题。最优子结构的意思是局部最优解能决定全局最优解（对有些问题这个要求并不能完全满足，故有时需要引入一定的近似）。简单地说，问题能够分解成子问题来解决。 动态规划的三要素 最优子结构性质。如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质（即满足最优化原理）。最优子结构性质为动态规划算法解决问题提供了重要线索。 无后效性。即子问题的解一旦确定，就不再改变，不受在这之后、包含它的更大的问题的求解决策影响。 子问题重叠性质。子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个表格中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。 动态规划算法的设计步骤： 刻画最优解的结构特征（寻找最优子结构） 递归地定义最优解的值（确定状态转移方程） 计算最优解的值（有两种方法：带备忘录自顶向下法、自底向上法） 利用计算出的信息构造一个最优解（通常是将具体的最优解输出） 一般的解法把动态规划的解法分为自顶向下和自底向上两种方式。自顶向下的方式其实就是使用递归来求解子问题，最终解只需要调用递归式，子问题逐步往下层递归的求解。我们可以使用缓存把每次求解出来的子问题缓存起来，下次调用的时候就不必再递归计算了。自底向上是另一种求解动态规划问题的方法，它不使用递归式，而是直接使用循环来计算所有可能的结果，往上层逐渐累加子问题的解。 LeetCode题1. House Robber题目，转化过来的意思是，一个数组nums[]，求最大的不存在相邻元素的子数组的和。 用动态规划的递归解法,自顶向下。时间复杂度O(nlogn)，空间复杂度O(1) 12345678910111213141516171819202122232425//Time Limit Exceededpublic int robRecursiveDP(int[] nums, int length) &#123; if (length == 0) &#123; return 0; &#125; if (length == 1) &#123; return nums[0]; &#125; if (length == 2) &#123; return Math.max(nums[0], nums[1]); &#125; int rob1 = robRecursiveDP(nums, length - 1); int rob2 = robRecursiveDP(nums, length - 2); if (rob1 == rob2) &#123; return rob1 + nums[length - 1]; &#125; else if (rob1 &gt; rob2) &#123; return Math.max(rob2 + nums[length - 1], rob1); &#125; else &#123; System.out.println("data error"); return 0; &#125; 动态规划的状态转移方程：dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1]);dp[i][1] = num[i - 1] + dp[i - 1][0]; 用动态规划的自底向上解法, 时间复杂度O(n)，空间复杂度O(n) 123456789// 300mspublic int robDP(int[] num) &#123; // dp[i][1] means we rob the current house and dp[i][0] means we don't int[][] dp = new int[num.length + 1][2]; for (int i = 1; i &lt;= num.length; i++) &#123; dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1]); dp[i][1] = num[i - 1] + dp[i - 1][0]; &#125; return Math.max(dp[num.length][0], dp[num.length][1]); 用带备忘录的自底向上动态规划的解法, 时间复杂度O(n)，空间复杂度O(1)1234567891011// 250mspublic int rob(int[] num) &#123; int prevNo = 0; int prevYes = 0; for (int n : num) &#123; int temp = prevNo; prevNo = Math.max(prevNo, prevYes); prevYes = n + temp; &#125; return Math.max(prevNo, prevYes);&#125; 2. House Robber2题目，转化过来的意思是，一个数组nums[], 首尾看成相邻，求最大的不存在相邻元素的子数组的和。 Actually, extending from the logic that if house i is not robbed, then you are free to choose whether to rob house i + 1, you can break the circle by assuming a house is not robbed.For example, 1 -&gt; 2 -&gt; 3 -&gt; 1 becomes 2 -&gt; 3 if 1 is not robbed.Since every house is either robbed or not robbed and at least half of the houses are not robbed, the solution is simply the larger of two cases with consecutive houses, i.e. house i not robbed, break the circle, solve it, or house i + 1 not robbed. Hence, the following solution. I chose i = n and i + 1 = 0 for simpler coding. But, you can choose whichever two consecutive ones. 123456789101112131415public int robCycle(int[] nums) &#123; if (nums.length == 0) &#123; return 0; &#125; if (nums.length == 1) &#123; return nums[0]; &#125; if (nums.length == 2) &#123; return Math.max(nums[0], nums[1]); &#125; return Math.max(rob(Arrays.copyOfRange(nums, 0, nums.length - 1)), rob(Arrays.copyOfRange(nums, 1, nums.length)));&#125; 3. Maximum Subarray题目，求最大连续子数组和。 不用动态规划的解法1234567891011121314public int maxSubArray(int[] nums) &#123; int sumMax = nums[0], sum = 0; for (int num : nums) &#123; sum += num; if (sum &lt; num) &#123; sum = num; &#125; if (sum &gt;= sumMax) &#123; sumMax = sum; &#125; &#125; return sumMax;&#125; 动态规划的状态转移方程：dp[i] = Math.max(dp[i - 1] + nums[i - 1], nums[i - 1]); 用动态规划的自底向上解法, 时间复杂度O(n)，空间复杂度O(n) 12345678910public int maxSubArrayDP(int[] nums) &#123; int sumMax = nums[0]; int[] dp = new int[nums.length + 1]; for (int i = 1; i &lt;= nums.length; i++) &#123; dp[i] = Math.max(dp[i - 1] + nums[i - 1], nums[i - 1]); sumMax = Math.max(sumMax, dp[i]); &#125; return sumMax;&#125; 用带备忘录的自底向上动态规划的解法, 时间复杂度O(n)，空间复杂度O(1)123456789public int maxSubArrayDPWithMem(int[] nums) &#123; int sumMax = nums[0], sumPre = 0; for (int i = 1; i &lt;= nums.length; i++) &#123; sumPre = Math.max(sumPre + nums[i - 1], nums[i - 1]); sumMax = Math.max(sumMax, sumPre); &#125; return sumMax;&#125; 4. Interleaving String题目，Given s1, s2, s3, find whether s3 is formed by the interleaving of s1 and s2.For example,Given:s1 = “aabcc”,s2 = “dbbca”,When s3 = “aadbbcbcac”, return true.When s3 = “aadbbbaccc”, return false. 动态规划的递归调用解法，时间复杂度不符合要求。 123456789101112131415161718192021222324252627282930public boolean isInterleaveRecursiveDP(String s1, String s2, String s3) &#123; if (s3.length() != s1.length() + s2.length()) &#123; return false; &#125; if (s1.length() == 0 &amp;&amp; s2.length() == 0 &amp;&amp; s3.length() == 0) &#123; return true; &#125; else if (s3.length() == 0) &#123; return false; &#125; String newS3 = s3.substring(0, s3.length() - 1); String newS1 = s1.length() &gt; 0 ? s1.substring(0, s1.length() - 1) : ""; String newS2 = s2.length() &gt; 0 ? s2.substring(0, s2.length() - 1) : ""; boolean equalS1 = s1.length() &gt; 0 &amp;&amp; (s1.charAt(s1.length() - 1) == s3.charAt(s3.length() - 1)); boolean equalS2 = s2.length() &gt; 0 &amp;&amp; s2.charAt(s2.length() - 1) == s3.charAt(s3.length() - 1); if (equalS1 &amp;&amp; !equalS2) &#123; return isInterleaveRecursiveDP(newS1, s2, newS3); &#125; else if (!equalS1 &amp;&amp; equalS2) &#123; return isInterleaveRecursiveDP(s1, newS2, newS3); &#125; else if (equalS1 &amp;&amp; equalS2) &#123; return isInterleaveRecursiveDP(newS1, s2, newS3) || isInterleaveRecursiveDP(s1, newS2, newS3); &#125; else &#123; return false; &#125;&#125; 动态规划带备忘录自底向上的解法，难点就在于如何将解法1的递归公式转化为动态转移方程，下述代码构造的二维数组很好地诠释了这一点。 123456789101112131415161718192021public boolean isInterleaveDP(String s1, String s2, String s3) &#123; if (s3.length() != s1.length() + s2.length()) return false; boolean[][] table = new boolean[s1.length() + 1][s2.length() + 1]; for (int i = 0; i &lt; s1.length() + 1; i++) for (int j = 0; j &lt; s2.length() + 1; j++) &#123; if (i == 0 &amp;&amp; j == 0) table[i][j] = true; else if (i == 0) table[i][j] = (table[i][j - 1] &amp;&amp; s2.charAt(j - 1) == s3.charAt(i + j - 1)); else if (j == 0) table[i][j] = (table[i - 1][j] &amp;&amp; s1.charAt(i - 1) == s3.charAt(i + j - 1)); else table[i][j] = (table[i - 1][j] &amp;&amp; s1.charAt(i - 1) == s3.charAt(i + j - 1) || (table[i][j - 1] &amp;&amp; s2.charAt(j - 1) == s3.charAt(i + j - 1))); &#125; return table[s1.length()][s2.length()];&#125;]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程中断]]></title>
    <url>%2F2015%2F04%2F13%2FJava%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[Java中断的现象首先，看看Thread类里的几个方法：public static boolean interrupted 测试当前线程是否已经中断。线程的中断状态 由该方法清除。换句话说，如果连续两次调用该方法，则第二次调用将返回 false（在第一次调用已清除了其中断状态之后，且第二次调用检验完中断状态前，当前线程再次中断的情况除外）。public boolean isInterrupted() 测试线程是否已经中断。线程的中断状态 不受该方法的影响。public void interrupt() 中断线程。 Thread.interrupt API:Interrupts this thread. First the checkAccess method of this thread is invoked, which may cause a SecurityException to be thrown. If this thread is blocked in an invocation of the wait(), wait(long), or wait(long, int) methods of the Object class, or of the join(), join(long), join(long, int), sleep(long), or sleep(long, int), methods of this class, then its interrupt status will be cleared and it will receive an InterruptedException. If this thread is blocked in an I/O operation upon an interruptible channel then the channel will be closed, the thread’s interrupt status will be set, and the thread will receive a ClosedByInterruptException. If this thread is blocked in a Selector then the thread’s interrupt status will be set and it will return immediately from the selection operation, possibly with a non-zero value, just as if the selector’s wakeup method were invoked. If none of the previous conditions hold then this thread’s interrupt status will be set.1234567891011121314public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0(); &#125; 其实，Java的中断是一种协作机制。也就是说调用线程对象的interrupt方法并不一定就中断了正在运行的线程，它只是要求线程自己在合适的时机中断自己。每个线程都有一个boolean的中断状态（不一定就是对象的属性，事实上，该状态也确实不是Thread的字段），interrupt方法仅仅只是将该状态置为true代码如下: 1234567891011121314151617181920212223public class TestInterrupt &#123; public static void main(String[] args) &#123; Thread t = new MyThread(); t.start(); t.interrupt(); System.out.println("已调用线程的interrupt方法"); &#125; static class MyThread extends Thread &#123; public void run() &#123; int num = longTimeRunningNonInterruptMethod(2, 0); System.out.println("长时间任务运行结束,num=" + num); System.out.println("线程的中断状态:" + Thread.interrupted()); &#125; private static int longTimeRunningNonInterruptMethod(int count, int initNum) &#123; for(int i=0; i&lt;count; i++) &#123; for(int j=0; j&lt;Integer.MAX_VALUE; j++) &#123; initNum ++; &#125; &#125; return initNum; &#125; &#125; &#125; 一般情况下，会打印如下内容：已调用线程的interrupt方法长时间任务运行结束,num=-2线程的中断状态:true可见，interrupt方法并不一定能中断线程。但是，如果改成下面的程序，情况会怎样呢？代码如下: 12345678910111213141516171819202122232425262728import java.util.concurrent.TimeUnit; public class TestInterrupt &#123; public static void main(String[] args) &#123; Thread t = new MyThread(); t.start(); t.interrupt(); System.out.println("已调用线程的interrupt方法"); &#125; static class MyThread extends Thread &#123; public void run() &#123; int num = -1; try &#123; num = longTimeRunningInterruptMethod(2, 0); &#125; catch (InterruptedException e) &#123; System.out.println("线程被中断"); throw new RuntimeException(e); &#125; System.out.println("长时间任务运行结束,num=" + num); System.out.println("线程的中断状态:" + Thread.interrupted()); &#125; private static int longTimeRunningInterruptMethod(int count, int initNum) throws InterruptedException&#123; for(int i=0; i&lt;count; i++) &#123; TimeUnit.SECONDS.sleep(5); &#125; return initNum; &#125; &#125; &#125; 经运行可以发现，程序抛出异常停止了，run方法里的后两条打印语句没有执行。那么，区别在哪里？一般说来，如果一个方法声明抛出InterruptedException，表示该方法是可中断的（没有在方法中处理中断却也声明抛出InterruptedException的除外），也就是说可中断方法会对interrupt调用做出响应（例如sleep响应interrupt的操作包括清除中断状态，抛出InterruptedException），如果interrupt调用是在可中断方法之前调用，可中断方法一定会处理中断，像上面的例子，interrupt方法极可能在run未进入sleep的时候就调用了，但sleep检测到中断，就会处理该中断。如果在可中断方法正在执行中的时候调用interrupt，会怎么样呢？这就要看可中断方法处理中断的时机了，只要可中断方法能检测到中断状态为true，就应该处理中断。让我们为开头的那段代码加上中断处理。那么自定义的可中断方法该如何处理中断呢？那就是在适合处理中断的地方检测线程中断状态并处理。代码如下: 12345678910111213141516171819202122232425262728293031323334353637public class TestInterrupt &#123; public static void main(String[] args) throws Exception &#123; Thread t = new MyThread(); t.start(); // TimeUnit.SECONDS.sleep(1);//如果不能看到处理过程中被中断的情形，可以启用这句再看看效果 t.interrupt(); System.out.println("已调用线程的interrupt方法"); &#125; static class MyThread extends Thread &#123; public void run() &#123; int num; try &#123; num = longTimeRunningNonInterruptMethod(2, 0); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; System.out.println("长时间任务运行结束,num=" + num); System.out.println("线程的中断状态:" + Thread.interrupted()); &#125; private static int longTimeRunningNonInterruptMethod(int count, int initNum) throws InterruptedException &#123; if(interrupted()) &#123; throw new InterruptedException("正式处理前线程已经被请求中断"); &#125; for(int i=0; i&lt;count; i++) &#123; for(int j=0; j&lt;Integer.MAX_VALUE; j++) &#123; initNum ++; &#125; //假如这就是一个合适的地方 if(interrupted()) &#123; //回滚数据，清理操作等 throw new InterruptedException("线程正在处理过程中被中断"); &#125; &#125; return initNum; &#125; &#125; &#125; 如上面的代码，方法longTimeRunningMethod此时已是一个可中断的方法了。在进入方法的时候判断是否被请求中断，如果是，就不进行相应的处理了；处理过程中，可能也有合适的地方处理中断，例如上面最内层循环结束后。这段代码中检测中断用了Thread的静态方法interrupted，它将中断状态置为false，并将之前的状态返回，而isInterrupted只是检测中断，并不改变中断状态。一般来说，处理过了中断请求，应该将其状态置为false。但具体还要看实际情形。 Java中断的本质在历史上，Java试图提供过抢占式限制中断，但问题多多，例如已被废弃的Thread.stop、Thread.suspend和 Thread.resume等。另一方面，出于Java应用代码的健壮性的考虑，降低了编程门槛，减少不清楚底层机制的程序员无意破坏系统的概率。如今，Java的线程调度不提供抢占式中断，而采用协作式的中断。其实，协作式的中断，原理很简单，就是轮询某个表示中断的标记，我们在任何普通代码的中都可以实现。 例如下面的代码：代码如下: 12345volatile bool isInterrupted; //… while(!isInterrupted) &#123; compute(); &#125; 但是，上述的代码问题也很明显。当compute执行时间比较长时，中断无法及时被响应。另一方面，利用轮询检查标志变量的方式，想要中断wait和sleep等线程阻塞操作也束手无策。如果仍然利用上面的思路，要想让中断及时被响应，必须在虚拟机底层进行线程调度的对标记变量进行检查。是的，JVM中确实是这样做的。下面摘自java.lang.Thread的源代码：代码如下:12345public static boolean interrupted() &#123; return currentThread().isInterrupted(true); &#125; //… private native boolean isInterrupted(boolean ClearInterrupted); 可以发现，isInterrupted被声明为native方法，取决于JVM底层的实现。实际上，JVM内部确实为每个线程维护了一个中断标记。但应用程序不能直接访问这个中断变量，必须通过下面几个方法进行操作：代码如下:123456789public class Thread &#123; //设置中断标记 public void interrupt() &#123; ... &#125; //获取中断标记的值 public boolean isInterrupted() &#123; ... &#125; //清除中断标记，并返回上一次中断标记的值 public static boolean interrupted() &#123; ... &#125; ... &#125; 通常情况下，调用线程的interrupt方法，并不能立即引发中断，只是设置了JVM内部的中断标记。因此，通过检查中断标记，应用程序可以做一些特殊操作，也可以完全忽略中断。 你可能想，如果JVM只提供了这种简陋的中断机制，那和应用程序自己定义中断变量并轮询的方法相比，基本也没有什么优势。 JVM内部中断变量的主要优势，就是对于某些情况，提供了模拟自动“中断陷入”的机制。在执行涉及线程调度的阻塞调用时（例如wait、sleep和join），如果发生中断，被阻塞线程会“尽可能快的”抛出InterruptedException。因此，我们就可以用下面的代码框架来处理线程阻塞中断：代码如下:123456try &#123; //wait、sleep或join &#125; catch(InterruptedException e) &#123; //某些中断处理工作 &#125; 所谓“尽可能快”，我猜测JVM就是在线程调度调度的间隙检查中断变量，速度取决于JVM的实现和硬件的性能。 一些不会抛出 InterruptedException 的线程阻塞操作然而，对于某些线程阻塞操作，JVM并不会自动抛出InterruptedException异常。例如，某些I/O操作和内部锁操作。对于这类操作，可以用其他方式模拟中断：1）java.io中的异步socket I/O读写socket的时候，InputStream和OutputStream的read和write方法会阻塞等待，但不会响应java中断。不过，调用Socket的close方法后，被阻塞线程会抛出SocketException异常。2）利用Selector实现的异步I/O如果线程被阻塞于Selector.select（在java.nio.channels中），调用wakeup方法会引起ClosedSelectorException异常。3）锁获取如果线程在等待获取一个内部锁，我们将无法中断它。但是，利用Lock类的lockInterruptibly方法，我们可以在等待锁的同时，提供中断能力。 四、两条编程原则另外，在任务与线程分离的框架中，任务通常并不知道自身会被哪个线程调用，也就不知道调用线程处理中断的策略。所以，在任务设置了线程中断标记后，并不能确保任务会被取消。因此，有以下两条编程原则：1）除非你知道线程的中断策略，否则不应该中断它。这条原则告诉我们，不应该直接调用Executer之类框架中线程的interrupt方法，应该利用诸如Future.cancel的方法来取消任务。 2）任务代码不该猜测中断对执行线程的含义。这条原则告诉我们，一般代码遇在到InterruptedException异常时，不应该将其捕获后“吞掉”，而应该继续向上层代码抛出。总之，Java中的非抢占式中断机制，要求我们必须改变传统的抢占式中断思路，在理解其本质的基础上，采用相应的原则和模式来编程。 总结要使任务和线程能安全、快速、可靠地停止下来，并不是一件容易的事。Java没有提供任何机制来安全地终止线程。但它提供了中断（Interruption），这是一种协作机制，能够使一个线程终止另一个线程的的工作。—— 『Java并发编程实战』 第7章 取消与关闭 p111 中断是一种协作机制。一个线程不能强制其它线程停止正在执行的操作而去执行其它的操作。当线程A中断B时，A仅仅是要求B在执行到某个可以暂停的地方停止正在执行的操作——前提是如果线程B愿意停下来。—— 『Java并发编程实战』 第5章 基础构建模块 p77 总之，中断只是一种协作机制，需要被中断的线程自己处理中断。停止一个线程最佳实践是 中断 + 条件变量。 Reference http://www.infoq.com/cn/articles/java-interrupt-mechanism《Java Concurrency in Practice》《Concurrent Programming in Java Design principles and patterns》http://docs.oracle.com/javase/1.4.2/docs/guide/misc/threadPrimitiveDeprecation.htmlhttp://ibruce.info/2013/12/19/how-to-stop-a-java-thread/]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[转]数据库的乐观锁和悲观锁]]></title>
    <url>%2F2015%2F04%2F13%2F-%E8%BD%AC-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81%2F</url>
    <content type="text"><![CDATA[悲观锁悲观锁假定其他用户企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。悲观的缺陷是不论是页锁还是行锁，加锁的时间可能会很长，这样可能会长时间的限制其他用户的访问，也就是说悲观锁的并发访问性不好。 乐观锁乐观锁则认为其他用户企图改变你正在更改的对象的概率是很小的，因此乐观锁直到你准备提交所作的更改时才将对象锁住，当你读取以及改变该对象时并不加锁。可见乐观锁加锁的时间要比悲观锁短，乐观锁可以用较大的锁粒度获得较好的并发访问性能。但是如果第二个用户恰好在第一个用户提交更改之前读取了该对象，那么当他完成了自己的更改进行提交时，数据库就会发现该对象已经变化了，这样，第二个用户不得不重新读取该对象并作出更改。这说明在乐观锁环境中，会增加并发用户读取对象的次数。 例子以版本控制系统为例，来说说两种最基本的并发性问题。 【丢失更新】 小张想修改源代码里面的a方法，正在她修改的同时，小李打开了这个文件，修改了b方法并且保存了文件，等小张修改完成后，保存文件，小李所做的修改就被覆盖了。 【不一致的读】 小张想要知道包里面一共有多少个类，包分了a，b两个子包。小张打开a包，看到了7个类。突然小张接到老婆打来的电话，在小张接电话的时候，小李往a包中加了2个类，b包中加了3个类（原先b包中是5个类）。 小张接完电话后再打开b包，看到了8个类，很自然得出结论：包中一共有15个类。 很遗憾，15个永远不是正确的答案。在小李修改前，正确答案是12（7+5），修改后是17（9+8）。这两个答案都是正确的，虽然有一个不是当前的。但15不对，因为小张读取的数据是不一致的。 小结：不一致读指你要读取两种数据，这两种数据都是正确的，但是在同一时刻两者并非都正确。 隔离和不可变 在企业应用中，解决并发冲突的两种常用手段是隔离和不可变。 只有当多个活动（进程或者线程）同时访问同一数据时才会引发并发问题。一种很自然的思路就是同一时刻只允许一个活动访问数据。如果小张打开了文件，就不允许其他人打开，或者其他人只能通过只读的方式打开副本，就可以解决这个问题。 隔离能够有效减少发生错误的可能。我们经常见到程序员陷入到并发问题的泥潭里，每一段代码写完都要考虑并发问题，这样太累了。我们可以利用隔离技术创建出隔离区域，当程序进入隔离区域时不用关心并发问题。好的并发性设计就是创造这样的一些隔离区域，并保证代码尽可能的运行在其中。 另一种思路：只有当你需要修改共享的数据时才可能引发并发性问题，所以我们可以将要共享的数据制作为“不可变”的，以避免并发性问题。当然我们不可能将所有的数据都做成不可变的，但如果一些数据是不可变的，对它们进行并发操作时我们就可以放松自己的神经了。 乐观并发控制、悲观并发控制如果数据是可变的，并且无法隔离呢？这种情况下最常用的两种控制就是乐观并发控制和悲观并发控制。 假设小张和小李想要同时修改同一个文件。如果使用乐观锁，俩人都能打开文件进行修改，如果小张先提交了内容，没有问题，他所做的改变会保存到服务器上。但小李提交时就会遇到麻烦，版本控制服务器会检测出两种修改的冲突，小李的提交会被具体，并由小李决定该如何处理这种情况（对于绝大部分版本控制软件来说，会读取并标识出小张做的改变，然后由小李决定是否合并）。 如果使用的是悲观锁，小张先检出（check out）文件，那么小李就无法再次检出同一文件，直到小张提交了他的改变。 建议你将乐观锁想成一种检测冲突的手段，而悲观锁是一种避免冲突的手段（严格来说，乐观锁其实不能称之为“锁”，但是这个名字已经流传开了，那就继续使用吧）。一些老的版本控制系统，比如VSS 6.0使用的是悲观锁的机制。而现代的版本控制系统一般两种都支持，默认使用乐观锁。 乐观锁可以提高并发访问的效率，但是如果出现了冲突只能向上抛出，然后重来一遍；悲观锁可以避免冲突的发生，但是会降低效率。 选择使用那一种锁取决于访问频率和一旦产生冲突的严重性。如果系统被并发访问的概率很低，或者冲突发生后的后果不太严重（所谓后果应该指被检测到冲突的提交会失败，必须重来一次），可以使用乐观锁，否则使用悲观锁。 实现 我们经常会在访问数据库的时候用到锁，怎么实现乐观锁和悲观锁呢？以Hibernate为例，可以通过为记录添加版本或时间戳字段来实现乐观锁。可以用session.Lock()锁定对象来实现悲观锁（本质上就是执行了SELECT * FROM t FOR UPDATE语句）。 转至： http://www.cnblogs.com/chenlulouis/archive/2010/08/17/1801358.html]]></content>
      <tags>
        <tag>Data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell常用技巧]]></title>
    <url>%2F2015%2F04%2F10%2FShell%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[grep常用技巧grep匹配TAB 12直接grep tab字符 //命令行下用”ESC TAB”输入grep $&apos;\t&apos; grep匹配减号 1cat file | grep -- -1 去除所有空行 1cat file | grep -v &quot;^$&quot; &gt; file2 只显示以a开头的行。 1cat file | grep &apos;^a&apos; 显示log中error附近的内容 1cat file | grep -C5 &quot;error&quot; awk常用技巧隔行显示 1cat file | awk &apos;&#123;getline; print $1;&#125;&apos; 取奇数/偶数行数据 12awk &apos;NR%2==1&apos; file //显示奇数行awk &apos;NR%2==0&apos; file //显示偶数行 vim常用技巧vim下将x替换成制表符 12%s/x/^Ip.s: 直接按TAB就可以啦 ,不需要用转义序列\t的 vim下将x替换成换行 1%s/x/\r sed常用技巧查看文件选定的行 123wc -l a.txt //统计a.txt 行数sed -n &apos;190,196p&apos; a.txt //查看第190行到第196行sed -n &apos;190,1p&apos; a.txt //查看第190行 将文件中的 , 换成 tab 符号1cat data.csv | sed $&apos;s/,/\t/g&apos;]]></content>
      <tags>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM编码方式未设置引发的乱码]]></title>
    <url>%2F2015%2F02%2F04%2FJVM%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F%E6%9C%AA%E8%AE%BE%E7%BD%AE%E5%BC%95%E5%8F%91%E7%9A%84%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[现象服务中出现大量乱码数据，并且全部入库。 原因虽然maven项目的pom.xml文件中已配置成UTF-8，并且打出的jar包编码也是UTF-8，但运行时出现中文全是乱码。发现是系统环境变量中未设置LANG相关变量为UTF-8导致的。 分析这是表面原因，究其根本，为什么JVM运行jar包的编码方式会依赖系统环境变量呢？查到原因是因为运行jar包时未指定jvm的 file.encoding参数，改为1java -Dfile.encoding=UTF-8 XXX 后彻底解决。 但是这样发布服务时就太依赖发布脚本了，那能否在程序中就设置好编码呢？比如这样：1System.setProperty("file.encoding", "UTF-8"); 其实，这样设置是不生效的，因为JVM在启动时就开始cache编码方式了，程序中再设置已然无效。不过可以在程序每个读写数据的地方都设置编码方式，但是这样未免太工程浩大，而且无法保证每个写代码的人都能做到。所以最后改为依赖在发布脚本中设置编码方式，并且在服务启动时对编码进行检查。 Reference As Edward Grech points out, in a special case like this, the environment variable JAVA_TOOL_OPTIONS can be used to specify this property, but it’s normally done like this: java -Dfile.encoding=UTF-8 XXX Charset.defaultCharset() will reflect changes to the file.encoding property, but most of the code in the core Java libraries that need to determine the default character encoding do not use this mechanism. Important points to note: JVM caches value of default character encoding once JVM starts and so is the case for default constructors of InputStreamReader and other core Java classes. So calling System.setProperty(“file.encoding” , “UTF-16”) may not have desire effect. Always work with your own character encoding if you can, that is more accurate and precise way of converting bytes to Strings.]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iterator详解]]></title>
    <url>%2F2015%2F02%2F03%2FIterator%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Iterator详解Iterator是java中的一个接口，借用源码中的注释：An iterator over a collection. {@code Iterator} takes the place of {@link Enumeration} in the Java Collections Framework. Iterators differ from enumerations in two ways: Iterators allow the caller to remove elements from the underlying collection during the iteration with well-defined semantics. Method names have been improved. 123public interface Iterator&lt;E&gt; &#123; ... ... &#125; 需要迭代器的地方实现这个接口。集合的基本类Collection就实现了这个接口123public interface Collection&lt;E&gt; extends Iterable&lt;E&gt; &#123; ... ...&#125; 举例来看下java的ArrayList类迭代器的实现。ArrayList中iterator()方法：123public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125; 再来看Itr的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * An optimized version of AbstractList.Itr */private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings("unchecked") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); // 见下文代码 cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; @Override @SuppressWarnings("unchecked") public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &#123; Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) &#123; return; &#125; final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) &#123; throw new ConcurrentModificationException(); &#125; while (i != size &amp;&amp; modCount == expectedModCount) &#123; consumer.accept((E) elementData[i++]); &#125; // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125;``` 调ArrayList.this.remove(lastRet)时，remove的实现```javapublic E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 所以使用iterator来遍历List集合时，不能对list增删元素。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap实现原理]]></title>
    <url>%2F2015%2F02%2F03%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashMap源码分析概要 HashMap是基于Map接口实现的，提供了所有Map支持的操作，并且允许key和value为null。HashMap可以近似地认为是HashTable，其差别仅在于前者允许null的key,value，并且操作不是同步的(unsynchronized)。 Iteration遍历整个hashMap的时间与hashMap的capacity(buckets的数量)加上hashMap的size的值是成正比的，所以如果想要高效地遍历HashMap，就不要将capacity的初始值设置的太高，也不要将load factor设置的太低。 衡量HashMap性能的指标只有两个，一个是capacity的初始值，一个是load factor。 capacity是指hash表中buckets的数量，而capacity的初始值是指当hash表被创建时capacity被设定的值。 load factor是用来衡量当hash表扩容之前有多满的指标。load_factor = put_size/size 当hash表的元素超过了阈值(loadFactor*capacity)时会自动将内部数据重建一遍，并将buckets的数量翻倍，这个过程称为rehash。 根据经验来讲，当load factor为0.75时，较好地权衡了时间和空间上的取舍。load factor高虽然能减少空间的消耗但是增加了查询的代价，主要反映在put和get操作。 当设定capacity初始值时需要考虑map中期望地元素个数和load factor，这样能最小化rehash的次数。如果capacity初始值大于最大元素个数除以load factor的值，则永远不会发生load factor操作。 如果有很多mapping都要存放到同一个HashMap，那么在最开始就设置一个充足的capacity比当hash表超过阈值后再rehash要高效地多。 请注意：所以的实现都不是synchronized的，如果有多个线程同时操作HashMap，并且有线程会修改HashMap的结构时，则必须要对此操作加synchronized标识。增加或删除HashMap中的元素都算是修改HashMap的结构，如果仅仅只是修改某个key的value则不算。 如果没有可以对HashMap做synchronized的对象，那么可以使用1Map m = Collections.synchronizedMap(new HashMap(…) 来生成一个同步操作的Map. HashMap的实现Fields123456transient Node&lt;K,V&gt;[] table;;//存储元素的实体数组transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //Holds cached entrySet()transient int size;//存放元素的个数int threshold; //当实际大小超过临界值时，会进行扩容threshold = 加载因子*容量, DEFAULT_INITIAL_CAPACITYfinal float loadFactor; //加载因子transient int modCount;//This field is used to make iterators on Collection-views of the HashMap fail-fast 实现java8的改进点 java.util.HashMap 是JDK里散列的一个实现，JDK6里采用位桶+链表的形式实现，Java8里采用的是位桶+链表/红黑树的方式，this will improve the worst case performance from O(n) to O(log n).。 访问map的过程仅以put操作为例来说明，put操作的过程： 当未冲突时；put的位置为 (tab.length-1)&amp;key.hashCode() 当冲突时；如果冲突的位置上放的是TreeNode，则加入。否则加入冲突位置的元素链表的最末尾，如果加入后链表长度达到TREEIFY_THRESHOLD，则将链表转为红黑树。 加入操作完成后，如果size大于threshold则resize。 hashCode和sizehash函数如下：1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; tab.length的大小为2的幂次方，实现：123456789101112/*** Returns a power of two size for the given target capacity.*/static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 遍历HashMap当需要取出key-value时，推荐123456Iterator iter = map.entrySet().iterator();while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); Object key = entry.getKey(); Object val = entry.getValue();&#125; 遍历时操作遍历时removeRemoves the current element. Throws IllegalStateException if an attempt is made to call remove() that is not preceded by a call to next( ). keySet的使用keySet没有实现add(E e)方法，所有当对keySet调用add方法时会抛出UnsupportedOperationException。KeySet继承关系如下：123456class KeySet extends AbstractSet&lt;K&gt;abstract class AbstractSet&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Set&lt;E&gt;abstract class AbstractCollection&lt;E&gt; implements Collection&lt;E&gt;&#123; public boolean add(E e) &#123; throw new UnsupportedOperationException();&#125; 直接使用subclass遍历时不允许修改map1234for (Instance key : InsMap.keySet()) &#123; keySet.remove(instance2); System.out.println(InsMap.get(key));&#125; remove后第二遍进入for循环时会抛ConcurrentModificationException。原因是KeySet, Values, EntrySet这三个subclass都不允许在遍历过程中map被修改1234567891011121314public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125;&#125;]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Good Engineer Keys]]></title>
    <url>%2F2014%2F12%2F25%2FGoog-Engineer-Keys%2F</url>
    <content type="text"><![CDATA[A good engineer has technical mastery. A great engineer has these additional qualities: Clear communication of complex ideas.Can the engineer explain themselves to non-technical stakeholders, as well as other engineers? Many technically proficient engineers are not considered great because they can’t communicate their ideas. They love to code.Being an engineer is a great high paying job, which is why many good developers do it. Great engineers would code even if that wasn’t the case. They keep their skills current, and they have the stamina to power through long hours because they are doing what they love.Desire to simplify instead of making things more complex. Hard, complex challenges are often fun for developers. Great engineers want to simplify the problem instead of building something complicated. A strong business and product sense.In the development of a feature, developers often need to make product decisions that aren’t covered in the spec. Their ability to make the right call depends on an understanding of why a feature is good for the business, and how products should be built. They focus on the highest impact items.Good engineers get distracted. Great engineers spend their time where it matters. Strong social skills.An engineer needs to effectively interact with people across the company to be great a their job. If they can only interact with other developers, then they are only good at their job.]]></content>
      <tags>
        <tag>Introspect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2014%2F11%2F14%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in trobuleshooting or you can ask me on GitHub. single asterisks double asterisks Red Green Blue Bird McHale Parish default primary success titleQuick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
